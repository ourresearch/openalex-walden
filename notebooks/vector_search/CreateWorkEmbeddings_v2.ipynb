{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Work Embeddings for Vector Search (v2)\n",
    "\n",
    "Generates text embeddings for all OpenAlex works using `databricks-bge-large-en` (1024 dims).\n",
    "\n",
    "**Format**: `Title: {title}\\n\\nAbstract: {abstract}`\n",
    "\n",
    "**Output**: `openalex.vector_search.work_embeddings` Delta table\n",
    "\n",
    "**Exclusions**: Works with type='dataset' (non-semantic titles)\n",
    "\n",
    "## Changes from v1\n",
    "- Uses `databricks-bge-large-en` (free, built-in) instead of OpenAI\n",
    "- Fixed column names: `title` (not `display_name`), `abstract` (already a string)\n",
    "- Uses ai_query() for simpler SQL-based processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EMBEDDING_MODEL = \"databricks-bge-large-en\"  # Built-in, free, 1024 dims\n",
    "OUTPUT_TABLE = \"openalex.vector_search.work_embeddings\"\n",
    "SOURCE_TABLE = \"openalex.works.openalex_works\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify schema and table exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Verify table exists\n",
    "DESCRIBE TABLE openalex.vector_search.work_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Count works available for embedding\n",
    "SELECT \n",
    "    COUNT(*) as total_works,\n",
    "    SUM(CASE WHEN abstract IS NOT NULL THEN 1 ELSE 0 END) as with_abstract,\n",
    "    SUM(CASE WHEN abstract IS NULL THEN 1 ELSE 0 END) as title_only\n",
    "FROM openalex.works.openalex_works \n",
    "WHERE type != 'dataset'\n",
    "  AND title IS NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test embedding on sample (verify before scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Test: Embed 5 works to verify pipeline\n",
    "SELECT \n",
    "    CAST(id AS STRING) as work_id,\n",
    "    title,\n",
    "    SIZE(ai_query(\n",
    "        'databricks-bge-large-en',\n",
    "        CONCAT('Title: ', title, COALESCE(CONCAT('\\n\\nAbstract: ', abstract), ''))\n",
    "    )) as embedding_dims\n",
    "FROM openalex.works.openalex_works\n",
    "WHERE type != 'dataset' \n",
    "  AND title IS NOT NULL\n",
    "  AND abstract IS NOT NULL\n",
    "  AND publication_year = 2024\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert small validation batch (100 works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Insert 100 works with abstracts from 2024 for validation\n",
    "INSERT INTO openalex.vector_search.work_embeddings\n",
    "SELECT \n",
    "    CAST(id AS STRING) as work_id,\n",
    "    CAST(ai_query(\n",
    "        'databricks-bge-large-en',\n",
    "        CONCAT('Title: ', title, '\\n\\nAbstract: ', abstract)\n",
    "    ) AS ARRAY<FLOAT>) as embedding,\n",
    "    md5(CONCAT('Title: ', title, '\\n\\nAbstract: ', abstract)) as text_hash,\n",
    "    publication_year,\n",
    "    type,\n",
    "    open_access.is_oa as is_oa,\n",
    "    true as has_abstract,\n",
    "    current_timestamp() as created_at,\n",
    "    current_timestamp() as updated_at\n",
    "FROM openalex.works.openalex_works\n",
    "WHERE type != 'dataset' \n",
    "  AND title IS NOT NULL\n",
    "  AND abstract IS NOT NULL\n",
    "  AND publication_year = 2024\n",
    "  AND CAST(id AS STRING) NOT IN (SELECT work_id FROM openalex.vector_search.work_embeddings)\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    COUNT(*) as total_embeddings,\n",
    "    SUM(CASE WHEN has_abstract THEN 1 ELSE 0 END) as with_abstract,\n",
    "    MIN(created_at) as oldest,\n",
    "    MAX(created_at) as newest\n",
    "FROM openalex.vector_search.work_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Check embedding dimensions and sample data\n",
    "SELECT \n",
    "    work_id,\n",
    "    SIZE(embedding) as embedding_dims,\n",
    "    publication_year,\n",
    "    type\n",
    "FROM openalex.vector_search.work_embeddings\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test similarity search\n",
    "\n",
    "Verify embeddings work for similarity search before scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Test similarity: find works similar to a query about \"climate change impacts on marine ecosystems\"\n",
    "WITH query_embedding AS (\n",
    "    SELECT ai_query(\n",
    "        'databricks-bge-large-en',\n",
    "        'climate change impacts on marine ecosystems and ocean biodiversity'\n",
    "    ) as embedding\n",
    ")\n",
    "SELECT \n",
    "    e.work_id,\n",
    "    w.title,\n",
    "    -- Cosine similarity approximation using dot product (embeddings are normalized)\n",
    "    AGGREGATE(\n",
    "        TRANSFORM(\n",
    "            SEQUENCE(0, SIZE(e.embedding) - 1),\n",
    "            i -> CAST(e.embedding[i] AS DOUBLE) * CAST(q.embedding[i] AS DOUBLE)\n",
    "        ),\n",
    "        CAST(0.0 AS DOUBLE),\n",
    "        (acc, x) -> acc + x\n",
    "    ) as similarity_score\n",
    "FROM openalex.vector_search.work_embeddings e\n",
    "CROSS JOIN query_embedding q\n",
    "JOIN openalex.works.openalex_works w ON CAST(w.id AS STRING) = e.work_id\n",
    "ORDER BY similarity_score DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Scale up (run after validation)\n",
    "\n",
    "Once validation passes, insert larger batches. Run these cells incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Insert 10K more works (with abstracts, 2024)\n",
    "INSERT INTO openalex.vector_search.work_embeddings\n",
    "SELECT \n",
    "    CAST(id AS STRING) as work_id,\n",
    "    CAST(ai_query(\n",
    "        'databricks-bge-large-en',\n",
    "        CONCAT('Title: ', title, '\\n\\nAbstract: ', abstract)\n",
    "    ) AS ARRAY<FLOAT>) as embedding,\n",
    "    md5(CONCAT('Title: ', title, '\\n\\nAbstract: ', abstract)) as text_hash,\n",
    "    publication_year,\n",
    "    type,\n",
    "    open_access.is_oa as is_oa,\n",
    "    true as has_abstract,\n",
    "    current_timestamp() as created_at,\n",
    "    current_timestamp() as updated_at\n",
    "FROM openalex.works.openalex_works\n",
    "WHERE type != 'dataset' \n",
    "  AND title IS NOT NULL\n",
    "  AND abstract IS NOT NULL\n",
    "  AND publication_year >= 2020\n",
    "  AND CAST(id AS STRING) NOT IN (SELECT work_id FROM openalex.vector_search.work_embeddings)\n",
    "LIMIT 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Model Choice: BGE vs OpenAI\n",
    "\n",
    "| Model | Dims | Cost (187M works) | Notes |\n",
    "|-------|------|-------------------|-------|\n",
    "| databricks-bge-large-en | 1024 | Free (built-in) | Ready to use |\n",
    "| text-embedding-3-small | 1536 | ~$1,500 | Requires endpoint setup |\n",
    "\n",
    "Started with BGE for validation. Can switch to OpenAI later if needed.\n",
    "\n",
    "### Scaling Strategy\n",
    "\n",
    "1. **Phase 1**: 100 works (this notebook) - validate pipeline\n",
    "2. **Phase 2**: 10K works - validate at small scale\n",
    "3. **Phase 3**: Scale to all 187M works with abstracts\n",
    "\n",
    "For Phase 3, consider:\n",
    "- Running as a scheduled job with batches\n",
    "- Using a dedicated SQL warehouse\n",
    "- Monitoring rate limits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
