{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Create Mosaic AI Vector Search Index (Managed Embeddings)\n\nSets up a Vector Search endpoint and Delta Sync index with **Databricks-managed embeddings**.\n\n**Source**: `openalex.vector_search.works_for_embedding`\n**Embedding Model**: `databricks-gte-large-en` (1024 dims, managed by Databricks)\n**Endpoint**: Storage-optimized for cost efficiency at scale\n**Sync**: Delta Sync (automatic updates from source table)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nENDPOINT_NAME = \"openalex-vector-search\"\nINDEX_NAME = \"openalex.vector_search.work_embeddings_index\"\nSOURCE_TABLE = \"openalex.vector_search.works_for_embedding\"\nEMBEDDING_SOURCE_COLUMN = \"text_to_embed\"\nEMBEDDING_MODEL = \"databricks-gte-large-en\"  # Databricks manages embedding\nPRIMARY_KEY = \"work_id\"\n\n# Metadata columns for filtering\nMETADATA_COLUMNS = [\"publication_year\", \"type\", \"is_oa\", \"has_abstract\", \"has_content_pdf\", \"has_content_grobid_xml\"]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Vector Search Endpoint (storage-optimized)\n",
    "\n",
    "Storage-optimized endpoints are up to 7x cheaper than standard endpoints.\n",
    "- 1 unit = 64M vectors @ 768 dimensions\n",
    "- For 250M vectors @ 1536 dimensions = ~8 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Initialize client\n",
    "vsc = VectorSearchClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if endpoint exists\n",
    "try:\n",
    "    endpoint = vsc.get_endpoint(ENDPOINT_NAME)\n",
    "    print(f\"Endpoint '{ENDPOINT_NAME}' already exists\")\n",
    "    print(f\"  Status: {endpoint.get('endpoint_status', {}).get('state')}\")\n",
    "    print(f\"  Type: {endpoint.get('endpoint_type')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint does not exist, will create: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage-optimized endpoint\n",
    "# Only run if endpoint doesn't exist\n",
    "\n",
    "try:\n",
    "    vsc.get_endpoint(ENDPOINT_NAME)\n",
    "    print(f\"Endpoint '{ENDPOINT_NAME}' already exists, skipping creation\")\n",
    "except Exception:\n",
    "    endpoint = vsc.create_endpoint(\n",
    "        name=ENDPOINT_NAME,\n",
    "        endpoint_type=\"STORAGE_OPTIMIZED\"  # 7x cheaper than STANDARD\n",
    "    )\n",
    "    print(f\"Created endpoint: {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for endpoint to be ready\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    endpoint = vsc.get_endpoint(ENDPOINT_NAME)\n",
    "    state = endpoint.get('endpoint_status', {}).get('state')\n",
    "    print(f\"Endpoint state: {state}\")\n",
    "    \n",
    "    if state == 'ONLINE':\n",
    "        print(\"Endpoint is ready!\")\n",
    "        break\n",
    "    elif state in ['OFFLINE', 'FAILED']:\n",
    "        raise Exception(f\"Endpoint failed to start: {endpoint}\")\n",
    "    \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Create Source Table (if needed)\n\nThe source table contains the text to embed and metadata columns."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%sql\n-- Create source table with Change Data Feed enabled (if not exists)\nCREATE TABLE IF NOT EXISTS openalex.vector_search.works_for_embedding (\n    work_id STRING NOT NULL,\n    text_to_embed STRING NOT NULL,\n    publication_year INT,\n    type STRING,\n    is_oa BOOLEAN,\n    has_abstract BOOLEAN,\n    has_content_pdf BOOLEAN,\n    has_content_grobid_xml BOOLEAN\n)\nTBLPROPERTIES ('delta.enableChangeDataFeed' = 'true');\n\n-- Populate from source (only if empty)\n-- INSERT INTO openalex.vector_search.works_for_embedding\n-- SELECT\n--     CAST(id AS STRING) as work_id,\n--     CONCAT('Title: ', COALESCE(title, ''), '\\n\\nAbstract: ', COALESCE(abstract, '')) as text_to_embed,\n--     publication_year,\n--     type,\n--     open_access.is_oa as is_oa,\n--     CASE WHEN abstract IS NOT NULL THEN true ELSE false END as has_abstract,\n--     has_content.pdf as has_content_pdf,\n--     has_content.grobid_xml as has_content_grobid_xml\n-- FROM openalex.works.openalex_works\n-- WHERE type != 'dataset'\n--   AND abstract IS NOT NULL\n--   AND title IS NOT NULL\n--   AND id IS NOT NULL;"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Delta Sync Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if index exists\n",
    "try:\n",
    "    index = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n",
    "    print(f\"Index '{INDEX_NAME}' already exists\")\n",
    "    print(f\"  Status: {index.get('status', {}).get('ready')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Index does not exist, will create: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create Delta Sync index with MANAGED EMBEDDINGS\n# Databricks handles embedding generation automatically using the specified model\n\ntry:\n    vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n    print(f\"Index '{INDEX_NAME}' already exists, skipping creation\")\nexcept Exception:\n    index = vsc.create_delta_sync_index(\n        endpoint_name=ENDPOINT_NAME,\n        index_name=INDEX_NAME,\n        source_table_name=SOURCE_TABLE,\n        primary_key=PRIMARY_KEY,\n        # Managed embeddings: specify source column and model\n        embedding_source_column=EMBEDDING_SOURCE_COLUMN,\n        embedding_model_endpoint_name=EMBEDDING_MODEL,\n        # Metadata columns for filtering\n        columns_to_sync=METADATA_COLUMNS,\n        # Use triggered sync for cost control (vs continuous)\n        pipeline_type=\"TRIGGERED\"\n    )\n    print(f\"Created managed embedding index: {index}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for index to sync\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    index = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n",
    "    status = index.get('status', {})\n",
    "    ready = status.get('ready', False)\n",
    "    indexed_count = status.get('indexed_row_count', 0)\n",
    "    \n",
    "    print(f\"Index ready: {ready}, Indexed rows: {indexed_count:,}\")\n",
    "    \n",
    "    if ready:\n",
    "        print(\"Index is ready!\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test query using text (Databricks handles embedding automatically)\ntest_query = \"climate change impacts on coral reef ecosystems\"\n\nindex = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n\n# With managed embeddings, use query_text instead of query_vector\nresults = index.similarity_search(\n    query_text=test_query,\n    num_results=10,\n    columns=[\"work_id\", \"publication_year\", \"type\", \"is_oa\"]\n)\n\nprint(f\"Query: {test_query}\")\nprint(f\"Found {len(results.get('result', {}).get('data_array', []))} results\")\nfor row in results.get('result', {}).get('data_array', []):\n    print(f\"  work_id: {row[0]}, year: {row[1]}, type: {row[2]}, is_oa: {row[3]}, score: {row[-1]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test with metadata filter\nresults_filtered = index.similarity_search(\n    query_text=test_query,\n    num_results=10,\n    filters=\"publication_year > 2020\",\n    columns=[\"work_id\", \"publication_year\", \"type\", \"is_oa\"]\n)\n\nprint(f\"Found {len(results_filtered.get('result', {}).get('data_array', []))} results (year > 2020)\")\nfor row in results_filtered.get('result', {}).get('data_array', []):\n    print(f\"  work_id: {row[0]}, year: {row[1]}, type: {row[2]}, is_oa: {row[3]}, score: {row[-1]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Trigger manual sync (for updates)\n",
    "\n",
    "Call this after new embeddings are added to sync the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger manual sync (for TRIGGERED pipeline type)\n",
    "index = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n",
    "sync_result = index.sync()\n",
    "print(f\"Sync triggered: {sync_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current index info\n",
    "index = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n",
    "print(\"Index configuration:\")\n",
    "print(f\"  Name: {index.get('name')}\")\n",
    "print(f\"  Source table: {index.get('delta_sync_index_spec', {}).get('source_table')}\")\n",
    "print(f\"  Embedding column: {index.get('delta_sync_index_spec', {}).get('embedding_vector_columns')}\")\n",
    "print(f\"  Embedding dimension: {index.get('delta_sync_index_spec', {}).get('embedding_dimension')}\")\n",
    "print(f\"  Pipeline type: {index.get('delta_sync_index_spec', {}).get('pipeline_type')}\")\n",
    "print(f\"  Status: {index.get('status')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}