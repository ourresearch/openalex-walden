{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29c65842-0749-4901-93f4-f6178eaa795d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use raw data from `openalex_works_base` to assign authors & institutions in `author_institutions` mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34e80a10-caa7-4955-8f68-fe74ec720501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE max_updated_date TIMESTAMP DEFAULT to_timestamp('1900-01-01');\n",
    "SET VARIABLE max_updated_date = COALESCE((SELECT MAX(updated_datetime) FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations')), to_timestamp('1900-01-01'));\n",
    "SELECT max_updated_date;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1f152e3-74aa-4f5d-8219-5def2704bf38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Get updated works for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "589b332f-153c-43ec-a85e-ab8959127398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMPORARY VIEW batch_staged_data AS\n",
    "WITH raw_exploded AS (\n",
    "    SELECT \n",
    "        id AS work_id,\n",
    "        updated_date,\n",
    "        POSEXPLODE(authorships) AS (author_sequence, authorship)\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works_base')\n",
    "    WHERE updated_date > :max_updated_date\n",
    "      AND authorships IS NOT NULL \n",
    "      AND SIZE(authorships) > 0\n",
    "),\n",
    "exploded_affiliations AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        authorship,\n",
    "        authorship.raw_author_name,\n",
    "        EXPLODE_OUTER(authorship.raw_affiliation_strings) AS raw_affiliation_string\n",
    "    FROM raw_exploded\n",
    "),\n",
    "resolved_institutions AS (\n",
    "    SELECT \n",
    "        ea.work_id,\n",
    "        ea.author_sequence,\n",
    "        ea.authorship, \n",
    "        ea.raw_author_name,\n",
    "        CASE \n",
    "            WHEN ea.raw_affiliation_string IS NULL THEN NULL\n",
    "            WHEN asl.institution_ids_override IS NOT NULL AND SIZE(asl.institution_ids_override) > 0 \n",
    "                THEN asl.institution_ids_override\n",
    "            WHEN asl.institution_ids IS NOT NULL AND SIZE(asl.institution_ids) > 0 \n",
    "                AND NOT (SIZE(asl.institution_ids) = 1 AND asl.institution_ids[0] = -1) \n",
    "                THEN asl.institution_ids\n",
    "            ELSE NULL\n",
    "        END AS institution_ids_array,\n",
    "        asl.countries AS raw_countries\n",
    "    FROM exploded_affiliations ea\n",
    "    LEFT JOIN openalex.institutions.affiliation_strings_lookup asl\n",
    "        ON ea.raw_affiliation_string = asl.raw_affiliation_string\n",
    ")\n",
    "SELECT \n",
    "    work_id,\n",
    "    author_sequence,\n",
    "    array_distinct(flatten(collect_list(institution_ids_array))) as all_institution_ids,\n",
    "    first(authorship) as authorship_struct,\n",
    "    first(raw_author_name) as raw_author_name,\n",
    "    first(raw_countries) as raw_countries\n",
    "FROM resolved_institutions\n",
    "GROUP BY work_id, author_sequence;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "717c33cd-491c-43af-86d6-f5fadb1e63ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Run Matching Algorithm Over Updated Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b1f5de5-fa14-41b8-9267-00dfdebecd85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE openalex.authors.pending_author_assignments AS\n",
    "WITH \n",
    "-- 1. ENRICH BATCH DATA\n",
    "-- We need to add Signals (Topics, Sources) and parsed names to the staged batch data\n",
    "enriched_batch AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.author_sequence,\n",
    "    b.raw_author_name,\n",
    "    b.all_institution_ids AS institution_ids,\n",
    "    \n",
    "    -- Lookup Parsed Name\n",
    "    COALESCE(pn.parsed_name, named_struct('first', '', 'last', '', 'middle', '')) AS parsed_name,\n",
    "    \n",
    "    -- Lookup Topics (Join to existing topics table)\n",
    "    COALESCE(wtf.topics, ARRAY()) AS topics,\n",
    "    \n",
    "    -- Lookup Sources (Extract from works table)\n",
    "    ARRAY_DISTINCT(\n",
    "      TRANSFORM(\n",
    "        FILTER(w.locations, x -> x.source.id IS NOT NULL),\n",
    "        x -> x.source.id\n",
    "      )\n",
    "    ) AS work_source_ids\n",
    "    \n",
    "  FROM batch_staged_data b\n",
    "  -- Get Parsed Name\n",
    "  LEFT JOIN openalex.authors.parsed_names_lookup pn \n",
    "    ON TRIM(b.raw_author_name) = pn.raw_author_name\n",
    "  -- Get Topics\n",
    "  LEFT JOIN openalex.works.work_topics_frontfill wtf \n",
    "    ON b.work_id = wtf.work_id\n",
    "  -- Get Sources\n",
    "  LEFT JOIN openalex.works.openalex_works w \n",
    "    ON b.work_id = w.id\n",
    "),\n",
    "\n",
    "-- 2. PREPARE MATCHING INPUTS\n",
    "-- Calculate Block Keys and ID arrays\n",
    "authors_prepared AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    author_sequence,\n",
    "    raw_author_name,\n",
    "    parsed_name,\n",
    "    -- Block Key Generation\n",
    "    LOWER(CONCAT(SUBSTRING(parsed_name.first, 1, 1), ' ', parsed_name.last)) AS block_key,\n",
    "    institution_ids,\n",
    "    -- Extract Topic IDs\n",
    "    TRANSFORM(topics, t -> t.id) AS topic_ids,\n",
    "    work_source_ids\n",
    "  FROM enriched_batch\n",
    "  -- Filter invalid rows if necessary, though batch_staged_data should be clean\n",
    "  WHERE raw_author_name IS NOT NULL\n",
    "),\n",
    "\n",
    "-- 3. CANDIDATE BLOCKING\n",
    "blocked_candidates AS (\n",
    "  SELECT \n",
    "    e.work_id,\n",
    "    e.author_sequence,\n",
    "    e.raw_author_name,\n",
    "    e.parsed_name,\n",
    "    e.block_key,\n",
    "    e.institution_ids,\n",
    "    e.topic_ids,\n",
    "    e.work_source_ids,\n",
    "    alm.author_id,\n",
    "    alm.parsed_longest_name,\n",
    "    alm.institution_ids as candidate_institution_ids,\n",
    "    alm.topic_ids as candidate_topic_ids,\n",
    "    alm.source_ids AS candidate_source_ids,\n",
    "    alm.works_count\n",
    "  FROM authors_prepared e\n",
    "  JOIN openalex.authors.author_lookup_mapping alm\n",
    "    ON alm.block_key = e.block_key\n",
    "),\n",
    "\n",
    "with_match_signals AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    NAMED_STRUCT(\n",
    "      'id', author_id,\n",
    "      'display_name', CONCAT(parsed_longest_name.first, ' ', parsed_longest_name.last),\n",
    "      'parsed_name', parsed_longest_name\n",
    "    ) AS candidate_obj,\n",
    "    length(parsed_name.first) as pn_first_len,\n",
    "    length(parsed_longest_name.first) as cand_first_len,\n",
    "    coalesce(parsed_name.middle, '') as pn_middle,\n",
    "    coalesce(parsed_longest_name.middle, '') as cand_middle,\n",
    "    \n",
    "    (size(institution_ids) > 0 AND size(candidate_institution_ids) > 0 \n",
    "     AND arrays_overlap(candidate_institution_ids, institution_ids)) as has_inst,\n",
    "    \n",
    "    (size(topic_ids) > 0 AND size(candidate_topic_ids) > 0 \n",
    "     AND arrays_overlap(candidate_topic_ids, topic_ids)) as has_topic,\n",
    "\n",
    "     (SIZE(work_source_ids) > 0 AND SIZE(candidate_source_ids) > 0\n",
    "     AND ARRAYS_OVERLAP(candidate_source_ids, work_source_ids)) AS has_source\n",
    "  FROM blocked_candidates\n",
    "),\n",
    "\n",
    "with_name_matches AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- 1: Exact Full Name\n",
    "    (pn_first_len > 1 AND length(pn_middle) > 1 AND cand_first_len > 1 AND length(cand_middle) > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(pn_middle) = lower(cand_middle)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_1_exact_full,\n",
    "\n",
    "    -- 2: Exact First, Middle Initial match\n",
    "    (pn_first_len > 1 AND length(pn_middle) = 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND (cand_middle = '' OR lower(pn_middle) = lower(substring(cand_middle, 1, 1)))\n",
    "    ) as pattern_2_exact_first_mid_init,\n",
    "\n",
    "    -- 3: Initials match to Full\n",
    "    (pn_first_len = 1 AND pn_middle != '' AND cand_first_len > 1 AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_3_init_mid_init,\n",
    "\n",
    "    -- 4: First Initial, Middle Initial match\n",
    "    (pn_first_len = 1 AND cand_first_len = 1 AND pn_middle != '' AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_4_first_init_mid_init,\n",
    "\n",
    "    -- 5: Exact First, Exact Last\n",
    "    (pn_first_len > 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = ''\n",
    "    ) as pattern_5_exact_first_last,\n",
    "\n",
    "    -- 6: First Initial Only to Full\n",
    "    (pn_first_len = 1 AND pn_middle = '' AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_6_first_init_to_full,\n",
    "\n",
    "    -- 7: First Initial Only\n",
    "    (pn_first_len = 1 AND cand_first_len = 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = '' AND cand_middle = ''\n",
    "    ) as pattern_7_first_init_last,\n",
    "\n",
    "    -- 8: Full Name to Initial\n",
    "    (pn_first_len > 1 AND cand_first_len = 1\n",
    "     AND lower(substring(parsed_name.first, 1, 1)) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_8_full_to_init\n",
    "\n",
    "  FROM with_match_signals\n",
    "),\n",
    "\n",
    "with_any_name_match AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    (pattern_1_exact_full OR pattern_2_exact_first_mid_init OR pattern_3_init_mid_init OR \n",
    "     pattern_4_first_init_mid_init OR pattern_5_exact_first_last OR pattern_6_first_init_to_full OR \n",
    "     pattern_7_first_init_last OR pattern_8_full_to_init) as any_name_match\n",
    "  FROM with_name_matches\n",
    "),\n",
    "\n",
    "aggregated_counts AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    author_sequence,\n",
    "    raw_author_name,\n",
    "    block_key,\n",
    "    institution_ids,\n",
    "    parsed_name,\n",
    "    work_source_ids,\n",
    "    \n",
    "    -- STRATEGY 1: Name Only (Unique)\n",
    "    count_if(pattern_1_exact_full) AS s1_n1, count_if(pattern_2_exact_first_mid_init) AS s1_n2,\n",
    "    count_if(pattern_3_init_mid_init) AS s1_n3, count_if(pattern_4_first_init_mid_init) AS s1_n4,\n",
    "    count_if(pattern_5_exact_first_last) AS s1_n5, count_if(pattern_6_first_init_to_full) AS s1_n6,\n",
    "    count_if(pattern_7_first_init_last) AS s1_n7, count_if(pattern_8_full_to_init) AS s1_n8,\n",
    "    \n",
    "    -- STRATEGY 2: Name + Institution\n",
    "    count_if(pattern_1_exact_full AND has_inst) AS s2_n1, count_if(pattern_2_exact_first_mid_init AND has_inst) AS s2_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_inst) AS s2_n3, count_if(pattern_4_first_init_mid_init AND has_inst) AS s2_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst) AS s2_n5, count_if(pattern_6_first_init_to_full AND has_inst) AS s2_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst) AS s2_n7, count_if(pattern_8_full_to_init AND has_inst) AS s2_n8,\n",
    "\n",
    "    -- STRATEGY 6: Name + Inst + Source\n",
    "    count_if(pattern_1_exact_full AND has_inst AND has_source) AS s6_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst AND has_source) AS s6_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst AND has_source) AS s6_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst AND has_source) AS s6_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst AND has_source) AS s6_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst AND has_source) AS s6_n8,\n",
    "\n",
    "    -- STRATEGY 4: Name + Inst + Topic\n",
    "    count_if(pattern_1_exact_full AND has_inst AND has_topic) AS s4_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst AND has_topic) AS s4_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst AND has_topic) AS s4_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst AND has_topic) AS s4_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst AND has_topic) AS s4_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst AND has_topic) AS s4_n8,\n",
    "\n",
    "    -- STRATEGY 5: Name + Source\n",
    "    count_if(pattern_1_exact_full AND has_source) AS s5_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_source) AS s5_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_source) AS s5_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_source) AS s5_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_source) AS s5_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_source) AS s5_n8,\n",
    "\n",
    "    -- STRATEGY 3: Name + Topic (STRICT)\n",
    "    count_if(pattern_1_exact_full AND has_topic) AS s3_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_topic) AS s3_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_topic) AS s3_n5,\n",
    "    \n",
    "    -- CAPTURE MATCHED OBJECTS (Same as before)\n",
    "    MAX(CASE WHEN pattern_1_exact_full THEN candidate_obj END) AS match_s1_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init THEN candidate_obj END) AS match_s1_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last THEN candidate_obj END) AS match_s1_n5,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst THEN candidate_obj END) AS match_s2_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst THEN candidate_obj END) AS match_s2_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst THEN candidate_obj END) AS match_s2_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst THEN candidate_obj END) AS match_s2_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst THEN candidate_obj END) AS match_s2_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_source THEN candidate_obj END) AS match_s5_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_source THEN candidate_obj END) AS match_s5_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_source THEN candidate_obj END) AS match_s5_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_source THEN candidate_obj END) AS match_s5_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_source THEN candidate_obj END) AS match_s5_n8,\n",
    "    \n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_topic THEN candidate_obj END) AS match_s3_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_topic THEN candidate_obj END) AS match_s3_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_topic THEN candidate_obj END) AS match_s3_n5,\n",
    "    \n",
    "    COUNT(*) AS total_candidates_in_block,\n",
    "    COUNT_IF(any_name_match) AS total_name_matches\n",
    "\n",
    "  FROM with_any_name_match\n",
    "  GROUP BY work_id, author_sequence, raw_author_name, block_key, institution_ids, parsed_name, work_source_ids\n",
    "),\n",
    "\n",
    "final_decision AS (\n",
    "SELECT\n",
    "  work_id,\n",
    "  author_sequence,\n",
    "  block_key,\n",
    "  raw_author_name,\n",
    "  institution_ids,\n",
    "  parsed_name,\n",
    "  work_source_ids,\n",
    "  \n",
    "  -- MATCH OUTCOME\n",
    "  CASE \n",
    "    WHEN (\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      s6_n1=1 OR s6_n2=1 OR s6_n5=1 OR s6_n6=1 OR s6_n8=1 OR\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n5=1 OR s2_n6=1 OR s2_n8=1 OR\n",
    "      s4_n1=1 OR s4_n2=1 OR s4_n5=1 OR s4_n6=1 OR s4_n8=1 OR\n",
    "      s5_n1=1 OR s5_n2=1 OR s5_n5=1 OR s5_n6=1 OR s5_n8=1 OR\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    ) THEN 'MATCHED'\n",
    "    WHEN total_candidates_in_block = 0 THEN 'NO_CANDIDATES'\n",
    "    ELSE 'AMBIGUOUS'\n",
    "  END AS match_outcome,\n",
    "\n",
    "  -- MATCHED AUTHOR ID\n",
    "  CASE \n",
    "    WHEN s1_n1 = 1 THEN match_s1_n1.id\n",
    "    WHEN s1_n2 = 1 THEN match_s1_n2.id\n",
    "    WHEN s1_n5 = 1 THEN match_s1_n5.id\n",
    "    \n",
    "    WHEN s6_n1 = 1 THEN match_s6_n1.id\n",
    "    WHEN s6_n2 = 1 THEN match_s6_n2.id\n",
    "    WHEN s6_n5 = 1 THEN match_s6_n5.id\n",
    "    WHEN s6_n6 = 1 THEN match_s6_n6.id\n",
    "    WHEN s6_n8 = 1 THEN match_s6_n8.id\n",
    "\n",
    "    WHEN s2_n1 = 1 THEN match_s2_n1.id\n",
    "    WHEN s2_n2 = 1 THEN match_s2_n2.id\n",
    "    WHEN s2_n5 = 1 THEN match_s2_n5.id\n",
    "    WHEN s2_n6 = 1 THEN match_s2_n6.id\n",
    "    WHEN s2_n8 = 1 THEN match_s2_n8.id\n",
    "\n",
    "    WHEN s4_n1 = 1 THEN match_s4_n1.id\n",
    "    WHEN s4_n2 = 1 THEN match_s4_n2.id\n",
    "    WHEN s4_n5 = 1 THEN match_s4_n5.id\n",
    "    WHEN s4_n6 = 1 THEN match_s4_n6.id\n",
    "    WHEN s4_n8 = 1 THEN match_s4_n8.id\n",
    "\n",
    "    WHEN s5_n1 = 1 THEN match_s5_n1.id\n",
    "    WHEN s5_n2 = 1 THEN match_s5_n2.id\n",
    "    WHEN s5_n5 = 1 THEN match_s5_n5.id\n",
    "    WHEN s5_n6 = 1 THEN match_s5_n6.id\n",
    "    WHEN s5_n8 = 1 THEN match_s5_n8.id\n",
    "\n",
    "    WHEN s3_n1 = 1 THEN match_s3_n1.id\n",
    "    WHEN s3_n2 = 1 THEN match_s3_n2.id\n",
    "    WHEN s3_n5 = 1 THEN match_s3_n5.id\n",
    "\n",
    "    ELSE NULL\n",
    "  END AS existing_author_id\n",
    "\n",
    "FROM aggregated_counts\n",
    ")\n",
    "SELECT * FROM final_decision;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c7d261f-6c11-4e07-93bf-ea5b4f2db097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Cluster Unmatched & Mint New IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aeee6ee9-c9c7-46a5-8f92-2d32210564c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- A. Get the current High Water Mark\n",
    "DECLARE OR REPLACE VARIABLE max_id BIGINT;\n",
    "SET VARIABLE max_id = SELECT MAX(id) FROM openalex.authors.author_registry;\n",
    "\n",
    "-- B. Cluster and Mint\n",
    "CREATE OR REPLACE TEMPORARY VIEW new_author_creation_queue AS\n",
    "WITH unmatched_with_hash AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        raw_author_name,\n",
    "        \n",
    "        -- SINGLE CLUSTERING KEY\n",
    "        -- Combines Name + (Institutions IF present, ELSE Sources)\n",
    "        xxhash64(\n",
    "            -- Part 1: Strict Name (First + Last)\n",
    "            LOWER(CONCAT(parsed_name.first, ' ', parsed_name.last)),\n",
    "            \n",
    "            -- Part 2: Best Available Signal\n",
    "            CASE \n",
    "                WHEN SIZE(institution_ids) > 0 THEN concat_ws('|', sort_array(institution_ids))\n",
    "                ELSE concat_ws('|', sort_array(work_source_ids))\n",
    "            END\n",
    "        ) AS cluster_hash\n",
    "\n",
    "    FROM openalex.authors.pending_author_assignments\n",
    "    WHERE match_outcome <> 'MATCHED'\n",
    "      -- Safety check for names\n",
    "      AND parsed_name.first IS NOT NULL AND parsed_name.first <> ''\n",
    "      AND parsed_name.last IS NOT NULL AND parsed_name.last <> ''\n",
    "),\n",
    "unique_clusters AS (\n",
    "    SELECT \n",
    "        cluster_hash,\n",
    "        -- Pick the longest name as the display name\n",
    "        MIN_BY(raw_author_name, length(raw_author_name)) as display_name,\n",
    "        -- Generate a batch ID\n",
    "        monotonically_increasing_id() as batch_row_id\n",
    "    FROM unmatched_with_hash\n",
    "    GROUP BY cluster_hash\n",
    ")\n",
    "SELECT \n",
    "    uc.cluster_hash,\n",
    "    uc.display_name,\n",
    "    -- MINTING\n",
    "    max_id + ROW_NUMBER() OVER (ORDER BY uc.batch_row_id) AS new_author_id\n",
    "FROM unique_clusters uc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "653b16ff-9de8-4a4b-a0ce-a41b7d0672c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 4: Write New Authors to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3687e7e2-f771-43ef-905c-bf799348da27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INSERT INTO openalex.authors.author_registry \n",
    "    (id, display_name, merge_into_id, merge_into_date, created_date, updated_date)\n",
    "SELECT \n",
    "    new_author_id AS id,\n",
    "    display_name,\n",
    "    NULL AS merge_into_id,\n",
    "    NULL AS merge_into_date,\n",
    "    current_timestamp() AS created_date,\n",
    "    current_timestamp() AS updated_date,\n",
    "FROM new_author_creation_queue;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce1f0b9f-3852-4544-8b8c-f56396a77d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 5: Consolidate Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a9b5447-f064-4fdb-a51f-c7b9b4531be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMPORARY VIEW batch_author_decisions AS\n",
    "SELECT \n",
    "    pa.work_id,\n",
    "    pa.author_sequence,\n",
    "    -- LOGIC: If matched, use existing ID. If unmatched, use the newly minted ID.\n",
    "    COALESCE(q.new_author_id, pa.existing_author_id) AS final_author_id\n",
    "FROM openalex.authors.pending_author_assignments pa\n",
    "LEFT JOIN new_author_creation_queue q\n",
    "    ON pa.match_outcome <> 'MATCHED'\n",
    "    -- REPLICATE THE SINGLE HASH LOGIC\n",
    "    AND xxhash64(\n",
    "            LOWER(CONCAT(pa.parsed_name.first, ' ', pa.parsed_name.last)),\n",
    "            CASE \n",
    "                WHEN SIZE(pa.institution_ids) > 0 THEN concat_ws('|', sort_array(pa.institution_ids))\n",
    "                ELSE concat_ws('|', sort_array(pa.work_source_ids))\n",
    "            END\n",
    "        ) = q.cluster_hash;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fe45ea0-50d1-45b5-93cc-bc0a81f86a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 6: Update Mapping Table (author_institutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44bd7537-582f-458c-bbe0-3ca6add0b412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO openalex.authors.author_institutions AS target\n",
    "USING (\n",
    "    -- Join Physical Data (Staged) + Decisions\n",
    "    SELECT \n",
    "        raw.work_id,\n",
    "        raw.author_sequence,\n",
    "        -- HERE is where we generate the physical rows for the bridge table\n",
    "        explode_outer(raw.all_institution_ids) AS single_institution_id,\n",
    "        raw.raw_author_name,\n",
    "        raw.raw_countries,\n",
    "        decisions.final_author_id\n",
    "    FROM batch_staged_data raw\n",
    "    INNER JOIN batch_author_decisions decisions\n",
    "        ON raw.work_id = decisions.work_id \n",
    "        AND raw.author_sequence = decisions.author_sequence\n",
    ") AS source\n",
    "ON target.work_id = source.work_id \n",
    "   AND target.author_sequence = source.author_sequence\n",
    "   -- Handle NULL institution_id for authors with no affiliations\n",
    "   AND NVL(target.institution_id, -1) = NVL(source.single_institution_id, -1)\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET \n",
    "        target.author_id = source.final_author_id,\n",
    "        target.raw_countries = source.raw_countries\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (work_id, author_sequence, institution_id, author_id, raw_author_name, raw_countries)\n",
    "    VALUES (source.work_id, source.author_sequence, source.single_institution_id, source.final_author_id, source.raw_author_name, source.raw_countries);"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AND",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "9e92974b-a347-4d7c-a4f4-58daf96627f8",
     "typedWidgetInfo": {
      "autoCreated": true,
      "defaultValue": "",
      "label": null,
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": true,
       "validationRegex": null
      }
     }
    },
    "max_updated_date": {
     "currentValue": "",
     "nuid": "a56e0bc4-0c9c-4021-8122-788a22da59e1",
     "typedWidgetInfo": {
      "autoCreated": true,
      "defaultValue": "",
      "label": null,
      "name": "max_updated_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "max_updated_date",
      "options": {
       "widgetType": "text",
       "autoCreated": true,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
