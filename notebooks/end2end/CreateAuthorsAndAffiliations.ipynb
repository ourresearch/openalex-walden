{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f681e42-5af8-49f0-8da4-e8d25166d569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creates `openalex.works.authors_and_affiliations` in Walden End to End workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0cbdbe5-a902-4903-8911-231603ef4bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE max_updated_date TIMESTAMP DEFAULT to_timestamp('1900-01-01');\n",
    "SET VARIABLE max_updated_date = COALESCE((SELECT MAX(updated_datetime) FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations')), to_timestamp('1900-01-01'));\n",
    "SELECT max_updated_date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43adc5be-230d-44d3-bc18-755cd42e3ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Step 1: Create updates table directly (combined stage1 + updates)\n",
    "CREATE OR REPLACE TABLE identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "CLUSTER BY (work_id) AS (\n",
    "WITH deduplicated_works AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        authors,\n",
    "        openalex_updated_dt AS updated_datetime,\n",
    "        GET(authors.affiliations.name, 0) IS NOT NULL AS affiliations_exist,\n",
    "        EXISTS(authors.is_corresponding, x -> x = TRUE) AS is_corresponding_exists,\n",
    "        array_size(authors) AS author_count\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.locations_mapped')\n",
    "    LEFT JOIN openalex.system.priority_table USING (provenance)\n",
    "    WHERE authors_exist\n",
    "      AND openalex_updated_dt > max_updated_date\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY work_id ORDER BY priority ASC) = 1\n",
    "),\n",
    "exploded_authors AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        updated_datetime,\n",
    "        author_count,\n",
    "        affiliations_exist,\n",
    "        is_corresponding_exists,\n",
    "        posexplode(authors) AS (original_author_order, author_data),\n",
    "        TRIM(author_data.name) AS raw_author_name_trimmed\n",
    "    FROM deduplicated_works\n",
    "),\n",
    "enriched_authors AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        updated_datetime,\n",
    "        original_author_order,\n",
    "        author_count,\n",
    "        raw_author_name_trimmed AS raw_author_name,\n",
    "        author_data.affiliations.name AS raw_affiliation_strings,\n",
    "        author_data.is_corresponding AS is_corresponding_from_source,\n",
    "        is_corresponding_exists,\n",
    "        pn.parsed_name\n",
    "    FROM exploded_authors\n",
    "    LEFT JOIN identifier('openalex' || :env_suffix || '.authors.parsed_names_lookup') pn\n",
    "        ON exploded_authors.raw_author_name_trimmed = pn.raw_author_name\n",
    "),\n",
    "merged_duplicates AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        FIRST(updated_datetime) AS updated_datetime,\n",
    "        original_author_order,\n",
    "        author_count,\n",
    "        MIN_BY(raw_author_name, original_author_order) AS raw_author_name,\n",
    "        MIN_BY(parsed_name, original_author_order) AS parsed_name,\n",
    "        MAX_BY(is_corresponding_from_source, original_author_order) AS is_corresponding_from_source,\n",
    "        FIRST(is_corresponding_exists, true) AS is_corresponding_exists,\n",
    "        ARRAY_DISTINCT(\n",
    "            TRANSFORM(\n",
    "                ARRAY_COMPACT(FLATTEN(COLLECT_LIST(raw_affiliation_strings))),\n",
    "                s -> TRIM(REPLACE(s, '\\\\n', ''))\n",
    "            )\n",
    "        ) AS raw_affiliation_strings,\n",
    "        -- Compute work_has_corresponding directly using window function on grouped data\n",
    "        CASE\n",
    "            WHEN FIRST(is_corresponding_exists, true) THEN\n",
    "                MAX(CASE WHEN MAX_BY(is_corresponding_from_source, original_author_order) = TRUE THEN 1 ELSE 0 END) \n",
    "                    OVER (PARTITION BY work_id)\n",
    "            ELSE 0\n",
    "        END AS work_has_corresponding\n",
    "    FROM enriched_authors\n",
    "    GROUP BY work_id, original_author_order, author_count\n",
    ")\n",
    "SELECT\n",
    "    work_id,\n",
    "    updated_datetime,\n",
    "    TRANSFORM(\n",
    "        ARRAY_SORT(\n",
    "            COLLECT_LIST(\n",
    "                STRUCT(\n",
    "                    original_author_order,\n",
    "                    STRUCT(\n",
    "                        CASE\n",
    "                            WHEN original_author_order == 0 THEN 'first'\n",
    "                            WHEN original_author_order + 1 == author_count THEN 'last'\n",
    "                            ELSE 'middle'\n",
    "                        END AS author_position,\n",
    "                        TRIM(REPLACE(raw_author_name, '\\\\n', '')) AS raw_author_name,\n",
    "                        parsed_name,\n",
    "                        CASE\n",
    "                            WHEN is_corresponding_from_source = TRUE THEN TRUE\n",
    "                            WHEN work_has_corresponding = 1 THEN FALSE\n",
    "                            WHEN original_author_order == 0 THEN TRUE\n",
    "                            ELSE FALSE\n",
    "                        END AS is_corresponding,\n",
    "                        raw_affiliation_strings,\n",
    "                        original_author_order,\n",
    "                        NAMED_STRUCT(\n",
    "                            'id', CAST(NULL AS STRING), \n",
    "                            -- Fallback to raw name\n",
    "                            'display_name', TRIM(REPLACE(raw_author_name, '\\\\n', '')),\n",
    "                            'orcid', CAST(NULL AS STRING)\n",
    "                        ) AS author\n",
    "                    ) AS authorship\n",
    "                )\n",
    "            ),\n",
    "            (left, right) -> CASE\n",
    "                WHEN left.original_author_order < right.original_author_order THEN -1\n",
    "                WHEN left.original_author_order > right.original_author_order THEN 1\n",
    "                ELSE 0\n",
    "            END\n",
    "        ),\n",
    "        x -> x.authorship\n",
    "    ) AS authorships\n",
    "FROM merged_duplicates\n",
    "GROUP BY work_id, updated_datetime);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "929646c6-f824-4153-8af7-a36b5b12b2a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Merge new affiliation strings into `affiliation_strings_lookup` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc19b6c-9cdd-4547-9461-e75d6023af77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Step 2: Merge new raw affiliation strings into lookup table\n",
    "MERGE INTO openalex.institutions.affiliation_strings_lookup AS target\n",
    "USING (\n",
    "    WITH new_affiliation_strings AS (\n",
    "        SELECT DISTINCT\n",
    "            affiliation_string AS raw_affiliation_string\n",
    "        FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "        LATERAL VIEW explode(authorships) AS authorship\n",
    "        LATERAL VIEW explode(authorship.raw_affiliation_strings) AS affiliation_string\n",
    "        WHERE affiliation_string IS NOT NULL \n",
    "          AND affiliation_string != \"\"\n",
    "    )\n",
    "    SELECT \n",
    "        nas.raw_affiliation_string,\n",
    "        CAST(NULL AS ARRAY<BIGINT>) AS institution_ids,\n",
    "        CAST(NULL AS ARRAY<BIGINT>) AS institution_ids_override,\n",
    "        CURRENT_TIMESTAMP() AS created_datetime\n",
    "    FROM new_affiliation_strings nas\n",
    "    LEFT ANTI JOIN openalex.institutions.affiliation_strings_lookup existing\n",
    "        ON nas.raw_affiliation_string = existing.raw_affiliation_string\n",
    ") AS source\n",
    "ON target.raw_affiliation_string = source.raw_affiliation_string\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (raw_affiliation_string, institution_ids, institution_ids_override, created_datetime)\n",
    "    VALUES (source.raw_affiliation_string, source.institution_ids, source.institution_ids_override, source.created_datetime);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d36b9d02-a4a3-45c5-ae81-56a0f472e75e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create and populate `openalex.authors.author_institutions` mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bab625e-8c90-483c-85d8-588ddabf8500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Step 3: author_institutions mapping\n",
    "\n",
    "-- Execute merge - explode from updates table\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.authors.author_institutions') AS target\n",
    "USING (\n",
    "    WITH exploded_authors AS (\n",
    "        SELECT \n",
    "            work_id,\n",
    "            posexplode(authorships) AS (author_sequence, authorship)\n",
    "        FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "    ),\n",
    "    exploded_affiliations AS (\n",
    "        SELECT \n",
    "            work_id,\n",
    "            author_sequence,\n",
    "            authorship.raw_author_name,\n",
    "            explode_outer(authorship.raw_affiliation_strings) AS raw_affiliation_string\n",
    "        FROM exploded_authors\n",
    "    ),\n",
    "    \n",
    "    with_institutions AS (\n",
    "        SELECT \n",
    "            ea.work_id,\n",
    "            ea.author_sequence,\n",
    "            ea.raw_author_name,\n",
    "            ea.raw_affiliation_string,\n",
    "            asl.countries as raw_countries,\n",
    "            CASE \n",
    "                WHEN ea.raw_affiliation_string IS NULL THEN NULL\n",
    "                WHEN asl.institution_ids_override IS NOT NULL AND SIZE(asl.institution_ids_override) > 0 \n",
    "                    THEN asl.institution_ids_override\n",
    "                WHEN asl.institution_ids IS NOT NULL AND SIZE(asl.institution_ids) > 0 \n",
    "                    AND NOT (SIZE(asl.institution_ids) = 1 AND asl.institution_ids[0] = -1) \n",
    "                    THEN asl.institution_ids\n",
    "                ELSE NULL\n",
    "            END AS institution_ids\n",
    "        FROM exploded_affiliations ea\n",
    "        LEFT JOIN openalex.institutions.affiliation_strings_lookup asl\n",
    "            ON ea.raw_affiliation_string = asl.raw_affiliation_string\n",
    "            AND ea.raw_affiliation_string IS NOT NULL\n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        explode_outer(institution_ids) AS institution_id,\n",
    "        raw_author_name,\n",
    "        raw_affiliation_string,\n",
    "        raw_countries\n",
    "    FROM with_institutions\n",
    "    WHERE institution_ids IS NOT NULL AND SIZE(institution_ids) > 0\n",
    ") AS source\n",
    "ON target.work_id = source.work_id \n",
    "   AND target.author_sequence = source.author_sequence \n",
    "   AND NVL(target.institution_id, -1) = NVL(source.institution_id, -1)\n",
    "   AND NVL(target.raw_affiliation_string, '') = NVL(source.raw_affiliation_string, '')\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (work_id, author_sequence, institution_id, raw_author_name, raw_affiliation_string, raw_countries)\n",
    "    VALUES (source.work_id, source.author_sequence, source.institution_id, \n",
    "            source.raw_author_name, source.raw_affiliation_string, source.raw_countries);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f2ba9cf-1ad7-433f-ba67-54f1afe9cc8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Add institutions arrays to authorships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3370ea-47e6-4adc-8c20-e77faeddaaa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f58bd9ca-a7be-4cff-b5cb-b7b4a0a571ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Step 4: Enrich updates with full institution details using array operations (no explode!)\n",
    "CREATE OR REPLACE TABLE identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "CLUSTER BY (work_id) AS (\n",
    "WITH base_authorships AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        updated_datetime,\n",
    "        authorships\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "),\n",
    "institution_lineage AS (\n",
    "  SELECT\n",
    "    institution_id,\n",
    "    COLLECT_LIST(ancestor_id) AS lineage_ids\n",
    "  FROM openalex.mid.institution_ancestors\n",
    "  WHERE NOT ARRAY_CONTAINS(SUPER_SYSTEM_INSTITUTIONS, ancestor_id)\n",
    "  GROUP BY institution_id\n",
    "),\n",
    "author_institutions_with_details AS (\n",
    "    SELECT\n",
    "        ai.work_id,\n",
    "        ai.author_sequence,\n",
    "        array_distinct(flatten(collect_set(ai.raw_countries))) as raw_parsed_countries,\n",
    "        COLLECT_SET(\n",
    "            STRUCT(\n",
    "                inst.iso3166_code as country_code,\n",
    "                inst.display_name,\n",
    "                CONCAT('https://openalex.org/I', ai.institution_id) AS id,\n",
    "                ARRAY_SORT(\n",
    "                    TRANSFORM(\n",
    "                    ARRAY_COMPACT(CONCAT(ARRAY(ai.institution_id), COALESCE(il.lineage_ids, ARRAY()))), id -> CONCAT('https://openalex.org/I', id)\n",
    "                    )\n",
    "                ) AS lineage,\n",
    "                CASE \n",
    "                    WHEN inst.ror_id IS NULL THEN NULL\n",
    "                    WHEN inst.ror_id LIKE 'https://ror.org/%' THEN inst.ror_id\n",
    "                    ELSE CONCAT('https://ror.org/', inst.ror_id) \n",
    "                END AS ror,\n",
    "                inst.type--,\n",
    "                --CAST(ARRAY(inst.type) as array<string>) as type_list -- no longer a wanted attribute\n",
    "            )\n",
    "        ) AS institutions\n",
    "    FROM identifier('openalex' || :env_suffix || '.authors.author_institutions') ai\n",
    "    LEFT JOIN openalex.institutions.institutions inst ON inst.id = ai.institution_id\n",
    "    LEFT JOIN institution_lineage il USING (institution_id)\n",
    "    WHERE ai.institution_id IS NOT NULL\n",
    "    GROUP BY ai.work_id, ai.author_sequence\n",
    "),\n",
    "-- Map raw_affiliation_string -> institution_ids per (work_id, author_sequence)\n",
    "affiliations_map_ids AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        raw_affiliation_string,\n",
    "        array_distinct(\n",
    "            array_compact(\n",
    "                COLLECT_LIST(CONCAT('https://openalex.org/I', institution_id))\n",
    "            )\n",
    "        ) AS institution_ids\n",
    "    FROM identifier('openalex' || :env_suffix || '.authors.author_institutions')\n",
    "    WHERE institution_id IS NOT NULL\n",
    "      AND raw_affiliation_string IS NOT NULL\n",
    "    GROUP BY work_id, author_sequence, raw_affiliation_string\n",
    "),\n",
    "affiliations_map AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        MAP_FROM_ENTRIES(\n",
    "            COLLECT_LIST(NAMED_STRUCT('key', raw_affiliation_string, 'value', institution_ids))\n",
    "        ) AS aff_map\n",
    "    FROM affiliations_map_ids\n",
    "    GROUP BY work_id, author_sequence\n",
    "),\n",
    "-- Pre-aggregate institution details per work_id as a map[author_sequence -> details]\n",
    "author_institution_lookup AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        MAP_FROM_ENTRIES(\n",
    "            COLLECT_LIST(\n",
    "                STRUCT(\n",
    "                    author_sequence,\n",
    "                    STRUCT(\n",
    "                        institutions,\n",
    "                        raw_parsed_countries,\n",
    "                        aff_map\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ) as author_lookup\n",
    "    FROM (\n",
    "        SELECT\n",
    "            aid.work_id,\n",
    "            aid.author_sequence,\n",
    "            aid.institutions,\n",
    "            aid.raw_parsed_countries,\n",
    "            am.aff_map\n",
    "        FROM author_institutions_with_details aid\n",
    "        LEFT JOIN affiliations_map am ON aid.work_id = am.work_id AND aid.author_sequence = am.author_sequence\n",
    "    )\n",
    "    GROUP BY work_id\n",
    ")\n",
    "SELECT\n",
    "    ba.work_id,\n",
    "    ba.updated_datetime,\n",
    "    -- Use TRANSFORM to enrich each authorship in-place, no explode/re-aggregate!\n",
    "    TRANSFORM(\n",
    "        ba.authorships,\n",
    "        (auth, idx) -> STRUCT(\n",
    "            -- affiliations: map raw_affiliation_strings to institution_ids\n",
    "            TRANSFORM(\n",
    "                COALESCE(auth.raw_affiliation_strings, ARRAY()),\n",
    "                s -> STRUCT(\n",
    "                    COALESCE(element_at(element_at(ail.author_lookup, idx).aff_map, s), ARRAY()) as institution_ids,\n",
    "                    s as raw_affiliation_string\n",
    "                )\n",
    "            ) as affiliations,\n",
    "            -- Preserve author field\n",
    "            auth.author,\n",
    "            -- All other fields\n",
    "            auth.author_position,\n",
    "            auth.original_author_order AS author_order_number,\n",
    "            -- countries from institutions\n",
    "            CASE\n",
    "                WHEN element_at(ail.author_lookup, idx).institutions IS NOT NULL \n",
    "                     AND size(FILTER(element_at(ail.author_lookup, idx).institutions.country_code, c -> c IS NOT NULL AND c <> '')) > 0\n",
    "                    THEN array_sort(array_distinct(FILTER(element_at(ail.author_lookup, idx).institutions.country_code, c -> c IS NOT NULL AND c <> '')))\n",
    "                WHEN element_at(ail.author_lookup, idx).raw_parsed_countries IS NOT NULL\n",
    "                    THEN element_at(ail.author_lookup, idx).raw_parsed_countries\n",
    "                ELSE ARRAY()\n",
    "            END AS countries,\n",
    "            COALESCE(element_at(ail.author_lookup, idx).institutions, ARRAY()) AS institutions,\n",
    "            auth.is_corresponding,\n",
    "            auth.parsed_name,\n",
    "            auth.raw_affiliation_strings,\n",
    "            auth.raw_author_name\n",
    "        )\n",
    "    ) AS authorships\n",
    "FROM base_authorships ba\n",
    "LEFT JOIN author_institution_lookup ail ON ba.work_id = ail.work_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c75774-c622-4b11-b2c6-755fa04f17f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Assign author IDs - diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67b96a37-cdbf-4312-8f2e-5bbce0669812",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765574038712}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------\n",
    "-- AUTHOR MATCHING ALGORITHM - DIAGNOSTIC TABLE\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "CREATE OR REPLACE TABLE openalex.authors.author_matching_diagnostics AS\n",
    "\n",
    "WITH with_topics AS (\n",
    "  SELECT\n",
    "    aa.work_id,\n",
    "    aa.authorships,\n",
    "    coalesce(wtf.topics, array()) as topics\n",
    "  FROM openalex.works.authors_and_affiliations_updates aa\n",
    "  LEFT JOIN openalex.works.work_topics_frontfill wtf\n",
    "    ON aa.work_id = wtf.work_id\n",
    "),\n",
    "\n",
    "authors_exploded AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    authorship.author.display_name,\n",
    "    authorship.parsed_name,\n",
    "    lower(concat(substring(authorship.parsed_name.first, 1, 1), ' ', authorship.parsed_name.last)) as block_key,\n",
    "    array_distinct(\n",
    "      concat(\n",
    "        transform(authorship.institutions, i -> i.id),\n",
    "        flatten(transform(authorship.institutions, i -> i.lineage))\n",
    "      )\n",
    "    ) as institution_ids,\n",
    "    transform(topics, t -> t.id) as topic_ids,\n",
    "    transform(topics, t -> t.subfield.id) as subfield_ids\n",
    "  FROM with_topics\n",
    "  LATERAL VIEW explode(authorships) AS authorship\n",
    "  WHERE work_id > 7000000000\n",
    "),\n",
    "\n",
    "blocked_candidates AS (\n",
    "  SELECT \n",
    "    e.work_id,\n",
    "    e.display_name,\n",
    "    e.parsed_name,\n",
    "    e.block_key,\n",
    "    e.institution_ids,\n",
    "    e.topic_ids,\n",
    "    e.subfield_ids,\n",
    "    alm.author_id,\n",
    "    alm.parsed_longest_name,\n",
    "    alm.institution_ids as candidate_institution_ids,\n",
    "    alm.topic_ids as candidate_topic_ids,\n",
    "    alm.subfield_ids as candidate_subfield_ids,\n",
    "    alm.works_count\n",
    "  FROM authors_exploded e\n",
    "  JOIN openalex.authors.author_lookup_mapping alm\n",
    "    ON alm.block_key = e.block_key\n",
    "),\n",
    "\n",
    "with_match_signals AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    length(parsed_name.first) as pn_first_len,\n",
    "    length(parsed_longest_name.first) as cand_first_len,\n",
    "    coalesce(parsed_name.middle, '') as pn_middle,\n",
    "    coalesce(parsed_longest_name.middle, '') as cand_middle,\n",
    "    \n",
    "    (size(institution_ids) > 0 AND size(candidate_institution_ids) > 0 \n",
    "     AND arrays_overlap(candidate_institution_ids, institution_ids)) as has_inst,\n",
    "    \n",
    "    (size(topic_ids) > 0 AND size(candidate_topic_ids) > 0 \n",
    "     AND arrays_overlap(candidate_topic_ids, topic_ids)) as has_topic,\n",
    "\n",
    "    (size(subfield_ids) > 0 AND size(candidate_subfield_ids) > 0 \n",
    "     AND arrays_overlap(candidate_subfield_ids, subfield_ids)) as has_subfield\n",
    "  FROM blocked_candidates\n",
    "),\n",
    "\n",
    "with_name_matches AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- 1: Exact Full Name (Exact First, Exact Middle, Exact Last)\n",
    "    (pn_first_len > 1 AND length(pn_middle) > 1 AND cand_first_len > 1 AND length(cand_middle) > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(pn_middle) = lower(cand_middle)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_1_exact_full,\n",
    "\n",
    "    -- 2: Exact First, Middle Initial match, Exact Last\n",
    "    (pn_first_len > 1 AND length(pn_middle) = 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND (cand_middle = '' OR lower(pn_middle) = lower(substring(cand_middle, 1, 1)))\n",
    "    ) as pattern_2_exact_first_mid_init,\n",
    "\n",
    "    -- 3: Initials match to Full (First Init, Mid Init, Exact Last)\n",
    "    (pn_first_len = 1 AND pn_middle != '' AND cand_first_len > 1 AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_3_init_mid_init,\n",
    "\n",
    "    -- 4: First Initial, Middle Initial match, Exact Last\n",
    "    (pn_first_len = 1 AND cand_first_len = 1 AND pn_middle != '' AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_4_first_init_mid_init,\n",
    "\n",
    "    -- 5: Exact First, Exact Last (No Middle info)\n",
    "    (pn_first_len > 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = ''\n",
    "    ) as pattern_5_exact_first_last,\n",
    "\n",
    "    -- 6: First Initial Only to Full, Exact Last\n",
    "    (pn_first_len = 1 AND pn_middle = '' AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_6_first_init_to_full,\n",
    "\n",
    "    -- 7: First Initial Only, Exact Last (Both sides)\n",
    "    (pn_first_len = 1 AND cand_first_len = 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = '' AND cand_middle = ''\n",
    "    ) as pattern_7_first_init_last,\n",
    "\n",
    "    -- 8: Full Name to Initial, Exact Last (Reverse of 6)\n",
    "    (pn_first_len > 1 AND cand_first_len = 1\n",
    "     AND lower(substring(parsed_name.first, 1, 1)) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_8_full_to_init\n",
    "\n",
    "  FROM with_match_signals\n",
    "),\n",
    "\n",
    "with_any_name_match AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    (pattern_1_exact_full OR pattern_2_exact_first_mid_init OR pattern_3_init_mid_init OR \n",
    "     pattern_4_first_init_mid_init OR pattern_5_exact_first_last OR pattern_6_first_init_to_full OR \n",
    "     pattern_7_first_init_last OR pattern_8_full_to_init) as any_name_match\n",
    "  FROM with_name_matches\n",
    "),\n",
    "\n",
    "aggregated_counts AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    display_name,\n",
    "    block_key,\n",
    "    \n",
    "    -- Counts for \"Unique Name\" strategy (Strategy 1)\n",
    "    count_if(pattern_1_exact_full) as s1_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init) as s1_n2,\n",
    "    count_if(pattern_3_init_mid_init) as s1_n3,\n",
    "    count_if(pattern_4_first_init_mid_init) as s1_n4,\n",
    "    count_if(pattern_5_exact_first_last) as s1_n5,\n",
    "    count_if(pattern_6_first_init_to_full) as s1_n6,\n",
    "    count_if(pattern_7_first_init_last) as s1_n7,\n",
    "    count_if(pattern_8_full_to_init) as s1_n8,\n",
    "    \n",
    "    -- Counts for \"Resolved by Inst\" strategy (Strategy 2)\n",
    "    count_if(pattern_1_exact_full AND has_inst) as s2_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst) as s2_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_inst) as s2_n3,\n",
    "    count_if(pattern_4_first_init_mid_init AND has_inst) as s2_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst) as s2_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst) as s2_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst) as s2_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst) as s2_n8,\n",
    "\n",
    "    -- Counts for \"Resolved by Topic\" strategy (Strategy 3)\n",
    "    count_if(pattern_1_exact_full AND has_topic) as s3_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_topic) as s3_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_topic) as s3_n3,\n",
    "    count_if(pattern_4_first_init_mid_init AND has_topic) as s3_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_topic) as s3_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_topic) as s3_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_topic) as s3_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_topic) as s3_n8,\n",
    "\n",
    "    -- Capture Author IDs\n",
    "    max(CASE WHEN pattern_1_exact_full THEN author_id END) as id_s1_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init THEN author_id END) as id_s1_n2,\n",
    "    max(CASE WHEN pattern_3_init_mid_init THEN author_id END) as id_s1_n3,\n",
    "    max(CASE WHEN pattern_4_first_init_mid_init THEN author_id END) as id_s1_n4,\n",
    "    max(CASE WHEN pattern_5_exact_first_last THEN author_id END) as id_s1_n5,\n",
    "    max(CASE WHEN pattern_6_first_init_to_full THEN author_id END) as id_s1_n6,\n",
    "    max(CASE WHEN pattern_7_first_init_last THEN author_id END) as id_s1_n7,\n",
    "    max(CASE WHEN pattern_8_full_to_init THEN author_id END) as id_s1_n8,\n",
    "\n",
    "    max(CASE WHEN pattern_1_exact_full AND has_inst THEN author_id END) as id_s2_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init AND has_inst THEN author_id END) as id_s2_n2,\n",
    "    max(CASE WHEN pattern_3_init_mid_init AND has_inst THEN author_id END) as id_s2_n3,\n",
    "    max(CASE WHEN pattern_4_first_init_mid_init AND has_inst THEN author_id END) as id_s2_n4,\n",
    "    max(CASE WHEN pattern_5_exact_first_last AND has_inst THEN author_id END) as id_s2_n5,\n",
    "    max(CASE WHEN pattern_6_first_init_to_full AND has_inst THEN author_id END) as id_s2_n6,\n",
    "    max(CASE WHEN pattern_7_first_init_last AND has_inst THEN author_id END) as id_s2_n7,\n",
    "    max(CASE WHEN pattern_8_full_to_init AND has_inst THEN author_id END) as id_s2_n8,\n",
    "    \n",
    "    max(CASE WHEN pattern_1_exact_full AND has_topic THEN author_id END) as id_s3_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init AND has_topic THEN author_id END) as id_s3_n2,\n",
    "    max(CASE WHEN pattern_5_exact_first_last AND has_topic THEN author_id END) as id_s3_n5,\n",
    "    \n",
    "    -- Diagnostics\n",
    "    count(*) as total_candidates_in_block,\n",
    "    count_if(any_name_match) as total_name_matches,\n",
    "    \n",
    "    count_if(has_inst) as total_candidates_with_inst,\n",
    "    count_if(any_name_match AND has_inst) as name_matched_candidates_with_inst,\n",
    "    \n",
    "    count_if(has_topic) as total_candidates_with_topic,\n",
    "    count_if(any_name_match AND has_topic) as name_matched_candidates_with_topic,\n",
    "    \n",
    "    max(size(institution_ids)) > 0 as work_has_inst,\n",
    "    max(size(topic_ids)) > 0 as work_has_topic,\n",
    "    \n",
    "    slice(collect_list(\n",
    "      CASE WHEN any_name_match THEN\n",
    "        named_struct(\n",
    "          'author_id', author_id,\n",
    "          'name', parsed_longest_name.first || ' ' || parsed_longest_name.last,\n",
    "          'has_inst', has_inst,\n",
    "          'has_topic', has_topic\n",
    "        )\n",
    "      END\n",
    "    ), 1, 10) as candidates_passing_name_check,\n",
    "    \n",
    "    slice(collect_list(\n",
    "      CASE WHEN NOT any_name_match THEN\n",
    "        named_struct(\n",
    "          'author_id', author_id,\n",
    "          'name', parsed_longest_name.first || ' ' || parsed_longest_name.last\n",
    "        )\n",
    "      END\n",
    "    ), 1, 5) as candidates_failing_name_check\n",
    "\n",
    "  FROM with_any_name_match\n",
    "  GROUP BY work_id, display_name, block_key\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  work_id,\n",
    "  display_name as work_author_name,\n",
    "  block_key,\n",
    "  \n",
    "  -- Determine Strategy Name\n",
    "  CASE \n",
    "    -- Strategy 1: Unique Name\n",
    "    WHEN s1_n1 = 1 THEN 'unique_exact_full_name'\n",
    "    WHEN s1_n2 = 1 THEN 'unique_exact_first_mid_init'\n",
    "    WHEN s1_n3 = 1 THEN 'unique_init_mid_init'\n",
    "    WHEN s1_n4 = 1 THEN 'unique_first_init_mid_init'\n",
    "    WHEN s1_n5 = 1 THEN 'unique_exact_first_last'\n",
    "    WHEN s1_n6 = 1 THEN 'unique_first_init_to_full'\n",
    "    WHEN s1_n7 = 1 THEN 'unique_first_init_only'\n",
    "    WHEN s1_n8 = 1 THEN 'unique_full_to_init'\n",
    "    \n",
    "    -- Strategy 2: Ambiguous Name Resolved by Institution\n",
    "    WHEN s2_n1 = 1 THEN 'exact_full_resolved_by_inst'\n",
    "    WHEN s2_n2 = 1 THEN 'exact_first_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n3 = 1 THEN 'init_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n4 = 1 THEN 'first_init_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n5 = 1 THEN 'exact_first_last_resolved_by_inst'\n",
    "    WHEN s2_n6 = 1 THEN 'first_init_to_full_resolved_by_inst'\n",
    "    WHEN s2_n7 = 1 THEN 'first_init_only_resolved_by_inst'\n",
    "    WHEN s2_n8 = 1 THEN 'full_to_init_resolved_by_inst'\n",
    "    \n",
    "    -- Strategy 3: Ambiguous Name Resolved by Topic\n",
    "    WHEN s3_n1 = 1 THEN 'exact_full_resolved_by_topic'\n",
    "    WHEN s3_n2 = 1 THEN 'exact_first_mid_init_resolved_by_topic'\n",
    "    WHEN s3_n5 = 1 THEN 'exact_first_last_resolved_by_topic'\n",
    "    \n",
    "    ELSE null\n",
    "  END as match_method,\n",
    "\n",
    "  -- Select Matched ID (Sequential Order 1-8)\n",
    "  CASE \n",
    "    -- Strategy 1 (Unique) - NOW INCLUDING WEAK PATTERNS IF UNIQUE\n",
    "    WHEN s1_n1 = 1 THEN id_s1_n1\n",
    "    WHEN s1_n2 = 1 THEN id_s1_n2\n",
    "    WHEN s1_n5 = 1 THEN id_s1_n5\n",
    "    WHEN s1_n3 = 1 THEN id_s1_n3\n",
    "    WHEN s1_n4 = 1 THEN id_s1_n4\n",
    "    WHEN s1_n6 = 1 THEN id_s1_n6\n",
    "    WHEN s1_n7 = 1 THEN id_s1_n7\n",
    "    WHEN s1_n8 = 1 THEN id_s1_n8\n",
    "    \n",
    "    -- Strategy 2 (Ambiguous -> Inst)\n",
    "    WHEN s2_n1 = 1 THEN id_s2_n1\n",
    "    WHEN s2_n2 = 1 THEN id_s2_n2\n",
    "    WHEN s2_n5 = 1 THEN id_s2_n5\n",
    "    WHEN s2_n3 = 1 THEN id_s2_n3\n",
    "    WHEN s2_n4 = 1 THEN id_s2_n4\n",
    "    WHEN s2_n6 = 1 THEN id_s2_n6\n",
    "    WHEN s2_n7 = 1 THEN id_s2_n7\n",
    "    WHEN s2_n8 = 1 THEN id_s2_n8\n",
    "    \n",
    "    -- Strategy 3 (Ambiguous -> Topic)\n",
    "    WHEN s3_n1 = 1 THEN id_s3_n1\n",
    "    WHEN s3_n2 = 1 THEN id_s3_n2\n",
    "    WHEN s3_n5 = 1 THEN id_s3_n5\n",
    "    ELSE null\n",
    "  END as matched_author_id,\n",
    "\n",
    "  -- High Level Outcome\n",
    "  CASE \n",
    "    WHEN (\n",
    "      -- Strong Unique\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      -- Weak Unique (Singleton Override)\n",
    "      s1_n3=1 OR s1_n4=1 OR s1_n6=1 OR s1_n7=1 OR s1_n8=1 OR\n",
    "      -- Resolved by Inst\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n3=1 OR s2_n4=1 OR s2_n5=1 OR s2_n6=1 OR s2_n7=1 OR s2_n8=1 OR\n",
    "      -- Resolved by Topic\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    )\n",
    "    THEN 'MATCHED'\n",
    "    WHEN total_candidates_in_block = 0 THEN 'NO_CANDIDATES'\n",
    "    ELSE 'AMBIGUOUS'\n",
    "  END as match_outcome,\n",
    "\n",
    "  -- Detailed Failure Reason\n",
    "  CASE\n",
    "    WHEN (\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      s1_n3=1 OR s1_n4=1 OR s1_n6=1 OR s1_n7=1 OR s1_n8=1 OR\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n3=1 OR s2_n4=1 OR s2_n5=1 OR s2_n6=1 OR s2_n7=1 OR s2_n8=1 OR\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    ) THEN null\n",
    "          \n",
    "    WHEN total_candidates_in_block = 0 THEN 'no_candidates_in_block'\n",
    "    WHEN total_name_matches = 0 THEN 'no_name_pattern_matched'\n",
    "    \n",
    "    WHEN total_name_matches > 1 THEN \n",
    "      CASE\n",
    "        WHEN NOT work_has_inst AND NOT work_has_topic THEN 'ambiguous_name_work_has_no_signals'\n",
    "        WHEN name_matched_candidates_with_inst = 0 AND name_matched_candidates_with_topic = 0 THEN 'ambiguous_name_no_signal_overlap'\n",
    "        WHEN name_matched_candidates_with_inst > 1 THEN 'ambiguous_name_multiple_candidates_have_inst'\n",
    "        WHEN name_matched_candidates_with_topic > 1 THEN 'ambiguous_name_multiple_candidates_have_topic'\n",
    "        ELSE 'ambiguous_other'\n",
    "      END\n",
    "    ELSE 'unknown_failure'\n",
    "  END as failure_reason,\n",
    "  \n",
    "  -- Extra context columns\n",
    "  total_candidates_in_block,\n",
    "  total_name_matches,\n",
    "  name_matched_candidates_with_inst,\n",
    "  name_matched_candidates_with_topic,\n",
    "  candidates_passing_name_check,\n",
    "  candidates_failing_name_check\n",
    "\n",
    "FROM aggregated_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6b909b-b74b-4c97-80ed-de0bf83b482c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Step 5: Merge enriched updates into final authors_and_affiliations table\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.authors_and_affiliations') AS target\n",
    "USING identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates') AS source\n",
    "ON target.work_id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.authorships = source.authorships,\n",
    "  target.updated_datetime = source.updated_datetime\n",
    "WHEN NOT MATCHED THEN INSERT (work_id, authorships, updated_datetime)\n",
    "VALUES (source.work_id, source.authorships, source.updated_datetime);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc131bf-e238-421a-a50d-be9adf3b780c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761803727429}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- SELECT * FROM openalex.works.authors_and_affiliations where work_id = 4415178126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9bf5971-a248-4b5f-b3f0-b49c237d1820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateAuthorsAndAffiliations",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "ab378cd9-0a33-46a0-bc9c-fa98464945d7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
