{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f681e42-5af8-49f0-8da4-e8d25166d569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creates `openalex.works.authors_and_affiliations` in Walden End to End workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0cbdbe5-a902-4903-8911-231603ef4bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE max_updated_date TIMESTAMP DEFAULT to_timestamp('1900-01-01');\n",
    "SET VARIABLE max_updated_date = COALESCE((SELECT MAX(updated_datetime) FROM identifier('openalex' || :env_suffix || '.works.authors_and_affiliations')), to_timestamp('1900-01-01'));\n",
    "SELECT max_updated_date;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1670d36f-ebfe-42c6-9f06-d22f26fc38b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Populate `openalex.authors.author_institutions` mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43adc5be-230d-44d3-bc18-755cd42e3ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.authors.author_institutions') AS target\n",
    "USING (\n",
    "    WITH exploded_authors AS (\n",
    "        SELECT \n",
    "            id AS work_id,\n",
    "            POSEXPLODE(authorships) AS (author_sequence, authorship)\n",
    "        FROM identifier('openalex' || :env_suffix || '.works.openalex_works_base')\n",
    "        WHERE updated_date > max_updated_date\n",
    "          AND authorships IS NOT NULL\n",
    "          AND SIZE(authorships) > 0\n",
    "    ),\n",
    "    exploded_affiliations AS (\n",
    "        SELECT \n",
    "            work_id,\n",
    "            author_sequence,\n",
    "            authorship.raw_author_name,\n",
    "            EXPLODE_OUTER(authorship.raw_affiliation_strings) AS raw_affiliation_string\n",
    "        FROM exploded_authors\n",
    "    ),\n",
    "    with_institutions AS (\n",
    "        SELECT \n",
    "            ea.work_id,\n",
    "            ea.author_sequence,\n",
    "            ea.raw_author_name,\n",
    "            ea.raw_affiliation_string,\n",
    "            asl.countries AS raw_countries,\n",
    "            CASE \n",
    "                WHEN ea.raw_affiliation_string IS NULL THEN NULL\n",
    "                WHEN asl.institution_ids_override IS NOT NULL AND SIZE(asl.institution_ids_override) > 0 \n",
    "                    THEN asl.institution_ids_override\n",
    "                WHEN asl.institution_ids IS NOT NULL AND SIZE(asl.institution_ids) > 0 \n",
    "                    AND NOT (SIZE(asl.institution_ids) = 1 AND asl.institution_ids[0] = -1) \n",
    "                    THEN asl.institution_ids\n",
    "                ELSE NULL\n",
    "            END AS institution_ids\n",
    "        FROM exploded_affiliations ea\n",
    "        LEFT JOIN openalex.institutions.affiliation_strings_lookup asl\n",
    "            ON ea.raw_affiliation_string = asl.raw_affiliation_string\n",
    "            AND ea.raw_affiliation_string IS NOT NULL\n",
    "    )\n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        EXPLODE_OUTER(institution_ids) AS institution_id,\n",
    "        raw_author_name,\n",
    "        raw_affiliation_string,\n",
    "        raw_countries\n",
    "    FROM with_institutions\n",
    "    WHERE institution_ids IS NOT NULL AND SIZE(institution_ids) > 0\n",
    ") AS source\n",
    "ON target.work_id = source.work_id \n",
    "   AND target.author_sequence = source.author_sequence \n",
    "   AND NVL(target.institution_id, -1) = NVL(source.institution_id, -1)\n",
    "   AND NVL(target.raw_affiliation_string, '') = NVL(source.raw_affiliation_string, '')\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (work_id, author_sequence, institution_id, raw_author_name, raw_affiliation_string, raw_countries)\n",
    "    VALUES (source.work_id, source.author_sequence, source.institution_id, \n",
    "            source.raw_author_name, source.raw_affiliation_string, source.raw_countries);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "836652e7-0293-45c6-a60e-04026d143301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Create enriched authorships with parsed names and institution details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac67e5b-1f6b-483a-8883-fa4a3d6ae246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30800b8d-a76d-46e2-b5c6-b94979aa8b28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates')\n",
    "CLUSTER BY (work_id) AS (\n",
    "WITH base_works AS (\n",
    "    -- Read raw authorships from openalex_works_base (incremental)\n",
    "    SELECT\n",
    "        id AS work_id,\n",
    "        authorships,\n",
    "        updated_date AS updated_datetime\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works_base')\n",
    "    WHERE updated_date > max_updated_date\n",
    "      AND authorships IS NOT NULL\n",
    "      AND SIZE(authorships) > 0\n",
    "),\n",
    "institution_lineage AS (\n",
    "    SELECT\n",
    "        institution_id,\n",
    "        COLLECT_LIST(ancestor_id) AS lineage_ids\n",
    "    FROM openalex.mid.institution_ancestors\n",
    "    WHERE NOT ARRAY_CONTAINS(SUPER_SYSTEM_INSTITUTIONS, ancestor_id)\n",
    "    GROUP BY institution_id\n",
    "),\n",
    "author_institutions_with_details AS (\n",
    "    SELECT\n",
    "        ai.work_id,\n",
    "        ai.author_sequence,\n",
    "        ARRAY_DISTINCT(FLATTEN(COLLECT_SET(ai.raw_countries))) AS raw_parsed_countries,\n",
    "        COLLECT_SET(\n",
    "            STRUCT(\n",
    "                inst.iso3166_code AS country_code,\n",
    "                inst.display_name,\n",
    "                CONCAT('https://openalex.org/I', ai.institution_id) AS id,\n",
    "                ARRAY_SORT(\n",
    "                    TRANSFORM(\n",
    "                        ARRAY_COMPACT(CONCAT(ARRAY(ai.institution_id), COALESCE(il.lineage_ids, ARRAY()))), \n",
    "                        id -> CONCAT('https://openalex.org/I', id)\n",
    "                    )\n",
    "                ) AS lineage,\n",
    "                CASE \n",
    "                    WHEN inst.ror_id IS NULL THEN NULL\n",
    "                    WHEN inst.ror_id LIKE 'https://ror.org/%' THEN inst.ror_id\n",
    "                    ELSE CONCAT('https://ror.org/', inst.ror_id) \n",
    "                END AS ror,\n",
    "                inst.type\n",
    "            )\n",
    "        ) AS institutions\n",
    "    FROM identifier('openalex' || :env_suffix || '.authors.author_institutions') ai\n",
    "    LEFT JOIN openalex.institutions.institutions inst ON inst.id = ai.institution_id\n",
    "    LEFT JOIN institution_lineage il USING (institution_id)\n",
    "    WHERE ai.institution_id IS NOT NULL\n",
    "    GROUP BY ai.work_id, ai.author_sequence\n",
    "),\n",
    "-- Map raw_affiliation_string -> institution_ids per (work_id, author_sequence)\n",
    "affiliations_map_ids AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        raw_affiliation_string,\n",
    "        ARRAY_DISTINCT(\n",
    "            ARRAY_COMPACT(\n",
    "                COLLECT_LIST(CONCAT('https://openalex.org/I', institution_id))\n",
    "            )\n",
    "        ) AS institution_ids\n",
    "    FROM identifier('openalex' || :env_suffix || '.authors.author_institutions')\n",
    "    WHERE institution_id IS NOT NULL\n",
    "      AND raw_affiliation_string IS NOT NULL\n",
    "    GROUP BY work_id, author_sequence, raw_affiliation_string\n",
    "),\n",
    "affiliations_map AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        MAP_FROM_ENTRIES(\n",
    "            COLLECT_LIST(NAMED_STRUCT('key', raw_affiliation_string, 'value', institution_ids))\n",
    "        ) AS aff_map\n",
    "    FROM affiliations_map_ids\n",
    "    GROUP BY work_id, author_sequence\n",
    "),\n",
    "-- Pre-aggregate institution details per work_id as a map[author_sequence -> details]\n",
    "author_institution_lookup AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        MAP_FROM_ENTRIES(\n",
    "            COLLECT_LIST(\n",
    "                STRUCT(\n",
    "                    author_sequence,\n",
    "                    STRUCT(\n",
    "                        institutions,\n",
    "                        raw_parsed_countries,\n",
    "                        aff_map\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ) AS author_lookup\n",
    "    FROM (\n",
    "        SELECT\n",
    "            aid.work_id,\n",
    "            aid.author_sequence,\n",
    "            aid.institutions,\n",
    "            aid.raw_parsed_countries,\n",
    "            am.aff_map\n",
    "        FROM author_institutions_with_details aid\n",
    "        LEFT JOIN affiliations_map am \n",
    "            ON aid.work_id = am.work_id \n",
    "            AND aid.author_sequence = am.author_sequence\n",
    "    )\n",
    "    GROUP BY work_id\n",
    "),\n",
    "-- Explode authorships to join with parsed names lookup\n",
    "exploded_for_parsed_names AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        updated_datetime,\n",
    "        POSEXPLODE(authorships) AS (author_idx, authorship)\n",
    "    FROM base_works\n",
    "),\n",
    "-- Join with parsed names lookup\n",
    "with_parsed_names AS (\n",
    "    SELECT\n",
    "        e.work_id,\n",
    "        e.updated_datetime,\n",
    "        e.author_idx,\n",
    "        e.authorship,\n",
    "        pn.parsed_name\n",
    "    FROM exploded_for_parsed_names e\n",
    "    LEFT JOIN identifier('openalex' || :env_suffix || '.authors.parsed_names_lookup') pn\n",
    "        ON TRIM(e.authorship.raw_author_name) = pn.raw_author_name\n",
    "),\n",
    "-- Reassemble authorships with parsed names\n",
    "authorships_with_parsed_names AS (\n",
    "    SELECT\n",
    "        work_id,\n",
    "        updated_datetime,\n",
    "        TRANSFORM(\n",
    "            ARRAY_SORT(\n",
    "                COLLECT_LIST(\n",
    "                    STRUCT(\n",
    "                        author_idx,\n",
    "                        STRUCT(\n",
    "                            authorship.affiliations AS affiliations,\n",
    "                            authorship.author AS author,\n",
    "                            authorship.author_position AS author_position,\n",
    "                            authorship.author_order_number AS author_order_number,\n",
    "                            authorship.countries AS countries,\n",
    "                            authorship.institutions AS institutions,\n",
    "                            authorship.is_corresponding AS is_corresponding,\n",
    "                            authorship.raw_affiliation_strings AS raw_affiliation_strings,\n",
    "                            authorship.raw_author_name AS raw_author_name,\n",
    "                            parsed_name AS parsed_name\n",
    "                        ) AS authorship\n",
    "                    )\n",
    "                ),\n",
    "                (left, right) -> CASE\n",
    "                    WHEN left.author_idx < right.author_idx THEN -1\n",
    "                    WHEN left.author_idx > right.author_idx THEN 1\n",
    "                    ELSE 0\n",
    "                END\n",
    "            ),\n",
    "            x -> x.authorship\n",
    "        ) AS authorships\n",
    "    FROM with_parsed_names\n",
    "    GROUP BY work_id, updated_datetime\n",
    ")\n",
    "-- Final enrichment: add institution details, countries, affiliations mapping\n",
    "SELECT\n",
    "    ba.work_id,\n",
    "    ba.updated_datetime,\n",
    "    TRANSFORM(\n",
    "        ba.authorships,\n",
    "        (auth, idx) -> STRUCT(\n",
    "            -- affiliations: map raw_affiliation_strings to institution_ids\n",
    "            TRANSFORM(\n",
    "                COALESCE(auth.raw_affiliation_strings, ARRAY()),\n",
    "                s -> STRUCT(\n",
    "                    COALESCE(ELEMENT_AT(ELEMENT_AT(ail.author_lookup, idx).aff_map, s), ARRAY()) AS institution_ids,\n",
    "                    s AS raw_affiliation_string\n",
    "                )\n",
    "            ) AS affiliations,\n",
    "            -- Preserve author field (id still NULL, will be assigned later)\n",
    "            auth.author,\n",
    "            -- All other fields\n",
    "            auth.author_position,\n",
    "            auth.author_order_number,\n",
    "            -- countries from institutions (fallback to raw parsed countries)\n",
    "            CASE\n",
    "                WHEN ELEMENT_AT(ail.author_lookup, idx).institutions IS NOT NULL \n",
    "                     AND SIZE(FILTER(ELEMENT_AT(ail.author_lookup, idx).institutions.country_code, c -> c IS NOT NULL AND c <> '')) > 0\n",
    "                    THEN ARRAY_SORT(ARRAY_DISTINCT(FILTER(ELEMENT_AT(ail.author_lookup, idx).institutions.country_code, c -> c IS NOT NULL AND c <> '')))\n",
    "                WHEN ELEMENT_AT(ail.author_lookup, idx).raw_parsed_countries IS NOT NULL\n",
    "                    THEN ELEMENT_AT(ail.author_lookup, idx).raw_parsed_countries\n",
    "                ELSE ARRAY()\n",
    "            END AS countries,\n",
    "            -- institutions with full details\n",
    "            COALESCE(ELEMENT_AT(ail.author_lookup, idx).institutions, ARRAY()) AS institutions,\n",
    "            auth.is_corresponding,\n",
    "            auth.raw_affiliation_strings,\n",
    "            auth.raw_author_name,\n",
    "            auth.parsed_name\n",
    "        )\n",
    "    ) AS authorships\n",
    "FROM authorships_with_parsed_names ba\n",
    "LEFT JOIN author_institution_lookup ail ON ba.work_id = ail.work_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "799fa2e3-464c-4030-9e41-e687f3e8223f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Match authors - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "529b4852-b927-477a-9715-ee7c36d995bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------\n",
    "-- AUTHOR MATCHING ALGORITHM - DIAGNOSTIC TABLE\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "CREATE OR REPLACE TABLE openalex.authors.author_matching_diagnostics AS\n",
    "\n",
    "WITH with_topics AS (\n",
    "  SELECT\n",
    "    aa.work_id,\n",
    "    aa.authorships,\n",
    "    coalesce(wtf.topics, array()) as topics\n",
    "  FROM openalex.works.authors_and_affiliations_updates aa\n",
    "  LEFT JOIN openalex.works.work_topics_frontfill wtf\n",
    "    ON aa.work_id = wtf.work_id\n",
    "),\n",
    "\n",
    "authors_exploded AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    authorship.author.display_name,\n",
    "    authorship.parsed_name,\n",
    "    lower(concat(substring(authorship.parsed_name.first, 1, 1), ' ', authorship.parsed_name.last)) as block_key,\n",
    "    array_distinct(\n",
    "      concat(\n",
    "        transform(authorship.institutions, i -> i.id),\n",
    "        flatten(transform(authorship.institutions, i -> i.lineage))\n",
    "      )\n",
    "    ) as institution_ids,\n",
    "    transform(topics, t -> t.id) as topic_ids,\n",
    "    transform(topics, t -> t.subfield.id) as subfield_ids\n",
    "  FROM with_topics\n",
    "  LATERAL VIEW explode(authorships) AS authorship\n",
    "  WHERE work_id > 7000000000\n",
    "),\n",
    "\n",
    "blocked_candidates AS (\n",
    "  SELECT \n",
    "    e.work_id,\n",
    "    e.display_name,\n",
    "    e.parsed_name,\n",
    "    e.block_key,\n",
    "    e.institution_ids,\n",
    "    e.topic_ids,\n",
    "    e.subfield_ids,\n",
    "    alm.author_id,\n",
    "    alm.parsed_longest_name,\n",
    "    alm.institution_ids as candidate_institution_ids,\n",
    "    alm.topic_ids as candidate_topic_ids,\n",
    "    alm.subfield_ids as candidate_subfield_ids,\n",
    "    alm.works_count\n",
    "  FROM authors_exploded e\n",
    "  JOIN openalex.authors.author_lookup_mapping alm\n",
    "    ON alm.block_key = e.block_key\n",
    "),\n",
    "\n",
    "with_match_signals AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    length(parsed_name.first) as pn_first_len,\n",
    "    length(parsed_longest_name.first) as cand_first_len,\n",
    "    coalesce(parsed_name.middle, '') as pn_middle,\n",
    "    coalesce(parsed_longest_name.middle, '') as cand_middle,\n",
    "    \n",
    "    (size(institution_ids) > 0 AND size(candidate_institution_ids) > 0 \n",
    "     AND arrays_overlap(candidate_institution_ids, institution_ids)) as has_inst,\n",
    "    \n",
    "    (size(topic_ids) > 0 AND size(candidate_topic_ids) > 0 \n",
    "     AND arrays_overlap(candidate_topic_ids, topic_ids)) as has_topic,\n",
    "\n",
    "    (size(subfield_ids) > 0 AND size(candidate_subfield_ids) > 0 \n",
    "     AND arrays_overlap(candidate_subfield_ids, subfield_ids)) as has_subfield\n",
    "  FROM blocked_candidates\n",
    "),\n",
    "\n",
    "with_name_matches AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- 1: Exact Full Name (Exact First, Exact Middle, Exact Last)\n",
    "    (pn_first_len > 1 AND length(pn_middle) > 1 AND cand_first_len > 1 AND length(cand_middle) > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(pn_middle) = lower(cand_middle)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_1_exact_full,\n",
    "\n",
    "    -- 2: Exact First, Middle Initial match, Exact Last\n",
    "    (pn_first_len > 1 AND length(pn_middle) = 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND (cand_middle = '' OR lower(pn_middle) = lower(substring(cand_middle, 1, 1)))\n",
    "    ) as pattern_2_exact_first_mid_init,\n",
    "\n",
    "    -- 3: Initials match to Full (First Init, Mid Init, Exact Last)\n",
    "    (pn_first_len = 1 AND pn_middle != '' AND cand_first_len > 1 AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_3_init_mid_init,\n",
    "\n",
    "    -- 4: First Initial, Middle Initial match, Exact Last\n",
    "    (pn_first_len = 1 AND cand_first_len = 1 AND pn_middle != '' AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_4_first_init_mid_init,\n",
    "\n",
    "    -- 5: Exact First, Exact Last (No Middle info)\n",
    "    (pn_first_len > 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = ''\n",
    "    ) as pattern_5_exact_first_last,\n",
    "\n",
    "    -- 6: First Initial Only to Full, Exact Last\n",
    "    (pn_first_len = 1 AND pn_middle = '' AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_6_first_init_to_full,\n",
    "\n",
    "    -- 7: First Initial Only, Exact Last (Both sides)\n",
    "    (pn_first_len = 1 AND cand_first_len = 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = '' AND cand_middle = ''\n",
    "    ) as pattern_7_first_init_last,\n",
    "\n",
    "    -- 8: Full Name to Initial, Exact Last (Reverse of 6)\n",
    "    (pn_first_len > 1 AND cand_first_len = 1\n",
    "     AND lower(substring(parsed_name.first, 1, 1)) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_8_full_to_init\n",
    "\n",
    "  FROM with_match_signals\n",
    "),\n",
    "\n",
    "with_any_name_match AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    (pattern_1_exact_full OR pattern_2_exact_first_mid_init OR pattern_3_init_mid_init OR \n",
    "     pattern_4_first_init_mid_init OR pattern_5_exact_first_last OR pattern_6_first_init_to_full OR \n",
    "     pattern_7_first_init_last OR pattern_8_full_to_init) as any_name_match\n",
    "  FROM with_name_matches\n",
    "),\n",
    "\n",
    "aggregated_counts AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    display_name,\n",
    "    block_key,\n",
    "    \n",
    "    -- Counts for \"Unique Name\" strategy (Strategy 1)\n",
    "    count_if(pattern_1_exact_full) as s1_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init) as s1_n2,\n",
    "    count_if(pattern_3_init_mid_init) as s1_n3,\n",
    "    count_if(pattern_4_first_init_mid_init) as s1_n4,\n",
    "    count_if(pattern_5_exact_first_last) as s1_n5,\n",
    "    count_if(pattern_6_first_init_to_full) as s1_n6,\n",
    "    count_if(pattern_7_first_init_last) as s1_n7,\n",
    "    count_if(pattern_8_full_to_init) as s1_n8,\n",
    "    \n",
    "    -- Counts for \"Resolved by Inst\" strategy (Strategy 2)\n",
    "    count_if(pattern_1_exact_full AND has_inst) as s2_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst) as s2_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_inst) as s2_n3,\n",
    "    count_if(pattern_4_first_init_mid_init AND has_inst) as s2_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst) as s2_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst) as s2_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst) as s2_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst) as s2_n8,\n",
    "\n",
    "    -- Counts for \"Resolved by Topic\" strategy (Strategy 3)\n",
    "    count_if(pattern_1_exact_full AND has_topic) as s3_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_topic) as s3_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_topic) as s3_n3,\n",
    "    count_if(pattern_4_first_init_mid_init AND has_topic) as s3_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_topic) as s3_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_topic) as s3_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_topic) as s3_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_topic) as s3_n8,\n",
    "\n",
    "    -- Capture Author IDs\n",
    "    max(CASE WHEN pattern_1_exact_full THEN author_id END) as id_s1_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init THEN author_id END) as id_s1_n2,\n",
    "    max(CASE WHEN pattern_3_init_mid_init THEN author_id END) as id_s1_n3,\n",
    "    max(CASE WHEN pattern_4_first_init_mid_init THEN author_id END) as id_s1_n4,\n",
    "    max(CASE WHEN pattern_5_exact_first_last THEN author_id END) as id_s1_n5,\n",
    "    max(CASE WHEN pattern_6_first_init_to_full THEN author_id END) as id_s1_n6,\n",
    "    max(CASE WHEN pattern_7_first_init_last THEN author_id END) as id_s1_n7,\n",
    "    max(CASE WHEN pattern_8_full_to_init THEN author_id END) as id_s1_n8,\n",
    "\n",
    "    max(CASE WHEN pattern_1_exact_full AND has_inst THEN author_id END) as id_s2_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init AND has_inst THEN author_id END) as id_s2_n2,\n",
    "    max(CASE WHEN pattern_3_init_mid_init AND has_inst THEN author_id END) as id_s2_n3,\n",
    "    max(CASE WHEN pattern_4_first_init_mid_init AND has_inst THEN author_id END) as id_s2_n4,\n",
    "    max(CASE WHEN pattern_5_exact_first_last AND has_inst THEN author_id END) as id_s2_n5,\n",
    "    max(CASE WHEN pattern_6_first_init_to_full AND has_inst THEN author_id END) as id_s2_n6,\n",
    "    max(CASE WHEN pattern_7_first_init_last AND has_inst THEN author_id END) as id_s2_n7,\n",
    "    max(CASE WHEN pattern_8_full_to_init AND has_inst THEN author_id END) as id_s2_n8,\n",
    "    \n",
    "    max(CASE WHEN pattern_1_exact_full AND has_topic THEN author_id END) as id_s3_n1,\n",
    "    max(CASE WHEN pattern_2_exact_first_mid_init AND has_topic THEN author_id END) as id_s3_n2,\n",
    "    max(CASE WHEN pattern_5_exact_first_last AND has_topic THEN author_id END) as id_s3_n5,\n",
    "    \n",
    "    -- Diagnostics\n",
    "    count(*) as total_candidates_in_block,\n",
    "    count_if(any_name_match) as total_name_matches,\n",
    "    \n",
    "    count_if(has_inst) as total_candidates_with_inst,\n",
    "    count_if(any_name_match AND has_inst) as name_matched_candidates_with_inst,\n",
    "    \n",
    "    count_if(has_topic) as total_candidates_with_topic,\n",
    "    count_if(any_name_match AND has_topic) as name_matched_candidates_with_topic,\n",
    "    \n",
    "    max(size(institution_ids)) > 0 as work_has_inst,\n",
    "    max(size(topic_ids)) > 0 as work_has_topic,\n",
    "    \n",
    "    slice(collect_list(\n",
    "      CASE WHEN any_name_match THEN\n",
    "        named_struct(\n",
    "          'author_id', author_id,\n",
    "          'name', parsed_longest_name.first || ' ' || parsed_longest_name.last,\n",
    "          'has_inst', has_inst,\n",
    "          'has_topic', has_topic\n",
    "        )\n",
    "      END\n",
    "    ), 1, 10) as candidates_passing_name_check,\n",
    "    \n",
    "    slice(collect_list(\n",
    "      CASE WHEN NOT any_name_match THEN\n",
    "        named_struct(\n",
    "          'author_id', author_id,\n",
    "          'name', parsed_longest_name.first || ' ' || parsed_longest_name.last\n",
    "        )\n",
    "      END\n",
    "    ), 1, 5) as candidates_failing_name_check\n",
    "\n",
    "  FROM with_any_name_match\n",
    "  GROUP BY work_id, display_name, block_key\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  work_id,\n",
    "  display_name as work_author_name,\n",
    "  block_key,\n",
    "  \n",
    "  -- Determine Strategy Name\n",
    "  CASE \n",
    "    -- Strategy 1: Unique Name\n",
    "    WHEN s1_n1 = 1 THEN 'unique_exact_full_name'\n",
    "    WHEN s1_n2 = 1 THEN 'unique_exact_first_mid_init'\n",
    "    WHEN s1_n3 = 1 THEN 'unique_init_mid_init'\n",
    "    WHEN s1_n4 = 1 THEN 'unique_first_init_mid_init'\n",
    "    WHEN s1_n5 = 1 THEN 'unique_exact_first_last'\n",
    "    WHEN s1_n6 = 1 THEN 'unique_first_init_to_full'\n",
    "    WHEN s1_n7 = 1 THEN 'unique_first_init_only'\n",
    "    WHEN s1_n8 = 1 THEN 'unique_full_to_init'\n",
    "    \n",
    "    -- Strategy 2: Ambiguous Name Resolved by Institution\n",
    "    WHEN s2_n1 = 1 THEN 'exact_full_resolved_by_inst'\n",
    "    WHEN s2_n2 = 1 THEN 'exact_first_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n3 = 1 THEN 'init_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n4 = 1 THEN 'first_init_mid_init_resolved_by_inst'\n",
    "    WHEN s2_n5 = 1 THEN 'exact_first_last_resolved_by_inst'\n",
    "    WHEN s2_n6 = 1 THEN 'first_init_to_full_resolved_by_inst'\n",
    "    WHEN s2_n7 = 1 THEN 'first_init_only_resolved_by_inst'\n",
    "    WHEN s2_n8 = 1 THEN 'full_to_init_resolved_by_inst'\n",
    "    \n",
    "    -- Strategy 3: Ambiguous Name Resolved by Topic\n",
    "    WHEN s3_n1 = 1 THEN 'exact_full_resolved_by_topic'\n",
    "    WHEN s3_n2 = 1 THEN 'exact_first_mid_init_resolved_by_topic'\n",
    "    WHEN s3_n5 = 1 THEN 'exact_first_last_resolved_by_topic'\n",
    "    \n",
    "    ELSE null\n",
    "  END as match_method,\n",
    "\n",
    "  -- Select Matched ID (Sequential Order 1-8)\n",
    "  CASE \n",
    "    -- Strategy 1 (Unique) - NOW INCLUDING WEAK PATTERNS IF UNIQUE\n",
    "    WHEN s1_n1 = 1 THEN id_s1_n1\n",
    "    WHEN s1_n2 = 1 THEN id_s1_n2\n",
    "    WHEN s1_n5 = 1 THEN id_s1_n5\n",
    "    WHEN s1_n3 = 1 THEN id_s1_n3\n",
    "    WHEN s1_n4 = 1 THEN id_s1_n4\n",
    "    WHEN s1_n6 = 1 THEN id_s1_n6\n",
    "    WHEN s1_n7 = 1 THEN id_s1_n7\n",
    "    WHEN s1_n8 = 1 THEN id_s1_n8\n",
    "    \n",
    "    -- Strategy 2 (Ambiguous -> Inst)\n",
    "    WHEN s2_n1 = 1 THEN id_s2_n1\n",
    "    WHEN s2_n2 = 1 THEN id_s2_n2\n",
    "    WHEN s2_n5 = 1 THEN id_s2_n5\n",
    "    WHEN s2_n3 = 1 THEN id_s2_n3\n",
    "    WHEN s2_n4 = 1 THEN id_s2_n4\n",
    "    WHEN s2_n6 = 1 THEN id_s2_n6\n",
    "    WHEN s2_n7 = 1 THEN id_s2_n7\n",
    "    WHEN s2_n8 = 1 THEN id_s2_n8\n",
    "    \n",
    "    -- Strategy 3 (Ambiguous -> Topic)\n",
    "    WHEN s3_n1 = 1 THEN id_s3_n1\n",
    "    WHEN s3_n2 = 1 THEN id_s3_n2\n",
    "    WHEN s3_n5 = 1 THEN id_s3_n5\n",
    "    ELSE null\n",
    "  END as matched_author_id,\n",
    "\n",
    "  -- High Level Outcome\n",
    "  CASE \n",
    "    WHEN (\n",
    "      -- Strong Unique\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      -- Weak Unique (Singleton Override)\n",
    "      s1_n3=1 OR s1_n4=1 OR s1_n6=1 OR s1_n7=1 OR s1_n8=1 OR\n",
    "      -- Resolved by Inst\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n3=1 OR s2_n4=1 OR s2_n5=1 OR s2_n6=1 OR s2_n7=1 OR s2_n8=1 OR\n",
    "      -- Resolved by Topic\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    )\n",
    "    THEN 'MATCHED'\n",
    "    WHEN total_candidates_in_block = 0 THEN 'NO_CANDIDATES'\n",
    "    ELSE 'AMBIGUOUS'\n",
    "  END as match_outcome,\n",
    "\n",
    "  -- Detailed Failure Reason\n",
    "  CASE\n",
    "    WHEN (\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      s1_n3=1 OR s1_n4=1 OR s1_n6=1 OR s1_n7=1 OR s1_n8=1 OR\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n3=1 OR s2_n4=1 OR s2_n5=1 OR s2_n6=1 OR s2_n7=1 OR s2_n8=1 OR\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    ) THEN null\n",
    "          \n",
    "    WHEN total_candidates_in_block = 0 THEN 'no_candidates_in_block'\n",
    "    WHEN total_name_matches = 0 THEN 'no_name_pattern_matched'\n",
    "    \n",
    "    WHEN total_name_matches > 1 THEN \n",
    "      CASE\n",
    "        WHEN NOT work_has_inst AND NOT work_has_topic THEN 'ambiguous_name_work_has_no_signals'\n",
    "        WHEN name_matched_candidates_with_inst = 0 AND name_matched_candidates_with_topic = 0 THEN 'ambiguous_name_no_signal_overlap'\n",
    "        WHEN name_matched_candidates_with_inst > 1 THEN 'ambiguous_name_multiple_candidates_have_inst'\n",
    "        WHEN name_matched_candidates_with_topic > 1 THEN 'ambiguous_name_multiple_candidates_have_topic'\n",
    "        ELSE 'ambiguous_other'\n",
    "      END\n",
    "    ELSE 'unknown_failure'\n",
    "  END as failure_reason,\n",
    "  \n",
    "  -- Extra context columns\n",
    "  total_candidates_in_block,\n",
    "  total_name_matches,\n",
    "  name_matched_candidates_with_inst,\n",
    "  name_matched_candidates_with_topic,\n",
    "  candidates_passing_name_check,\n",
    "  candidates_failing_name_check\n",
    "\n",
    "FROM aggregated_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c89457ae-aad5-4953-be8d-9ea3c38531e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- use author assignments to either 1) update openalex.works.work_authorships_map with assignment or 2) create new author then update openalex.works.work_authorships_map with new author id\n",
    "-- code to go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d0f8bfd-567a-4f69-bb3e-4dca6761c1d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 4: Merge enriched updates into final `authors_and_affiliations` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40ae6dbd-51e4-4cc6-b91a-65b35263b99a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.authors_and_affiliations') AS target\n",
    "USING identifier('openalex' || :env_suffix || '.works.authors_and_affiliations_updates') AS source\n",
    "ON target.work_id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.authorships = source.authorships,\n",
    "  target.updated_datetime = source.updated_datetime\n",
    "WHEN NOT MATCHED THEN INSERT (work_id, authorships, updated_datetime)\n",
    "VALUES (source.work_id, source.authorships, source.updated_datetime);"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateAuthorsAndAffiliations",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "ab378cd9-0a33-46a0-bc9c-fa98464945d7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
