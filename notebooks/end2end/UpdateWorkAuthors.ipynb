{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29c65842-0749-4901-93f4-f6178eaa795d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Update `openalex.works.work_authors` table using AND and raw affiliation string lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e80a10-caa7-4955-8f68-fe74ec720501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DECLARE OR REPLACE VARIABLE max_updated_date TIMESTAMP DEFAULT to_timestamp('1900-01-01');\n",
    "SET VARIABLE max_updated_date = COALESCE((SELECT MAX(updated_at) - INTERVAL 1 SECOND FROM identifier('openalex' || :env_suffix || '.works.work_authors')), to_timestamp('1900-01-01'));\n",
    "-- SET VARIABLE max_updated_date = to_timestamp('2025-12-20');\n",
    "SELECT max_updated_date;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1f152e3-74aa-4f5d-8219-5def2704bf38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Get updated works for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe68cc3-827b-42c2-9329-f11ddc218ca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589b332f-153c-43ec-a85e-ab8959127398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- STEP 1: Create Staging Table for Batch Works\n",
    "CREATE OR REPLACE TABLE openalex.authors.author_matching_batch AS\n",
    "WITH raw_exploded AS (\n",
    "    SELECT \n",
    "        id AS work_id,\n",
    "        updated_date,\n",
    "        POSEXPLODE(authorships) AS (author_sequence, authorship)\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works_base')\n",
    "    WHERE updated_date > max_updated_date\n",
    "      AND authorships IS NOT NULL \n",
    "      AND SIZE(authorships) > 0\n",
    "),\n",
    "exploded_affiliations AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        authorship,\n",
    "        authorship.raw_author_name,\n",
    "        EXPLODE_OUTER(authorship.raw_affiliation_strings) AS raw_affiliation_string\n",
    "    FROM raw_exploded\n",
    "),\n",
    "-- 1. Resolve Direct IDs\n",
    "resolved_direct_ids AS (\n",
    "    SELECT \n",
    "        ea.work_id,\n",
    "        ea.author_sequence,\n",
    "        ea.authorship, \n",
    "        ea.raw_author_name,\n",
    "        ea.raw_affiliation_string,\n",
    "        CASE \n",
    "            WHEN ea.raw_affiliation_string IS NULL THEN NULL\n",
    "            WHEN asl.institution_ids IS NOT NULL AND SIZE(asl.institution_ids) > 0 \n",
    "                AND NOT (SIZE(asl.institution_ids) = 1 AND asl.institution_ids[0] = -1) \n",
    "                THEN asl.institution_ids\n",
    "            ELSE NULL\n",
    "        END AS direct_ids,\n",
    "        asl.countries AS raw_countries\n",
    "    FROM exploded_affiliations ea\n",
    "    LEFT JOIN openalex.institutions.raw_affiliation_strings_institutions_mv asl\n",
    "        ON ea.raw_affiliation_string = asl.raw_affiliation_string\n",
    "),\n",
    "\n",
    "-- 2. Expand Lineage (FOR MATCHING ONLY)\n",
    "expanded_for_matching AS (\n",
    "    SELECT \n",
    "        r.work_id,\n",
    "        r.author_sequence,\n",
    "        -- Combine Direct + Ancestors into one big list for the matching algorithm\n",
    "        ARRAY_DISTINCT(FLATTEN(COLLECT_LIST(\n",
    "            FLATTEN(ARRAY(\n",
    "                FILTER(ARRAY(r.inst_id_scalar), x -> x IS NOT NULL),\n",
    "                COALESCE(anc.ancestors, ARRAY())\n",
    "            ))\n",
    "        ))) as matching_institution_ids\n",
    "    FROM (\n",
    "        SELECT *, EXPLODE_OUTER(direct_ids) as inst_id_scalar\n",
    "        FROM resolved_direct_ids \n",
    "    ) r\n",
    "    LEFT JOIN (\n",
    "        SELECT institution_id, lineage_ids as ancestors\n",
    "        FROM openalex.institutions.institution_ancestors\n",
    "    ) anc ON CAST(r.inst_id_scalar AS BIGINT) = anc.institution_id\n",
    "    GROUP BY r.work_id, r.author_sequence\n",
    "),\n",
    "\n",
    "-- 3. Group for Storage (DIRECT IDs ONLY)\n",
    "grouped_for_storage AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        author_sequence,\n",
    "        COLLECT_LIST(\n",
    "            NAMED_STRUCT(\n",
    "                'raw_string', raw_affiliation_string, \n",
    "                'ids', COALESCE(direct_ids, ARRAY()) \n",
    "            )\n",
    "        ) as affiliation_structs\n",
    "    FROM (\n",
    "        -- Deduplicate to ensure no duplicate raw affilition strings\n",
    "        SELECT \n",
    "            work_id, \n",
    "            author_sequence, \n",
    "            raw_affiliation_string,\n",
    "            FIRST(direct_ids) as direct_ids\n",
    "        FROM resolved_direct_ids\n",
    "        GROUP BY work_id, author_sequence, raw_affiliation_string\n",
    "    ) deduped\n",
    "    GROUP BY work_id, author_sequence\n",
    ")\n",
    "\n",
    "-- 4. Final Selection\n",
    "SELECT \n",
    "    r.work_id,\n",
    "    r.author_sequence,\n",
    "    FIRST(gs.affiliation_structs) as affiliation_structs,\n",
    "    COALESCE(FIRST(efm.matching_institution_ids), ARRAY()) as all_institution_ids,\n",
    "    FIRST(r.authorship) as authorship_struct,\n",
    "    FIRST(r.raw_author_name) as raw_author_name,\n",
    "    FIRST(r.raw_countries) as raw_countries\n",
    "FROM resolved_direct_ids r\n",
    "LEFT JOIN grouped_for_storage gs \n",
    "    ON r.work_id = gs.work_id AND r.author_sequence = gs.author_sequence\n",
    "LEFT JOIN expanded_for_matching efm\n",
    "    ON r.work_id = efm.work_id AND r.author_sequence = efm.author_sequence\n",
    "GROUP BY r.work_id, r.author_sequence;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "717c33cd-491c-43af-86d6-f5fadb1e63ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Run Matching Algorithm Over Updated Works with ID over 7000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b1f5de5-fa14-41b8-9267-00dfdebecd85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE openalex.authors.pending_author_assignments AS\n",
    "WITH \n",
    "-- 1. ENRICH BATCH DATA\n",
    "-- We need to add Signals (Topics, Sources) and parsed names to the staged batch data\n",
    "enriched_batch AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.author_sequence,\n",
    "    b.raw_author_name,\n",
    "    b.all_institution_ids,\n",
    "    TRANSFORM(b.all_institution_ids, x -> CONCAT('https://openalex.org/I', CAST(x AS STRING))) AS institution_ids,\n",
    "    \n",
    "    COALESCE(pn.parsed_name, \n",
    "             named_struct('title', '', 'first', '', 'middle', '', 'last', '', 'suffix', '', 'nickname', '')\n",
    "    ) AS parsed_name,\n",
    "    \n",
    "    COALESCE(wtf.topics, ARRAY()) AS topics,\n",
    "    \n",
    "    ARRAY_DISTINCT(\n",
    "      TRANSFORM(\n",
    "        FILTER(w.locations, x -> x.source.id IS NOT NULL),\n",
    "        x -> x.source.id\n",
    "      )\n",
    "    ) AS work_source_ids\n",
    "    \n",
    "  FROM openalex.authors.author_matching_batch b\n",
    "  LEFT JOIN openalex.authors.parsed_names_lookup pn \n",
    "    ON TRIM(b.raw_author_name) = pn.raw_author_name\n",
    "  LEFT JOIN openalex.works.work_topics_frontfill wtf \n",
    "    ON b.work_id = wtf.work_id\n",
    "  LEFT JOIN openalex.works.openalex_works w \n",
    "    ON b.work_id = w.id\n",
    "),\n",
    "\n",
    "-- 2. PREPARE MATCHING INPUTS\n",
    "-- Calculate Block Keys and ID arrays\n",
    "authors_prepared AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    author_sequence,\n",
    "    raw_author_name,\n",
    "    parsed_name,\n",
    "    -- Block Key Generation\n",
    "    LOWER(CONCAT(SUBSTRING(parsed_name.first, 1, 1), ' ', parsed_name.last)) AS block_key,\n",
    "    institution_ids,\n",
    "    -- Extract Topic IDs\n",
    "    TRANSFORM(topics, t -> t.id) AS topic_ids,\n",
    "    work_source_ids\n",
    "  FROM enriched_batch\n",
    "  -- Filter invalid rows if necessary, though batch_staged_data should be clean\n",
    "  WHERE raw_author_name IS NOT NULL\n",
    "),\n",
    "\n",
    "-- 3. CANDIDATE BLOCKING\n",
    "blocked_candidates AS (\n",
    "  SELECT \n",
    "    e.work_id,\n",
    "    e.author_sequence,\n",
    "    e.raw_author_name,\n",
    "    e.parsed_name,\n",
    "    e.block_key,\n",
    "    e.institution_ids,\n",
    "    e.topic_ids,\n",
    "    e.work_source_ids,\n",
    "    alm.author_id,\n",
    "    alm.parsed_longest_name,\n",
    "    alm.institution_ids as candidate_institution_ids,\n",
    "    alm.topic_ids as candidate_topic_ids,\n",
    "    alm.source_ids AS candidate_source_ids,\n",
    "    alm.works_count\n",
    "  FROM authors_prepared e\n",
    "  LEFT JOIN openalex.authors.author_lookup_mapping alm\n",
    "    ON alm.block_key = e.block_key\n",
    "    AND e.work_id > 7000000000  -- only attempt matching on new records, less than this will have no candidates right away\n",
    "),\n",
    "\n",
    "with_match_signals AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    NAMED_STRUCT(\n",
    "      'id', author_id,\n",
    "      'display_name', CONCAT(parsed_longest_name.first, ' ', parsed_longest_name.last),\n",
    "      'parsed_name', parsed_longest_name\n",
    "    ) AS candidate_obj,\n",
    "    length(parsed_name.first) as pn_first_len,\n",
    "    length(parsed_longest_name.first) as cand_first_len,\n",
    "    coalesce(parsed_name.middle, '') as pn_middle,\n",
    "    coalesce(parsed_longest_name.middle, '') as cand_middle,\n",
    "    \n",
    "    (size(institution_ids) > 0 AND size(candidate_institution_ids) > 0 \n",
    "     AND arrays_overlap(candidate_institution_ids, institution_ids)) as has_inst,\n",
    "    \n",
    "    (size(topic_ids) > 0 AND size(candidate_topic_ids) > 0 \n",
    "     AND arrays_overlap(candidate_topic_ids, topic_ids)) as has_topic,\n",
    "\n",
    "     (SIZE(work_source_ids) > 0 AND SIZE(candidate_source_ids) > 0\n",
    "     AND ARRAYS_OVERLAP(candidate_source_ids, work_source_ids)) AS has_source\n",
    "  FROM blocked_candidates\n",
    "),\n",
    "\n",
    "with_name_matches AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- 1: Exact Full Name\n",
    "    (pn_first_len > 1 AND length(pn_middle) > 1 AND cand_first_len > 1 AND length(cand_middle) > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(pn_middle) = lower(cand_middle)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_1_exact_full,\n",
    "\n",
    "    -- 2: Exact First, Middle Initial match\n",
    "    (pn_first_len > 1 AND length(pn_middle) = 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND (cand_middle = '' OR lower(pn_middle) = lower(substring(cand_middle, 1, 1)))\n",
    "    ) as pattern_2_exact_first_mid_init,\n",
    "\n",
    "    -- 3: Initials match to Full\n",
    "    (pn_first_len = 1 AND pn_middle != '' AND cand_first_len > 1 AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_3_init_mid_init,\n",
    "\n",
    "    -- 4: First Initial, Middle Initial match\n",
    "    (pn_first_len = 1 AND cand_first_len = 1 AND pn_middle != '' AND cand_middle != ''\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(substring(pn_middle, 1, 1)) = lower(substring(cand_middle, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_4_first_init_mid_init,\n",
    "\n",
    "    -- 5: Exact First, Exact Last\n",
    "    (pn_first_len > 1 AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = ''\n",
    "    ) as pattern_5_exact_first_last,\n",
    "\n",
    "    -- 6: First Initial Only to Full\n",
    "    (pn_first_len = 1 AND pn_middle = '' AND cand_first_len > 1\n",
    "     AND lower(parsed_name.first) = lower(substring(parsed_longest_name.first, 1, 1))\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_6_first_init_to_full,\n",
    "\n",
    "    -- 7: First Initial Only\n",
    "    (pn_first_len = 1 AND cand_first_len = 1\n",
    "     AND lower(parsed_name.first) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "     AND pn_middle = '' AND cand_middle = ''\n",
    "    ) as pattern_7_first_init_last,\n",
    "\n",
    "    -- 8: Full Name to Initial\n",
    "    (pn_first_len > 1 AND cand_first_len = 1\n",
    "     AND lower(substring(parsed_name.first, 1, 1)) = lower(parsed_longest_name.first)\n",
    "     AND lower(parsed_name.last) = lower(parsed_longest_name.last)\n",
    "    ) as pattern_8_full_to_init\n",
    "\n",
    "  FROM with_match_signals\n",
    "),\n",
    "\n",
    "with_any_name_match AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    (pattern_1_exact_full OR pattern_2_exact_first_mid_init OR pattern_3_init_mid_init OR \n",
    "     pattern_4_first_init_mid_init OR pattern_5_exact_first_last OR pattern_6_first_init_to_full OR \n",
    "     pattern_7_first_init_last OR pattern_8_full_to_init) as any_name_match\n",
    "  FROM with_name_matches\n",
    "),\n",
    "\n",
    "aggregated_counts AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    author_sequence,\n",
    "    raw_author_name,\n",
    "    block_key,\n",
    "    institution_ids,\n",
    "    parsed_name,\n",
    "    work_source_ids,\n",
    "    \n",
    "    -- STRATEGY 1: Name Only (Unique)\n",
    "    count_if(pattern_1_exact_full) AS s1_n1, count_if(pattern_2_exact_first_mid_init) AS s1_n2,\n",
    "    count_if(pattern_3_init_mid_init) AS s1_n3, count_if(pattern_4_first_init_mid_init) AS s1_n4,\n",
    "    count_if(pattern_5_exact_first_last) AS s1_n5, count_if(pattern_6_first_init_to_full) AS s1_n6,\n",
    "    count_if(pattern_7_first_init_last) AS s1_n7, count_if(pattern_8_full_to_init) AS s1_n8,\n",
    "    \n",
    "    -- STRATEGY 2: Name + Institution\n",
    "    count_if(pattern_1_exact_full AND has_inst) AS s2_n1, count_if(pattern_2_exact_first_mid_init AND has_inst) AS s2_n2,\n",
    "    count_if(pattern_3_init_mid_init AND has_inst) AS s2_n3, count_if(pattern_4_first_init_mid_init AND has_inst) AS s2_n4,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst) AS s2_n5, count_if(pattern_6_first_init_to_full AND has_inst) AS s2_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst) AS s2_n7, count_if(pattern_8_full_to_init AND has_inst) AS s2_n8,\n",
    "\n",
    "    -- STRATEGY 6: Name + Inst + Source\n",
    "    count_if(pattern_1_exact_full AND has_inst AND has_source) AS s6_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst AND has_source) AS s6_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst AND has_source) AS s6_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst AND has_source) AS s6_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst AND has_source) AS s6_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst AND has_source) AS s6_n8,\n",
    "\n",
    "    -- STRATEGY 4: Name + Inst + Topic\n",
    "    count_if(pattern_1_exact_full AND has_inst AND has_topic) AS s4_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_inst AND has_topic) AS s4_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_inst AND has_topic) AS s4_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_inst AND has_topic) AS s4_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_inst AND has_topic) AS s4_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_inst AND has_topic) AS s4_n8,\n",
    "\n",
    "    -- STRATEGY 5: Name + Source\n",
    "    count_if(pattern_1_exact_full AND has_source) AS s5_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_source) AS s5_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_source) AS s5_n5,\n",
    "    count_if(pattern_6_first_init_to_full AND has_source) AS s5_n6,\n",
    "    count_if(pattern_7_first_init_last AND has_source) AS s5_n7,\n",
    "    count_if(pattern_8_full_to_init AND has_source) AS s5_n8,\n",
    "\n",
    "    -- STRATEGY 3: Name + Topic\n",
    "    count_if(pattern_1_exact_full AND has_topic) AS s3_n1,\n",
    "    count_if(pattern_2_exact_first_mid_init AND has_topic) AS s3_n2,\n",
    "    count_if(pattern_5_exact_first_last AND has_topic) AS s3_n5,\n",
    "    \n",
    "    -- CAPTURE MATCHED OBJECTS (Same as before)\n",
    "    MAX(CASE WHEN pattern_1_exact_full THEN candidate_obj END) AS match_s1_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init THEN candidate_obj END) AS match_s1_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last THEN candidate_obj END) AS match_s1_n5,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst THEN candidate_obj END) AS match_s2_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst THEN candidate_obj END) AS match_s2_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst THEN candidate_obj END) AS match_s2_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst THEN candidate_obj END) AS match_s2_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst THEN candidate_obj END) AS match_s2_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst AND has_source THEN candidate_obj END) AS match_s6_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_source THEN candidate_obj END) AS match_s5_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_source THEN candidate_obj END) AS match_s5_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_source THEN candidate_obj END) AS match_s5_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_source THEN candidate_obj END) AS match_s5_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_source THEN candidate_obj END) AS match_s5_n8,\n",
    "    \n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n5,\n",
    "    MAX(CASE WHEN pattern_6_first_init_to_full AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n6,\n",
    "    MAX(CASE WHEN pattern_8_full_to_init AND has_inst AND has_topic THEN candidate_obj END) AS match_s4_n8,\n",
    "\n",
    "    MAX(CASE WHEN pattern_1_exact_full AND has_topic THEN candidate_obj END) AS match_s3_n1,\n",
    "    MAX(CASE WHEN pattern_2_exact_first_mid_init AND has_topic THEN candidate_obj END) AS match_s3_n2,\n",
    "    MAX(CASE WHEN pattern_5_exact_first_last AND has_topic THEN candidate_obj END) AS match_s3_n5,\n",
    "    \n",
    "    COUNT(author_id) AS total_candidates_in_block,\n",
    "    COUNT_IF(any_name_match) AS total_name_matches\n",
    "\n",
    "  FROM with_any_name_match\n",
    "  GROUP BY work_id, author_sequence, raw_author_name, block_key, institution_ids, parsed_name, work_source_ids\n",
    "),\n",
    "\n",
    "final_decision AS (\n",
    "SELECT\n",
    "  work_id,\n",
    "  author_sequence,\n",
    "  block_key,\n",
    "  raw_author_name,\n",
    "  institution_ids,\n",
    "  parsed_name,\n",
    "  work_source_ids,\n",
    "  \n",
    "  -- MATCH OUTCOME\n",
    "  CASE \n",
    "    WHEN (\n",
    "      s1_n1=1 OR s1_n2=1 OR s1_n5=1 OR \n",
    "      s6_n1=1 OR s6_n2=1 OR s6_n5=1 OR s6_n6=1 OR s6_n8=1 OR\n",
    "      s2_n1=1 OR s2_n2=1 OR s2_n5=1 OR s2_n6=1 OR s2_n8=1 OR\n",
    "      s4_n1=1 OR s4_n2=1 OR s4_n5=1 OR s4_n6=1 OR s4_n8=1 OR\n",
    "      s5_n1=1 OR s5_n2=1 OR s5_n5=1 OR s5_n6=1 OR s5_n8=1 OR\n",
    "      s3_n1=1 OR s3_n2=1 OR s3_n5=1\n",
    "    ) THEN 'MATCHED'\n",
    "    WHEN total_candidates_in_block = 0 THEN 'NO_CANDIDATES'\n",
    "    ELSE 'AMBIGUOUS'\n",
    "  END AS match_outcome,\n",
    "\n",
    "  -- MATCHED AUTHOR ID\n",
    "  CASE \n",
    "    WHEN s1_n1 = 1 THEN match_s1_n1.id\n",
    "    WHEN s1_n2 = 1 THEN match_s1_n2.id\n",
    "    WHEN s1_n5 = 1 THEN match_s1_n5.id\n",
    "    \n",
    "    WHEN s6_n1 = 1 THEN match_s6_n1.id\n",
    "    WHEN s6_n2 = 1 THEN match_s6_n2.id\n",
    "    WHEN s6_n5 = 1 THEN match_s6_n5.id\n",
    "    WHEN s6_n6 = 1 THEN match_s6_n6.id\n",
    "    WHEN s6_n8 = 1 THEN match_s6_n8.id\n",
    "\n",
    "    WHEN s2_n1 = 1 THEN match_s2_n1.id\n",
    "    WHEN s2_n2 = 1 THEN match_s2_n2.id\n",
    "    WHEN s2_n5 = 1 THEN match_s2_n5.id\n",
    "    WHEN s2_n6 = 1 THEN match_s2_n6.id\n",
    "    WHEN s2_n8 = 1 THEN match_s2_n8.id\n",
    "\n",
    "    WHEN s4_n1 = 1 THEN match_s4_n1.id\n",
    "    WHEN s4_n2 = 1 THEN match_s4_n2.id\n",
    "    WHEN s4_n5 = 1 THEN match_s4_n5.id\n",
    "    WHEN s4_n6 = 1 THEN match_s4_n6.id\n",
    "    WHEN s4_n8 = 1 THEN match_s4_n8.id\n",
    "\n",
    "    WHEN s5_n1 = 1 THEN match_s5_n1.id\n",
    "    WHEN s5_n2 = 1 THEN match_s5_n2.id\n",
    "    WHEN s5_n5 = 1 THEN match_s5_n5.id\n",
    "    WHEN s5_n6 = 1 THEN match_s5_n6.id\n",
    "    WHEN s5_n8 = 1 THEN match_s5_n8.id\n",
    "\n",
    "    WHEN s3_n1 = 1 THEN match_s3_n1.id\n",
    "    WHEN s3_n2 = 1 THEN match_s3_n2.id\n",
    "    WHEN s3_n5 = 1 THEN match_s3_n5.id\n",
    "\n",
    "    ELSE NULL\n",
    "  END AS existing_author_id\n",
    "\n",
    "FROM aggregated_counts\n",
    ")\n",
    "SELECT * FROM final_decision;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c7d261f-6c11-4e07-93bf-ea5b4f2db097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Cluster Unmatched & Mint New IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeee6ee9-c9c7-46a5-8f92-2d32210564c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- A. Get the current High Water Mark\n",
    "DECLARE OR REPLACE VARIABLE max_id BIGINT;\n",
    "SET VARIABLE max_id = (SELECT MAX(id) FROM openalex.authors.author_registry);\n",
    "\n",
    "-- B. Cluster and Mint\n",
    "CREATE OR REPLACE TABLE openalex.authors.author_matching_new_author_queue AS\n",
    "WITH unmatched_with_hash AS (\n",
    "    SELECT \n",
    "        pa.work_id,\n",
    "        pa.author_sequence,\n",
    "        pa.raw_author_name,\n",
    "        \n",
    "        xxhash64(\n",
    "            -- 1. NAME PART: Parsed if available, else Raw\n",
    "            CASE \n",
    "                WHEN pa.parsed_name.first IS NOT NULL AND pa.parsed_name.first <> '' \n",
    "                     AND pa.parsed_name.last IS NOT NULL AND pa.parsed_name.last <> ''\n",
    "                THEN LOWER(CONCAT(pa.parsed_name.first, ' ', pa.parsed_name.last))\n",
    "                ELSE LOWER(TRIM(pa.raw_author_name))\n",
    "            END,\n",
    "            -- 2. SIGNAL PART: Institutions -> Sources\n",
    "            CASE \n",
    "                WHEN SIZE(b.all_institution_ids) > 0\n",
    "                THEN concat_ws('|', sort_array(b.all_institution_ids))\n",
    "                ELSE concat_ws('|', sort_array(pa.work_source_ids))\n",
    "            END\n",
    "        ) AS cluster_hash\n",
    "\n",
    "    FROM openalex.authors.pending_author_assignments pa\n",
    "    --  Join Batch to get 'all_institution_ids'\n",
    "    LEFT JOIN openalex.authors.author_matching_batch b\n",
    "        ON pa.work_id = b.work_id AND pa.author_sequence = b.author_sequence\n",
    "    LEFT JOIN openalex.works.openalex_works_base w\n",
    "        ON pa.work_id = w.id\n",
    "    LEFT JOIN openalex.works.work_authors existing\n",
    "        ON pa.work_id = existing.work_id \n",
    "        AND pa.author_sequence = existing.author_sequence\n",
    "    WHERE \n",
    "        -- Only unmatched records\n",
    "        pa.match_outcome <> 'MATCHED'\n",
    "        -- ensure we haven't already assigned an ID in a previous run\n",
    "        AND existing.author_id IS NULL\n",
    "        -- Only mint IDs for new works, after the author start assignment date\n",
    "        AND pa.work_id > 7000000000\n",
    "        AND w.created_date >= to_timestamp('2025-12-20') \n",
    "        -- Safety: Ensure we actually have a name string to hash\n",
    "        AND pa.raw_author_name IS NOT NULL \n",
    "        AND TRIM(pa.raw_author_name) <> ''\n",
    "),\n",
    "unique_clusters AS (\n",
    "    SELECT \n",
    "        cluster_hash,\n",
    "        MAX_BY(raw_author_name, length(raw_author_name)) as raw_display_name,\n",
    "        monotonically_increasing_id() as batch_row_id\n",
    "    FROM unmatched_with_hash\n",
    "    GROUP BY cluster_hash\n",
    ")\n",
    "SELECT \n",
    "    uc.cluster_hash,\n",
    "    CASE \n",
    "        WHEN SIZE(SPLIT(uc.raw_display_name, ',')) = 2 THEN \n",
    "            TRIM(SPLIT(uc.raw_display_name, ',')[1]) || ' ' || TRIM(SPLIT(uc.raw_display_name, ',')[0])\n",
    "        ELSE \n",
    "            uc.raw_display_name \n",
    "    END AS display_name,\n",
    "    max_id + ROW_NUMBER() OVER (ORDER BY uc.batch_row_id) AS new_author_id\n",
    "FROM unique_clusters uc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2489ab-35fe-4b49-a19f-be6fc9318bd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- logging: review match rates\n",
    "SELECT \n",
    "    pa.match_outcome, \n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "FROM openalex.authors.pending_author_assignments pa\n",
    "JOIN openalex.works.openalex_works_base w \n",
    "    ON pa.work_id = w.id\n",
    "WHERE pa.work_id > 7000000000 \n",
    "  AND w.created_date >= to_timestamp('2025-12-20')\n",
    "GROUP BY pa.match_outcome\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- 2. MINTING STATS\n",
    "SELECT \n",
    "    'NEW_AUTHORS_TO_CREATE' as match_outcome,\n",
    "    COUNT(*) as count,\n",
    "    NULL as percentage\n",
    "FROM openalex.authors.author_matching_new_author_queue;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "653b16ff-9de8-4a4b-a0ce-a41b7d0672c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 4: Write New Authors to Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3687e7e2-f771-43ef-905c-bf799348da27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INSERT INTO openalex.authors.author_registry \n",
    "    (id, display_name, merge_into_id, merge_into_date, created_date, updated_date)\n",
    "SELECT \n",
    "    new_author_id AS id,\n",
    "    display_name,\n",
    "    NULL AS merge_into_id,\n",
    "    NULL AS merge_into_date,\n",
    "    current_timestamp() AS created_date,\n",
    "    current_timestamp() AS updated_date\n",
    "FROM openalex.authors.author_matching_new_author_queue;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce1f0b9f-3852-4544-8b8c-f56396a77d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 5: Consolidate Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a9b5447-f064-4fdb-a51f-c7b9b4531be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TEMPORARY VIEW batch_author_decisions AS\nSELECT \n    b.work_id,\n    b.author_sequence,\n    b.raw_author_name,\n    b.affiliation_structs,\n    \n    CASE \n        WHEN w.created_date >= to_timestamp('2025-12-20') \n            AND b.work_id > 7000000000\n        THEN COALESCE(pa.existing_author_id, q.new_author_id)\n        ELSE lwa.author_id  -- Use legacy author_id for older works\n    END AS final_author_id\n\nFROM openalex.authors.author_matching_batch b\n\nLEFT JOIN openalex.authors.pending_author_assignments pa\n    ON b.work_id = pa.work_id \n    AND b.author_sequence = pa.author_sequence\n\nLEFT JOIN openalex.works.openalex_works_base w\n    ON b.work_id = w.id\n\nLEFT JOIN openalex.works_legacy.work_authors lwa\n    ON b.work_id = lwa.work_id\n    AND b.author_sequence = lwa.author_sequence\n\nLEFT JOIN openalex.authors.author_matching_new_author_queue q\n    ON (pa.match_outcome IS NULL OR pa.match_outcome <> 'MATCHED')\n    AND xxhash64(\n            CASE \n               WHEN pa.parsed_name.first IS NOT NULL AND pa.parsed_name.first <> '' \n                AND pa.parsed_name.last IS NOT NULL AND pa.parsed_name.last <> ''\n               THEN LOWER(CONCAT(pa.parsed_name.first, ' ', pa.parsed_name.last))\n               ELSE LOWER(TRIM(b.raw_author_name))\n            END,\n            CASE \n                WHEN SIZE(b.all_institution_ids) > 0 \n                THEN concat_ws('|', sort_array(b.all_institution_ids))\n                ELSE concat_ws('|', sort_array(pa.work_source_ids))\n            END\n        ) = q.cluster_hash;"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fe45ea0-50d1-45b5-93cc-bc0a81f86a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 6: Update work_authors Table and refresh related view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44bd7537-582f-458c-bbe0-3ca6add0b412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "MERGE INTO openalex.works.work_authors AS target\nUSING (\n    SELECT\n        source.work_id,\n        source.author_sequence,\n        source.final_author_id,\n        source.raw_author_name,\n        ARRAY_COMPACT(ARRAY_DISTINCT(COLLECT_LIST(aff.raw_string))) AS raw_affiliation_strings,\n        MAX(w_auth.is_corresponding) AS is_corresponding,\n        MAX(wb.updated_date) AS source_updated_date\n\n    FROM (\n        SELECT *\n        FROM batch_author_decisions\n        LATERAL VIEW OUTER EXPLODE(affiliation_structs) t AS aff\n    ) source\n    LEFT JOIN (\n        SELECT\n            id AS work_id,\n            author_sequence,\n            authorship.is_corresponding\n        FROM openalex.works.openalex_works_base\n        LATERAL VIEW POSEXPLODE(authorships) t AS author_sequence, authorship\n    ) w_auth\n        ON source.work_id = w_auth.work_id\n        AND source.author_sequence = w_auth.author_sequence\n    LEFT JOIN openalex.works.openalex_works_base wb\n        ON source.work_id = wb.id\n    GROUP BY source.work_id, source.author_sequence, source.final_author_id, source.raw_author_name\n) AS source\nON target.work_id = source.work_id\n   AND target.author_sequence = source.author_sequence\n\nWHEN MATCHED THEN\n    UPDATE SET\n        target.author_id = COALESCE(target.author_id, source.final_author_id),\n        target.raw_author_name = source.raw_author_name,\n        target.raw_affiliation_strings = source.raw_affiliation_strings,\n        target.is_corresponding = source.is_corresponding,\n        target.updated_at = source.source_updated_date\n\nWHEN NOT MATCHED THEN\n    INSERT (\n        work_id, author_sequence, author_id,\n        raw_author_name, raw_affiliation_strings, is_corresponding,\n        created_at, updated_at\n    )\n    VALUES (\n        source.work_id, source.author_sequence, source.final_author_id,\n        source.raw_author_name, source.raw_affiliation_strings, source.is_corresponding,\n        current_timestamp(), source.source_updated_date\n    );"
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "UpdateWorkAuthors",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "63ca0d89-47c7-4cad-b218-3222126b5a91",
     "typedWidgetInfo": {
      "autoCreated": true,
      "defaultValue": "",
      "label": null,
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": true,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}