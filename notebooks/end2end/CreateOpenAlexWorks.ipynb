{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb11992-988b-4aea-be61-4f52efe22c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create `openalex_works` table, include curation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528f31e8-8785-4cc1-986f-74cbc29940b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Register helper function\n",
    "CREATE FUNCTION IF NOT EXISTS get_highest_priority_value(\n",
    "    all_structs ARRAY<STRUCT<field_value: STRING, priority: INT>>, field_name STRING\n",
    ") RETURNS STRING\n",
    "RETURN (\n",
    "    SELECT AGGREGATE(\n",
    "        FILTER(all_structs, y -> y.field_value IS NOT NULL),\n",
    "        STRUCT(CAST(NULL AS STRING) AS field_value, 999 AS priority),\n",
    "        (acc, x) -> CASE WHEN x.priority < acc.priority THEN x ELSE acc END\n",
    "    ).field_value\n",
    ");\n",
    "\n",
    "-- Final pipeline to create openalex_works\n",
    "CREATE OR REPLACE TABLE identifier('openalex' || :env_suffix || '.works.openalex_works') \n",
    "CLUSTER BY (id, doi)\n",
    "TBLPROPERTIES (\n",
    "  'delta.dataSkippingNumIndexedCols' = 36,\n",
    "  'delta.deletedFileRetentionDuration' = '60 days', -- default is 7\n",
    "  'delta.logRetentionDuration' = '60 days'          -- default is 30\n",
    ")\n",
    "AS (\n",
    "WITH mat_sources AS (\n",
    "    SELECT s.id AS source_id, s.display_name, s.issn AS issn_l, s.issns, s.is_in_doaj, s.is_core,\n",
    "           s.publisher AS source_publisher, s.publisher_id, s.institution_id, s.repository_id,\n",
    "           s.apc_prices AS apc_prices,\n",
    "           s.apc_usd, s.type AS source_type,\n",
    "           i.display_name AS institution_name, p.display_name AS publisher_name,\n",
    "           s.is_in_doaj_start_year, s.high_oa_rate_start_year, s.is_oa_high_oa_rate, s.is_fully_open_in_jstage, s.doaj_license\n",
    "    FROM openalex.sources.sources s\n",
    "    LEFT JOIN openalex.institutions.institutions i ON s.institution_id = i.id\n",
    "    LEFT JOIN openalex.publishers.publishers p ON s.publisher_id = p.id\n",
    "),\n",
    "\n",
    "priority_table AS (-- some comment\n",
    "    SELECT * FROM openalex.system.priority_table\n",
    "),\n",
    "\n",
    "base AS (\n",
    "    SELECT a.work_id, a.provenance, a.native_id, a.native_id_namespace, a.best_doi, a.title, a.type,\n",
    "           a.abstract, a.referenced_works_count,a.referenced_works,a.abstract_inverted_index, \n",
    "           b.priority, a.openalex_created_dt, a.openalex_updated_dt,\n",
    "           s.source_id, s.display_name, s.issn_l, s.issns, s.is_in_doaj,\n",
    "           CASE WHEN GET(s.apc_prices, 0) IS NULL THEN NULL ELSE s.apc_prices END AS apc_prices,\n",
    "           s.apc_usd, s.is_core, a.is_oa, COALESCE(a.is_oa, FALSE) AS is_oa_raw,\n",
    "           COALESCE(s.is_in_doaj, FALSE) AS is_in_doaj_raw,\n",
    "           COALESCE(is_in_doaj_raw AND (ISNULL(s.is_in_doaj_start_year) OR YEAR(a.published_date) >= s.is_in_doaj_start_year), FALSE) AS is_in_doaj_stg,\n",
    "           COALESCE(\n",
    "              s.is_oa_high_oa_rate AND (\n",
    "                  ISNULL(s.high_oa_rate_start_year) OR \n",
    "                  YEAR(a.published_date) >= s.high_oa_rate_start_year\n",
    "              ) OR s.is_fully_open_in_jstage, \n",
    "              FALSE\n",
    "           ) AS is_oa_high_rate,\n",
    "           (is_oa_high_rate or is_in_doaj_stg) AS source_is_oa,\n",
    "           (is_oa_raw OR source_is_oa) AS composite_is_oa,\n",
    "           s.is_in_doaj_start_year, s.source_type, a.source_name, a.publisher, a.published_date, a.volume, a.issue, a.first_page, a.last_page,\n",
    "           COALESCE(a.language_classification.language, a.language) as language, a.authors,\n",
    "           TRANSFORM(a.urls, x -> STRUCT(REGEXP_REPLACE(x.url, 'dx.doi.org', 'doi.org') AS url, x.content_type)) AS urls,\n",
    "           CASE\n",
    "              WHEN is_in_doaj_stg AND s.doaj_license IS NOT NULL\n",
    "                THEN s.doaj_license\n",
    "              ELSE a.license\n",
    "            END AS license,\n",
    "           s.institution_name, s.publisher_name, s.institution_id, s.publisher_id, a.version,\n",
    "           CASE WHEN LOWER(a.native_id) LIKE '%arxiv.org%' THEN COALESCE(GET(FILTER(a.urls, x -> x.content_type = 'html').url, 0), a.landing_page_url) ELSE a.landing_page_url END AS landing_page_url,\n",
    "           CASE WHEN LOWER(a.native_id) LIKE '%arxiv.org%' THEN COALESCE(CONCAT('https://arxiv.org/pdf/', SPLIT_PART(a.native_id, ':', 3)), a.pdf_url) ELSE a.pdf_url END AS pdf_url,\n",
    "           a.is_retracted, s.repository_id,\n",
    "           ROW_NUMBER() OVER (PARTITION BY a.work_id, a.provenance ORDER BY a.created_date DESC) AS row_num,\n",
    "           CASE\n",
    "              WHEN s.source_id IS NULL THEN NULL\n",
    "              WHEN (a.provenance = 'crossref' AND s.source_type != 'repository') THEN 'publisher' \n",
    "              ELSE 'repository' \n",
    "           END AS host_type,\n",
    "           CASE WHEN composite_is_oa AND host_type = 'publisher' THEN\n",
    "              CASE WHEN ZEROIFNULL(s.apc_usd) = 0 AND source_is_oa THEN 1\n",
    "                WHEN source_is_oa THEN 2\n",
    "                WHEN a.license IS NOT NULL AND a.license != 'publisher-specific-oa' THEN 3\n",
    "                ELSE 4 END\n",
    "              WHEN host_type IS NULL AND (a.is_oa OR composite_is_oa) THEN 2\n",
    "              WHEN (a.is_oa OR composite_is_oa) AND host_type = 'repository' THEN 5\n",
    "              ELSE 6 END AS oa_status\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.locations_mapped') a\n",
    "    LEFT JOIN priority_table b USING (provenance)\n",
    "    LEFT JOIN mat_sources s ON a.source_id = s.source_id\n",
    "    QUALIFY row_num <= 10\n",
    "),\n",
    "\n",
    "-- CURATION BLOCK\n",
    "curation_requests_clean AS (\n",
    "    WITH ranked AS (\n",
    "        SELECT LOWER(TRIM(REGEXP_REPLACE(doi, '^https?://(dx\\\\.)?doi\\\\.org/', ''))) AS doi,\n",
    "               TRIM(previous_url) AS prev_url, TRIM(new_url) AS new_url,\n",
    "               ROW_NUMBER() OVER (PARTITION BY LOWER(TRIM(REGEXP_REPLACE(doi, '^https?://(dx\\\\.)?doi\\\\.org/', ''))), TRIM(previous_url) ORDER BY ingestion_timestamp DESC) AS rn\n",
    "        FROM openalex.unpaywall.curation_requests\n",
    "    )\n",
    "    SELECT doi, prev_url, new_url FROM ranked WHERE rn = 1\n",
    "),\n",
    "\n",
    "cr_matches AS (\n",
    "    SELECT b.*, c.new_url\n",
    "    FROM base b\n",
    "    JOIN curation_requests_clean c ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE c.prev_url IS NOT NULL AND (\n",
    "        REGEXP_REPLACE(LOWER(COALESCE(b.pdf_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '') OR\n",
    "        REGEXP_REPLACE(LOWER(COALESCE(b.landing_page_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '') OR\n",
    "        ARRAY_CONTAINS(TRANSFORM(b.urls, u -> REGEXP_REPLACE(LOWER(u.url), '^https?://', '') = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '')), TRUE)\n",
    "    )\n",
    "),\n",
    "\n",
    "cr_upserts AS (\n",
    "-- curation upserts\n",
    "    SELECT\n",
    "        b.work_id, b.provenance, b.native_id, b.native_id_namespace,\n",
    "        b.best_doi, b.title, b.type, b.abstract, \n",
    "        b.referenced_works_count, b.referenced_works, b.abstract_inverted_index,\n",
    "        b.priority, b.openalex_created_dt, b.openalex_updated_dt,\n",
    "        b.source_id, b.display_name, b.issn_l, b.issns, b.is_in_doaj,\n",
    "        b.apc_prices, b.apc_usd, b.is_core, b.is_oa, b.is_oa_raw,\n",
    "        b.is_in_doaj_raw, b.is_in_doaj_stg, b.is_oa_high_rate,\n",
    "        b.source_is_oa, b.composite_is_oa, b.is_in_doaj_start_year,\n",
    "        b.source_type, b.source_name, b.publisher, b.published_date,\n",
    "        b.volume, b.issue, b.first_page, b.last_page, b.language,\n",
    "        b.authors, \n",
    "        \n",
    "        /* Update the urls array using normalized comparison */\n",
    "        transform(b.urls, u -> \n",
    "            struct(\n",
    "              CASE \n",
    "                WHEN regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN c.new_url\n",
    "                ELSE u.url\n",
    "              END as url,\n",
    "              u.content_type\n",
    "            )\n",
    "        ) AS urls,\n",
    "        \n",
    "        b.license, b.institution_name,\n",
    "        b.publisher_name, b.institution_id, b.publisher_id, b.version,\n",
    "\n",
    "        /* 44   landing_page_url  (may be replaced) --------------------- */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.landing_page_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN c.new_url\n",
    "          ELSE b.landing_page_url\n",
    "        END                                                   AS landing_page_url,\n",
    "\n",
    "        /* 45   pdf_url  (may be replaced) ------------------------------ */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN c.new_url\n",
    "          ELSE b.pdf_url\n",
    "        END                                                   AS pdf_url,\n",
    "\n",
    "        /* 46–52 : trailing columns in correct order -------------------- */\n",
    "        b.is_retracted,\n",
    "        b.repository_id,\n",
    "        b.row_num,\n",
    "        b.host_type,\n",
    "        b.oa_status\n",
    "    FROM   base AS b\n",
    "    JOIN   curation_requests_clean c\n",
    "      ON   lower(b.best_doi) = c.doi\n",
    "      AND  (\n",
    "              regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "              OR regexp_replace(lower(coalesce(b.landing_page_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "              OR array_contains(\n",
    "                  transform(b.urls, u -> regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')),\n",
    "                  true\n",
    "              )\n",
    "          )\n",
    "    WHERE  c.prev_url IS NOT NULL\n",
    "      AND  c.new_url  IS NOT NULL      -- replacement, not nullification\n",
    "),\n",
    "\n",
    "cr_nullify AS (\n",
    "    SELECT\n",
    "        b.work_id, b.provenance, b.native_id, b.native_id_namespace,\n",
    "        b.best_doi, b.title, b.type, b.abstract, b.referenced_works_count, b.referenced_works, b.abstract_inverted_index,\n",
    "        b.priority, b.openalex_created_dt, b.openalex_updated_dt,\n",
    "        b.source_id, b.display_name, b.issn_l, b.issns, b.is_in_doaj, \n",
    "        b.apc_prices, b.apc_usd, b.is_core, \n",
    "        \n",
    "        /* Update is_oa to false if pdf_url is being nullified */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN false\n",
    "          ELSE b.is_oa\n",
    "        END AS is_oa,\n",
    "        \n",
    "        /* Update is_oa_raw to false if pdf_url is being nullified */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN false\n",
    "          ELSE b.is_oa_raw\n",
    "        END AS is_oa_raw,\n",
    "        \n",
    "        b.is_in_doaj_raw, b.is_in_doaj_stg, b.is_oa_high_rate,\n",
    "        b.source_is_oa, \n",
    "        \n",
    "        /* Update composite_is_oa to account for nullified pdf_url */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN b.source_is_oa  /* When pdf_url is nullified, composite_is_oa depends only on source_is_oa */\n",
    "          ELSE b.composite_is_oa\n",
    "        END AS composite_is_oa,\n",
    "        \n",
    "        b.is_in_doaj_start_year,\n",
    "        b.source_type, b.source_name, b.publisher, b.published_date,\n",
    "        b.volume, b.issue, b.first_page, b.last_page, b.language,\n",
    "        b.authors, \n",
    "        \n",
    "        /* Update the urls array to nullify matched URLs using normalized comparison */\n",
    "        transform(b.urls, u -> \n",
    "            struct(\n",
    "              CASE \n",
    "                WHEN regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN null\n",
    "                ELSE u.url\n",
    "              END as url,\n",
    "              u.content_type\n",
    "            )\n",
    "        ) AS urls,\n",
    "        \n",
    "        b.license, b.institution_name,\n",
    "        b.publisher_name, b.institution_id, b.publisher_id, b.version,\n",
    "\n",
    "        /* 44   landing_page_url  (set to null if matched) ------------- */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.landing_page_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN null\n",
    "          ELSE b.landing_page_url\n",
    "        END                                                   AS landing_page_url,\n",
    "\n",
    "        /* 45   pdf_url  (set to null if matched) ---------------------- */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN null\n",
    "          ELSE b.pdf_url\n",
    "        END                                                   AS pdf_url,\n",
    "\n",
    "        /* 46–52 : trailing columns in correct order -------------------- */\n",
    "        b.is_retracted,\n",
    "        b.repository_id,\n",
    "        b.row_num,\n",
    "        b.host_type,\n",
    "        \n",
    "        /* Update oa_status to closed (6) if pdf_url is nullified */\n",
    "        CASE\n",
    "          WHEN regexp_replace(lower(coalesce(b.pdf_url,'')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "               THEN 6  /* closed */\n",
    "          ELSE b.oa_status\n",
    "        END AS oa_status\n",
    "        \n",
    "    FROM   base AS b\n",
    "    JOIN   curation_requests_clean c\n",
    "      ON   lower(b.best_doi) = c.doi\n",
    "      AND  (\n",
    "              regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "              OR regexp_replace(lower(coalesce(b.landing_page_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "              OR array_contains(\n",
    "                  transform(b.urls, u -> regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')),\n",
    "                  true\n",
    "              )\n",
    "          )\n",
    "    WHERE  c.prev_url IS NOT NULL\n",
    "      AND  c.new_url IS NULL         -- nullification, not update\n",
    "),\n",
    "\n",
    "cr_mark_oa AS (\n",
    "    SELECT\n",
    "        b.work_id, b.provenance, b.native_id, b.native_id_namespace,\n",
    "        b.best_doi, b.title, b.type, b.abstract, b.referenced_works_count, b.referenced_works, b.abstract_inverted_index,\n",
    "        b.priority, b.openalex_created_dt, b.openalex_updated_dt,\n",
    "        b.source_id, b.display_name, b.issn_l, b.issns, b.is_in_doaj,\n",
    "        b.apc_prices, b.apc_usd, b.is_core, \n",
    "        \n",
    "        TRUE AS is_oa,\n",
    "        TRUE AS is_oa_raw,\n",
    "        b.is_in_doaj_raw, b.is_in_doaj_stg, b.is_oa_high_rate,\n",
    "        b.source_is_oa, \n",
    "        \n",
    "        /* composite_is_oa only matters for publisher rows */\n",
    "        CASE WHEN b.host_type = 'publisher'\n",
    "             THEN TRUE\n",
    "             ELSE b.composite_is_oa \n",
    "        END AS composite_is_oa,\n",
    "        \n",
    "        b.is_in_doaj_start_year,\n",
    "        b.source_type, b.source_name, b.publisher, b.published_date,\n",
    "        b.volume, b.issue, b.first_page, b.last_page, b.language,\n",
    "        b.authors, b.urls, b.license, b.institution_name,\n",
    "        b.publisher_name, b.institution_id, b.publisher_id, b.version,\n",
    "        b.landing_page_url, b.pdf_url,\n",
    "        b.is_retracted, b.repository_id, b.row_num, b.host_type,\n",
    "\n",
    "        /* recompute oa_status the same way base does */\n",
    "        CASE\n",
    "          WHEN b.host_type = 'publisher' THEN\n",
    "               CASE WHEN ZEROIFNULL(b.apc_usd) = 0 AND b.source_is_oa THEN 1   -- diamond\n",
    "                    WHEN b.source_is_oa                       THEN 2           -- gold\n",
    "                    WHEN b.license IS NOT NULL\n",
    "                         AND b.license <> 'publisher-specific-oa' THEN 3       -- hybrid\n",
    "                    ELSE 4                                                    -- bronze\n",
    "               END\n",
    "          ELSE 5   -- repository => green\n",
    "        END AS oa_status\n",
    "        \n",
    "    FROM base b\n",
    "    JOIN curation_requests_clean c\n",
    "      ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE c.prev_url IS NULL\n",
    "      AND c.new_url IS NOT NULL\n",
    "      AND (\n",
    "            REGEXP_REPLACE(LOWER(COALESCE(b.pdf_url,'')),     '^https?://','')\n",
    "                   = REGEXP_REPLACE(LOWER(c.new_url),'^https?://','')\n",
    "         OR REGEXP_REPLACE(LOWER(COALESCE(b.landing_page_url,'')),'^https?://','')\n",
    "                   = REGEXP_REPLACE(LOWER(c.new_url),'^https?://','')\n",
    "         OR ARRAY_CONTAINS(\n",
    "                TRANSFORM(b.urls,\n",
    "                         u -> REGEXP_REPLACE(LOWER(u.url),'^https?://','')\n",
    "                                  = REGEXP_REPLACE(LOWER(c.new_url),'^https?://','')),\n",
    "                TRUE)\n",
    "          )\n",
    "),\n",
    "\n",
    "base_filtered AS (\n",
    "    SELECT * FROM base b WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM cr_matches m WHERE m.work_id = b.work_id AND m.provenance = b.provenance AND (\n",
    "            REGEXP_REPLACE(LOWER(COALESCE(m.pdf_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(COALESCE(b.pdf_url, '')), '^https?://', '') OR\n",
    "            REGEXP_REPLACE(LOWER(COALESCE(m.landing_page_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(COALESCE(b.landing_page_url, '')), '^https?://', '')\n",
    "        )\n",
    "    ) AND NOT EXISTS (\n",
    "        SELECT 1 FROM cr_mark_oa o\n",
    "         WHERE o.work_id   = b.work_id\n",
    "           AND o.provenance = b.provenance\n",
    "      )\n",
    "),\n",
    "\n",
    "cr_new_locations AS (\n",
    "    -- new locations for curation requests that don't match existing URLs\n",
    "    SELECT\n",
    "        b.work_id, \n",
    "        'curation' AS provenance,\n",
    "        b.native_id,\n",
    "        b.native_id_namespace,\n",
    "        b.best_doi, \n",
    "        b.title, \n",
    "        b.type, \n",
    "        b.abstract, \n",
    "        b.referenced_works_count,\n",
    "        b.referenced_works, \n",
    "        b.abstract_inverted_index,\n",
    "        999 AS priority,\n",
    "        b.openalex_created_dt, \n",
    "        CURRENT_TIMESTAMP() AS openalex_updated_dt,\n",
    "        b.source_id,  -- Use existing source\n",
    "        b.display_name,\n",
    "        b.issn_l,\n",
    "        b.issns,\n",
    "        b.is_in_doaj,\n",
    "        b.apc_prices,\n",
    "        b.apc_usd,\n",
    "        b.is_core,\n",
    "        TRUE AS is_oa,\n",
    "        TRUE AS is_oa_raw,\n",
    "        b.is_in_doaj_raw,\n",
    "        b.is_in_doaj_stg,\n",
    "        b.is_oa_high_rate,\n",
    "        b.source_is_oa,\n",
    "        TRUE AS composite_is_oa,\n",
    "        b.is_in_doaj_start_year,\n",
    "        b.source_type,\n",
    "        b.source_name,\n",
    "        b.publisher,\n",
    "        b.published_date,\n",
    "        b.volume,\n",
    "        b.issue,\n",
    "        b.first_page,\n",
    "        b.last_page,\n",
    "        b.language,\n",
    "        b.authors,\n",
    "      \n",
    "        ARRAY(STRUCT(c.new_url AS url, \n",
    "                    CASE \n",
    "                        WHEN LOWER(c.new_url) LIKE '%.pdf%' OR LOWER(c.new_url) LIKE '%/pdf/%' THEN 'pdf'\n",
    "                        ELSE 'html'\n",
    "                    END AS content_type)) AS urls,\n",
    "        \n",
    "        NULL AS license,\n",
    "        b.institution_name,\n",
    "        b.publisher_name,\n",
    "        b.institution_id,\n",
    "        b.publisher_id,\n",
    "        'publishedVersion' AS version,\n",
    "        \n",
    "        -- Set landing_page_url or pdf_url based on URL type\n",
    "        CASE \n",
    "            WHEN LOWER(c.new_url) LIKE '%.pdf%' OR LOWER(c.new_url) LIKE '%/pdf/%' THEN NULL\n",
    "            ELSE c.new_url\n",
    "        END AS landing_page_url,\n",
    "        \n",
    "        CASE \n",
    "            WHEN LOWER(c.new_url) LIKE '%.pdf%' OR LOWER(c.new_url) LIKE '%/pdf/%' THEN c.new_url\n",
    "            ELSE NULL\n",
    "        END AS pdf_url,\n",
    "        \n",
    "        b.is_retracted,\n",
    "        b.repository_id,\n",
    "        1 AS row_num,\n",
    "        b.host_type,\n",
    "        CASE WHEN b.composite_is_oa AND b.host_type = 'publisher' THEN\n",
    "                CASE WHEN ZEROIFNULL(b.apc_usd) = 0 AND b.source_is_oa THEN 1\n",
    "                     WHEN b.source_is_oa THEN 2  -- gold\n",
    "                     ELSE 4 END  -- bronze\n",
    "                WHEN b.host_type = 'repository' THEN 5\n",
    "                ELSE 4 END AS oa_status\n",
    "        \n",
    "    FROM curation_requests_clean c\n",
    "    INNER JOIN base b ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE c.new_url IS NOT NULL \n",
    "      AND c.prev_url IS NULL  -- this indicates a new URL addition, not a replacement\n",
    "      AND NOT EXISTS (\n",
    "          -- Ensure this URL doesn't already exist for this work\n",
    "          SELECT 1 FROM base b2 \n",
    "          WHERE b2.work_id = b.work_id \n",
    "          AND (\n",
    "              REGEXP_REPLACE(LOWER(COALESCE(b2.pdf_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '') OR\n",
    "              REGEXP_REPLACE(LOWER(COALESCE(b2.landing_page_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '') OR\n",
    "              ARRAY_CONTAINS(TRANSFORM(b2.urls, u -> REGEXP_REPLACE(LOWER(u.url), '^https?://', '') = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')), TRUE)\n",
    "          )\n",
    "      )\n",
    "),\n",
    "\n",
    "base_with_cr AS (\n",
    "    SELECT * FROM base_filtered\n",
    "    UNION ALL SELECT * FROM cr_upserts\n",
    "    UNION ALL SELECT * FROM cr_nullify\n",
    "    UNION ALL SELECT * FROM cr_new_locations\n",
    "    UNION ALL SELECT * FROM cr_mark_oa\n",
    "),\n",
    "\n",
    "-- deduplicate and rank landing page urls\n",
    "base_with_landing_page_rank AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    row_number() OVER (\n",
    "      PARTITION BY \n",
    "        work_id,\n",
    "        coalesce(landing_page_url, get(filter(urls, x -> x.content_type = \"html\").url, 0), '')\n",
    "      ORDER BY\n",
    "        case \n",
    "          when provenance = 'crossref' and best_doi is not null then 1\n",
    "          when provenance = 'crossref' then 2\n",
    "          when version = 'publishedVersion' and pdf_url is not null then 3\n",
    "          when version = 'publishedVersion' then 4\n",
    "          when version = 'acceptedVersion' and pdf_url is not null then 5\n",
    "          when version = 'acceptedVersion' then 6\n",
    "          when version = 'submittedVersion' and pdf_url is not null then 7\n",
    "          when version = 'submittedVersion' then 8\n",
    "          else 9\n",
    "        end,\n",
    "        -- Then by url_sort_score\n",
    "        case \n",
    "          when contains(coalesce(pdf_url, landing_page_url), \"europepmc.org\") then 1 \n",
    "          when contains(coalesce(pdf_url, landing_page_url), \"/pmc/\") then 2\n",
    "          when contains(coalesce(pdf_url, landing_page_url), \"arxiv\") then 3 \n",
    "          when contains(coalesce(pdf_url, landing_page_url), \".edu\") then 4 \n",
    "          else 5\n",
    "        end,\n",
    "        -- Finally by priority from priority_table\n",
    "        priority,\n",
    "        case when provenance in ('repo', 'repo_backfill') then native_id end\n",
    "    ) AS landing_page_rank\n",
    "  FROM base_with_cr\n",
    "),\n",
    "collect_all_values AS (\n",
    "  select\n",
    "    work_id,\n",
    "    collect_list(struct(best_doi, priority)) as best_dois,\n",
    "    collect_list(struct(title, priority)) as titles,\n",
    "    collect_list(struct(publisher, priority)) as publishers,\n",
    "    collect_list(struct(abstract, priority)) as abstracts,\n",
    "    array_distinct(flatten(collect_list(referenced_works))) as referenced_works, -- preserve natural order (whatever it may be), sort in JSON\n",
    "    collect_list(struct(abstract_inverted_index, priority)) as abstract_inverted_indexes,\n",
    "    collect_list(struct(volume, priority)) as volumes,\n",
    "    collect_list(struct(issue, priority)) as issues,\n",
    "    collect_list(struct(first_page, priority)) as first_pages,\n",
    "    collect_list(struct(last_page, priority)) as last_pages,\n",
    "    collect_list(struct(language, priority)) as languages,\n",
    "    collect_list(struct(type, priority)) as types,\n",
    "    filter(\n",
    "      collect_list(struct(published_date, priority)),\n",
    "      x -> x.published_date is not null\n",
    "    ) as published_dates,\n",
    "    filter(\n",
    "      collect_list(struct(openalex_created_dt, priority)),\n",
    "      x -> x.openalex_created_dt is not null\n",
    "    ) as openalex_created_dts,\n",
    "    filter(\n",
    "      collect_list(struct(openalex_updated_dt, priority)),\n",
    "      x -> x.openalex_updated_dt is not null\n",
    "    ) as openalex_updated_dts,\n",
    "    filter(\n",
    "      collect_set(struct(native_id_namespace, native_id)),\n",
    "      x -> lower(x.native_id_namespace) != 'pmh'\n",
    "    ) as ids,\n",
    "    -- locations\n",
    "    collect_set(\n",
    "      struct(\n",
    "        case when provenance = 'repo_backfill' then 'repo' else provenance end as provenance,\n",
    "        native_id,\n",
    "        case \n",
    "          when provenance =  'crossref' and best_doi is not null then 1 -- publisher with a doi\n",
    "          when provenance = 'crossref' then 2 -- publisher without a doi\n",
    "          when version = 'publishedVersion' and pdf_url is not null then 3 -- published version with a pdf url\n",
    "          when version = 'publishedVersion' then 4 -- published version without a pdf url\n",
    "          when version = 'acceptedVersion' and pdf_url is not null then 5 -- accepted version with a pdf url\n",
    "          when version = 'acceptedVersion' then 6 -- accepted version without a pdf url\n",
    "          when version = 'submittedVersion' and pdf_url is not null then 7 -- submitted version with a pdf url\n",
    "          when version = 'submittedVersion' then 8 -- submitted version without a pdf url\n",
    "          else 9\n",
    "        end as sort_score,\n",
    "        case when host_type = 'repository' then (is_oa_raw OR composite_is_oa) else composite_is_oa end as is_oa,\n",
    "        coalesce(landing_page_url, get(filter(urls, x -> x.content_type = \"html\").url, 0)) as landing_page_url,\n",
    "        pdf_url,\n",
    "        case \n",
    "        when contains(coalesce(pdf_url, landing_page_url), \"europepmc.org\") then 1 \n",
    "        when contains(coalesce(pdf_url, landing_page_url), \"/pmc/\") then 2\n",
    "        when contains(coalesce(pdf_url, landing_page_url), \"arxiv\") then 3 \n",
    "        when contains(coalesce(pdf_url, landing_page_url), \".edu\") then 4 \n",
    "        else 5\n",
    "        end as url_sort_score,\n",
    "        oa_status,\n",
    "        struct(\n",
    "          concat(\"https://openalex.org/S\", source_id) as id,\n",
    "          CASE \n",
    "            WHEN lower(trim(display_name)) = 'pubmed' AND COALESCE(trim(source_name), '') != '' THEN source_name\n",
    "            WHEN COALESCE(trim(display_name), '') != '' THEN display_name\n",
    "            WHEN COALESCE(trim(source_name), '') != '' THEN source_name\n",
    "            ELSE NULL\n",
    "          END AS display_name,\n",
    "          issn_l,\n",
    "          issns,\n",
    "          source_is_oa as is_oa,\n",
    "          is_in_doaj,\n",
    "          is_core,\n",
    "          case\n",
    "            when source_type = 'repository' then concat('https://openalex.org/I', institution_id)\n",
    "            else concat('https://openalex.org/P', publisher_id)\n",
    "          end as host_organization,\n",
    "          case\n",
    "          when\n",
    "            source_type = 'repository'\n",
    "          then\n",
    "            case\n",
    "              when REGEXP_EXTRACT(display_name, '\\\\(([^)]+)\\\\)', 1) = \"\" then display_name\n",
    "              else\n",
    "                concat(\n",
    "                  REGEXP_EXTRACT(display_name, '\\\\(([^)]+)\\\\)', 1),\n",
    "                  \" - \",\n",
    "                  REGEXP_REPLACE(display_name, '\\\\s*\\\\([^)]*\\\\)', '')\n",
    "                )\n",
    "            end\n",
    "          else publisher_name\n",
    "        end as host_organization_name,\n",
    "          source_type as type\n",
    "        ) as source,\n",
    "        apc_prices,\n",
    "        apc_usd,\n",
    "        license,\n",
    "        version,\n",
    "        host_type,\n",
    "        case when provenance in ('repo', 'repo_backfill') then repository_id end as endpoint_id,\n",
    "        case when provenance in ('repo', 'repo_backfill') then native_id end as pmh_id,\n",
    "        provenance = 'crossref' as is_unpaywall_record,\n",
    "        type as location_type,\n",
    "        cast(openalex_updated_dt as timestamp) as updated\n",
    "      )\n",
    "    ) as locations,\n",
    "    exists(collect_set(is_retracted), x -> x = True) as is_retracted,\n",
    "    array_contains(collect_set(provenance), 'crossref') as indexed_in_crossref\n",
    "  from\n",
    "    base_with_landing_page_rank\n",
    "  where\n",
    "    landing_page_rank = 1\n",
    "  group by\n",
    "    work_id\n",
    "),\n",
    "\n",
    "abstracts_backfill AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    abstract,\n",
    "    abstract_inverted_index\n",
    "  FROM openalex.abstracts.abstracts_backfill\n",
    "),\n",
    "\n",
    "set_fields AS (\n",
    "    SELECT\n",
    "      work_id as id,\n",
    "      get_highest_priority_value(titles, titles.title) AS title,\n",
    "      CONCAT('https://doi.org/', get_highest_priority_value(best_dois, best_dois.best_doi)) AS best_doi,\n",
    "      get_highest_priority_value(publishers, publishers.publisher) AS publisher,\n",
    "      get_highest_priority_value(\n",
    "        concat(\n",
    "          abstracts,\n",
    "          CASE\n",
    "            WHEN bf.abstract IS NOT NULL\n",
    "              THEN array(named_struct('abstract', bf.abstract, 'priority', 998))\n",
    "            ELSE array()\n",
    "          END\n",
    "        ),\n",
    "        abstracts.abstract\n",
    "      ) AS abstract,\n",
    "      SIZE(referenced_works) AS referenced_works_count,\n",
    "      referenced_works,\n",
    "      CASE\n",
    "        WHEN (\n",
    "              -- Springer/Elsevier by publisher string or host org id\n",
    "              (publisher IS NOT NULL\n",
    "              AND lower(publisher) RLIKE '(springer|elsevier)') OR\n",
    "              exists(\n",
    "                locations,\n",
    "                x -> x.source.host_organization IS NOT NULL\n",
    "                  AND get(split(x.source.host_organization, '/'), 4) IN ('P4310320990','P4310319965')\n",
    "              )\n",
    "            )\n",
    "            -- Allow only if best OA is diamond/gold/hybrid (1/2/3)\n",
    "            AND coalesce(\n",
    "                  try_element_at(\n",
    "                    transform(\n",
    "                      filter(locations, x -> x.is_oa),\n",
    "                      y -> y.oa_status\n",
    "                    ), 1\n",
    "                  ),\n",
    "                  0\n",
    "                ) NOT IN (1,2,3)\n",
    "          THEN NULL\n",
    "          ELSE get_highest_priority_value(\n",
    "                concat(\n",
    "                  abstract_inverted_indexes,\n",
    "                  CASE\n",
    "                    WHEN bf.abstract_inverted_index IS NOT NULL\n",
    "                      THEN array(named_struct('abstract_inverted_index', bf.abstract_inverted_index, 'priority', 998))\n",
    "                    ELSE array()\n",
    "                  END\n",
    "                ),\n",
    "                abstract_inverted_indexes.abstract_inverted_index\n",
    "              )\n",
    "      END AS abstract_inverted_index,\n",
    "      CASE WHEN id > 6600000000 THEN TRUE ELSE FALSE END AS is_xpac, \n",
    "      get_highest_priority_value(volumes, volumes.volume) AS volume,\n",
    "      get_highest_priority_value(issues, issues.issue) AS issue,\n",
    "      get_highest_priority_value(first_pages, first_pages.first_page) AS first_page,\n",
    "      get_highest_priority_value(last_pages, last_pages.last_page) AS last_page,\n",
    "      get_highest_priority_value(languages, languages.language) AS language,\n",
    "      get_highest_priority_value(types, types.type) AS type,\n",
    "      TRY_CAST(get_highest_priority_value(openalex_created_dts, openalex_created_dts.openalex_created_dt) AS DATE) AS created_date,\n",
    "      CAST(get_highest_priority_value(openalex_updated_dts, openalex_updated_dts.openalex_updated_dt) AS TIMESTAMP) AS updated_date,\n",
    "      TRY_CAST(get_highest_priority_value(published_dates, published_dates.published_date) AS DATE) AS publication_date,\n",
    "      YEAR(publication_date) AS publication_year,\n",
    "      MAP_FROM_ENTRIES(AGGREGATE(ids, ARRAY(NAMED_STRUCT('native_id_namespace', 'openalex', 'native_id', CONCAT('https://openalex.org/W', CAST(work_id AS STRING)))), (acc, x) -> CASE WHEN SIZE(FILTER(acc, y -> y.native_id_namespace = x.native_id_namespace)) = 0 THEN acc || ARRAY(x) ELSE acc END)) AS ids,\n",
    "      ARRAY_SORT(locations, (x, y) -> IF(x.sort_score < y.sort_score, -1, IF(x.sort_score > y.sort_score, 1, IF(x.url_sort_score < y.url_sort_score, -1, IF(x.url_sort_score > y.url_sort_score, 1, 0))))) AS locations_sorted,\n",
    "      authorships,\n",
    "      is_retracted,\n",
    "      indexed_in_crossref\n",
    "    FROM collect_all_values\n",
    "    LEFT JOIN identifier('openalex' || :env_suffix || '.works.authors_and_affiliations') USING (work_id)\n",
    "    LEFT JOIN abstracts_backfill bf USING (work_id)\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    s.id, s.best_doi AS doi, s.title, s.authorships, s.publication_date, s.publication_year, s.abstract, s.abstract IS NOT NULL AS has_abstract,\n",
    "    s.referenced_works_count, s.referenced_works, s.abstract_inverted_index,\n",
    "    CONCAT('https://api.openalex.org/works?filter=cites:W', CAST(s.id AS STRING)) AS cited_by_api_url,\n",
    "    CAST(0 AS INT) as cited_by_count,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<year: INT, cited_by_count: INT>>) AS counts_by_year,\n",
    "    CAST(0.0 AS DOUBLE) as fwci,\n",
    "    CAST(NULL AS STRUCT<value DOUBLE, is_in_top_1_percent BOOLEAN, is_in_top_10_percent BOOLEAN>) as citation_normalized_percentile,\n",
    "    CAST(NULL AS STRUCT<min INT, max INT>) as cited_by_percentile_year,\n",
    "    s.ids, s.language, s.publisher,\n",
    "    STRUCT(s.volume, s.issue, s.first_page, s.last_page) AS biblio,\n",
    "    CASE WHEN GET(GET(locations_sorted, 0).apc_prices, 0).price IS NOT NULL THEN STRUCT(GET(GET(locations_sorted, 0).apc_prices, 0).price AS value, GET(GET(locations_sorted, 0).apc_prices, 0).currency, GET(locations_sorted, 0).apc_usd AS value_usd) END AS apc_list,\n",
    "    CAST(NULL AS STRUCT<id STRING, display_name STRING, score FLOAT,\n",
    "        subfield STRUCT<id STRING, display_name STRING>,\n",
    "        field STRUCT<id STRING, display_name STRING>,\n",
    "        domain STRUCT<id STRING, display_name STRING>\n",
    "    >) AS primary_topic,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<id STRING, display_name STRING, score FLOAT,\n",
    "        subfield STRUCT<id STRING, display_name STRING>,\n",
    "        field STRUCT<id STRING, display_name STRING>,\n",
    "        domain STRUCT<id STRING, display_name STRING>\n",
    "    >>) AS topics,\n",
    "    CAST(NULL AS BIGINT) as topics_key,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<id STRING, display_name STRING, score FLOAT>>) AS keywords,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<id BIGINT, wikidata STRING, display_name STRING, level INT, score FLOAT>>) AS concepts,\n",
    "    SIZE(s.locations_sorted) AS locations_count,\n",
    "    TRANSFORM(s.locations_sorted, x -> STRUCT(COALESCE(x.is_oa, FALSE) AS is_oa, x.landing_page_url, x.pdf_url, x.source, x.license, x.version, x.oa_status, x.host_type, x.endpoint_id, x.pmh_id, x.is_unpaywall_record, x.location_type, CAST(x.updated AS TIMESTAMP) AS updated, x.provenance, x.native_id)) AS locations,\n",
    "    GET(locations, 0) AS primary_location,\n",
    "    GET(FILTER(locations, x -> x.is_oa), 0) AS best_oa_location,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<id STRING, display_name STRING, score FLOAT>>) AS sustainable_development_goals,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<funder STRING, funder_display_name STRING, award_id STRING>>) AS grants,\n",
    "    CAST(ARRAY() AS ARRAY<STRUCT<id STRING, funder_award_id STRING, funder_id STRING, funder_display_name STRING, doi STRING>>) AS awards,\n",
    "    STRUCT(best_oa_location IS NOT NULL AS is_oa, CASE WHEN best_oa_location.oa_status = 1 THEN 'diamond' WHEN best_oa_location.oa_status = 2 THEN 'gold' WHEN best_oa_location.oa_status = 3 THEN 'hybrid' WHEN best_oa_location.oa_status = 4 THEN 'bronze' WHEN best_oa_location.oa_status = 5 THEN 'green' ELSE 'closed' END AS oa_status, COALESCE(best_oa_location.pdf_url, best_oa_location.landing_page_url) AS oa_url, CAST(NULL AS BOOLEAN) AS any_repository_has_fulltext) AS open_access,\n",
    "    s.type, s.type = 'paratext' AS is_paratext, s.is_retracted, s.indexed_in_crossref, s.is_xpac,\n",
    "    m.mesh_formatted AS mesh, CAST(NULL AS STRING) AS fulltext, s.created_date, s.updated_date\n",
    "FROM set_fields s\n",
    "LEFT JOIN (\n",
    "    SELECT pmid, COLLECT_LIST(STRUCT(descriptor_ui, descriptor_name, qualifiers._UI AS qualifier_ui, qualifiers._VALUE AS qualifier_name, CASE WHEN is_major_topic = 'Y' THEN TRUE ELSE FALSE END AS is_major_topic)) AS mesh_formatted\n",
    "    FROM (\n",
    "        SELECT pmid, EXPLODE(mesh.MeshHeading) AS mesh_exploded, mesh_exploded.DescriptorName._UI AS descriptor_ui, mesh_exploded.DescriptorName._VALUE AS descriptor_name,\n",
    "               EXPLODE_OUTER(ARRAYS_ZIP(mesh_exploded.QualifierName._UI, mesh_exploded.QualifierName._VALUE)) AS qualifiers,\n",
    "               mesh_exploded.DescriptorName._MajorTopicYN AS is_major_topic\n",
    "        FROM (\n",
    "            SELECT FILTER(PubmedData.ArticleIdList.ArticleId, x -> x._IdType = 'pubmed')._VALUE[0] AS pmid, MedlineCitation.MeshHeadingList AS mesh\n",
    "            FROM openalex.pubmed.pubmed_items\n",
    "        )\n",
    "    ) GROUP BY pmid\n",
    ") m ON s.ids.pmid = m.pmid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85827ffa-dabe-4213-a08a-8774c527ef81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### End CREATE Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd34be96-351d-4d39-895e-81d4f90571d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "UPDATE identifier('openalex' || :env_suffix || '.works.openalex_works') \n",
    "SET topics_key = xxhash64(concat_ws('|', doi, title, abstract, primary_location.source.display_name));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e71ad0a-4c88-4d60-9fff-2b8f9e8dafef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OPTIMIZE identifier('openalex' || :env_suffix || '.works.openalex_works') FULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c22e0a6-ec93-458d-a819-2cabfa10b1d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### `MERGE` other fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfd34f75-6351-4ab0-b52a-c16149b44069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956bead7-87d8-4966-b14e-b422329749bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE Backfill referenced_works (mid.citation)\n",
    "WITH prod_ref_works AS (\n",
    "  SELECT \n",
    "    paper_id as id,\n",
    "    collect_set(paper_reference_id) as referenced_works\n",
    "  FROM openalex.mid.citation\n",
    "  GROUP BY paper_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING prod_ref_works as source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  referenced_works = array_union(target.referenced_works, source.referenced_works),\n",
    "  referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));\n",
    "\n",
    "-- Calculate and MERGE the citations\n",
    "-- Far fewer changes than propagating through locations_mapped and 17 CTEs, no need to select distinct work_id data\n",
    "-- runtime about 1 min, updates 67M rows\n",
    "WITH exploded_references AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    publication_year,\n",
    "    EXPLODE(referenced_works) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE referenced_works_count > 0\n",
    "    AND publication_year <= YEAR(CURRENT_DATE())\n",
    "),\n",
    "citation_counts AS (\n",
    "  SELECT\n",
    "    cited_work_id,\n",
    "    publication_year,\n",
    "    COUNT(*) AS cited_by_count\n",
    "  FROM exploded_references\n",
    "  GROUP BY cited_work_id, publication_year\n",
    "),\n",
    "citation_counts_by_work AS (\n",
    "  SELECT \n",
    "    cited_work_id,\n",
    "    FILTER(\n",
    "      SORT_ARRAY(\n",
    "        COLLECT_LIST(\n",
    "          NAMED_STRUCT(\n",
    "            'year', publication_year,\n",
    "            'cited_by_count', cited_by_count\n",
    "          )\n",
    "        ),\n",
    "        false\n",
    "      ),\n",
    "      x -> x.year >= 2012\n",
    "    ) AS counts_by_year,\n",
    "    SUM(cited_by_count) AS cited_by_count -- total across all years\n",
    "  FROM citation_counts\n",
    "  GROUP BY cited_work_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING citation_counts_by_work AS source\n",
    "ON target.id = source.cited_work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.cited_by_count = source.cited_by_count,\n",
    "  target.counts_by_year = source.counts_by_year;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b98cb5d-5d25-446b-a200-41a67a2c9995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge full-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9a12ef-50c6-41f1-8420-e2fd0b70424c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------- Merge fulltext from PDFs --------\n",
    "WITH pdf_fulltext_for_merge AS (\n",
    "    -- DOI-based matching\n",
    "    SELECT \n",
    "        CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) AS doi_normalized,\n",
    "        NULL AS pmh_id,\n",
    "        fulltext,\n",
    "        'doi' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'doi')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID-based matching\n",
    "    SELECT \n",
    "        NULL AS doi_normalized,\n",
    "        FILTER(ids, x -> x.namespace = 'pmh')[0].id AS pmh_id,\n",
    "        fulltext,\n",
    "        'pmh' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY FILTER(ids, x -> x.namespace = 'pmh')[0].id ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'pmh')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "      -- Only include PMH records that don't have DOIs (to avoid duplicates)\n",
    "      AND SIZE(FILTER(ids, x -> x.namespace = 'doi')) = 0\n",
    "),\n",
    "pdf_fulltext_deduped AS (\n",
    "    SELECT doi_normalized, pmh_id, fulltext, match_type\n",
    "    FROM pdf_fulltext_for_merge\n",
    "    WHERE rn = 1\n",
    "),\n",
    "works_with_locations AS (\n",
    "    SELECT \n",
    "        w.id,\n",
    "        w.doi,\n",
    "        EXPLODE_OUTER(w.locations) AS location\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "),\n",
    "matched_fulltext AS (\n",
    "    -- DOI matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM (SELECT DISTINCT id, doi FROM works_with_locations) w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON LOWER(w.doi) = p.doi_normalized\n",
    "    WHERE p.doi_normalized IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM works_with_locations w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON w.location.pmh_id = p.pmh_id\n",
    "    WHERE p.pmh_id IS NOT NULL\n",
    "      AND w.location.pmh_id IS NOT NULL\n",
    "),\n",
    "final_fulltext AS (\n",
    "    -- Deduplicate in case a work matches on both DOI and PMH\n",
    "    -- Prefer DOI matches over PMH matches\n",
    "    SELECT \n",
    "        work_id,\n",
    "        fulltext,\n",
    "        ROW_NUMBER() OVER (PARTITION BY work_id ORDER BY CASE WHEN match_type = 'doi' THEN 1 ELSE 2 END) AS priority_rn\n",
    "    FROM matched_fulltext\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (SELECT work_id, fulltext FROM final_fulltext WHERE priority_rn = 1) AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.fulltext = source.fulltext;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c438dd8-62f4-48f2-843d-2ed5fe4c297d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cc4afd-bb7a-4f80-bcc2-8cd568dacffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "---------- MERGE aggregated and sorted by score Concepts from backfill --------\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING openalex.works.work_concepts_backfill AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "  target.concepts = source.concepts,\n",
    "  target.keywords = filter(source.keywords, k -> k.score > 0);\n",
    "\n",
    "---------- MERGE from predicted Concepts using concept_key --------\n",
    "-- ============= Tunable parameters =============\n",
    "DECLARE OR REPLACE VARIABLE filter_threshold FLOAT DEFAULT 0.20;  -- score cutoff for filtering\n",
    "DECLARE OR REPLACE VARIABLE base_mid         FLOAT DEFAULT 5.0;   -- target median size (bell center)\n",
    "DECLARE OR REPLACE VARIABLE half_range       FLOAT DEFAULT 6.0;   -- maximum deviation from median (-+ range)\n",
    "DECLARE OR REPLACE VARIABLE center_size      INT   DEFAULT 7;     -- where the tanh crosses 0 (inflection point)\n",
    "DECLARE OR REPLACE VARIABLE slope            FLOAT DEFAULT 0.05;  -- steepness of the tanh curve\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  SELECT concept_key,\n",
    "         FIRST(concepts_enriched) AS concepts,\n",
    "         FIRST(keywords) as keywords\n",
    "  FROM openalex.works.openalex_works_concepts_predicted\n",
    "  WHERE size(concepts_enriched) > 0 OR size(keywords) > 0\n",
    "  GROUP BY concept_key\n",
    ") as source\n",
    "ON (target.concepts IS NULL OR size(target.concepts) = 0)\n",
    "   AND xxhash64(\n",
    "     -- sanitize later\n",
    "     concat_ws('|',\n",
    "       target.title,\n",
    "       target.abstract,\n",
    "       target.primary_location.source.display_name,\n",
    "       target.primary_location.source.type\n",
    "     )\n",
    "   ) = source.concept_key\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.concepts = slice(source.concepts, 1, 40), -- too many concepts from the model - up to 130\n",
    "    target.keywords = slice(\n",
    "      filter(source.keywords, k -> k.score > 0), 1,\n",
    "      greatest(2, least(12, round(base_mid + \n",
    "          half_range * tanh((\n",
    "            size(filter(source.keywords, \n",
    "              k -> k.score > filter_threshold)) - center_size) * slope)))\n",
    "      )\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff904bd-c78d-45e3-b0a7-3035442f3cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a54451e-0a37-4306-9953-1b16e4be8fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "-- MERGE from Topics backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    topics\n",
    "  FROM openalex.works.work_topics_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON id < 6600000000\n",
    "  AND target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];\n",
    "\n",
    "-- MERGE from Topics frontfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    topics_key,\n",
    "    FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  GROUP BY topics_key\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON id > 6600000000 -- speed this up\n",
    "  AND (target.topics IS NULL or size(target.topics) = 0)\n",
    "  AND target.topics_key = source.topics_key \n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];\n",
    "\n",
    "-- MERGE Topics BY DOI\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    lower(doi) as doi,\n",
    "    FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  WHERE doi is not null\n",
    "  GROUP BY doi\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON (target.topics IS NULL or size(target.topics) = 0)\n",
    "  AND target.doi = source.doi\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac29702-1f81-461a-b39c-e988465b99a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MERGE fwci and citation percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724a1f41-81a3-4c95-bf0e-1b2f9aba7495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- FWCI + citation percentile (subfield) + cited_by_percentile_year\n",
    "-- No counts_by_year, no lateral view; everything from exploded citation edges.\n",
    "\n",
    "WITH base AS (  -- candidate works we’ll update\n",
    "  SELECT\n",
    "    id AS work_id,\n",
    "    CASE\n",
    "      WHEN type IN ('article','journal-article') THEN 'article'\n",
    "      WHEN type IN ('conference-article','proceedings-article') THEN 'conference_article'\n",
    "      WHEN type IN ('book-chapter','book_chapter') THEN 'book-chapter'\n",
    "      WHEN type = 'book' THEN 'book'\n",
    "      WHEN type IN ('review','review-article') THEN 'review'\n",
    "      ELSE NULL\n",
    "    END AS work_type,\n",
    "    COALESCE(publication_year, YEAR(publication_date)) AS pub_year,\n",
    "    primary_topic.subfield.id AS subfield_id,\n",
    "    cited_by_count AS lifetime_citations\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE primary_topic.subfield.id IS NOT NULL\n",
    "    AND COALESCE(publication_year, YEAR(publication_date)) IS NOT NULL\n",
    "),\n",
    "\n",
    "-- All citation edges (citing -> cited) with citing year.\n",
    "edges AS (\n",
    "  SELECT\n",
    "    publication_year              AS citing_year,\n",
    "    EXPLODE(referenced_works)     AS cited_work_id\n",
    "  FROM openalex.works.openalex_works\n",
    "  WHERE referenced_works_count > 0\n",
    "    AND publication_year IS NOT NULL\n",
    "    AND publication_year <= YEAR(CURRENT_DATE())\n",
    "),\n",
    "\n",
    "-- CURRENT + 3-year citations for each target work: sum edges where\n",
    "-- citing_year between [pub_year, min(pub_year+3, current_year)].\n",
    "three_years AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.subfield_id,\n",
    "    b.pub_year,\n",
    "    SUM(CASE\n",
    "            WHEN e.citing_year BETWEEN b.pub_year AND LEAST(b.pub_year + 3, YEAR(CURRENT_DATE()))\n",
    "            THEN 1 ELSE 0\n",
    "        END ) AS cites_3y\n",
    "  FROM base b\n",
    "  LEFT JOIN edges e\n",
    "    ON e.cited_work_id = b.work_id\n",
    "  GROUP BY b.work_id, b.subfield_id, b.pub_year\n",
    "),\n",
    "\n",
    "-- Expected 3-year citations per subfield (simple, fast cohort baseline).\n",
    "expected_by_subfield AS (\n",
    "  SELECT\n",
    "    subfield_id,\n",
    "    AVG(cites_3y) AS expected_3y\n",
    "  FROM three_years\n",
    "  GROUP BY subfield_id\n",
    "),\n",
    "\n",
    "-- FWCI = actual / expected (NULL when no expectation).\n",
    "with_fwci AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.subfield_id,\n",
    "    b.pub_year,\n",
    "    b.lifetime_citations,\n",
    "    t.cites_3y,\n",
    "    CASE\n",
    "      WHEN e.expected_3y IS NULL OR e.expected_3y <= 0 THEN NULL\n",
    "      ELSE t.cites_3y / e.expected_3y\n",
    "    END AS fwci\n",
    "  FROM base b\n",
    "  JOIN three_years t ON t.work_id = b.work_id\n",
    "  JOIN expected_by_subfield e USING (subfield_id)\n",
    "),\n",
    "\n",
    "-- Citation percentile within subfield (0..1, higher = more cited).\n",
    "with_percentile AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    subfield_id,\n",
    "    pub_year,\n",
    "    ROUND(fwci, 5) AS fwci,\n",
    "    lifetime_citations,\n",
    "    ROUND(\n",
    "      PERCENT_RANK() OVER (\n",
    "        PARTITION BY subfield_id\n",
    "        ORDER BY lifetime_citations\n",
    "      ),\n",
    "      8\n",
    "    ) AS citation_pct\n",
    "  FROM with_fwci\n",
    "),\n",
    "\n",
    "-- Per-year citation counts from edges (global, not just base).\n",
    "by_year AS (\n",
    "  SELECT\n",
    "    cited_work_id,\n",
    "    citing_year AS year,\n",
    "    COUNT(*) AS citation_count\n",
    "  FROM edges\n",
    "  GROUP BY cited_work_id, citing_year\n",
    "),\n",
    "\n",
    "-- For each work: evaluation year = latest citing year (clamped to ≥1920).\n",
    "latest AS (\n",
    "  SELECT\n",
    "    cited_work_id AS work_id,\n",
    "    GREATEST(MAX(year), 1920) AS eval_year\n",
    "  FROM by_year\n",
    "  GROUP BY cited_work_id\n",
    "),\n",
    "\n",
    "-- Citation count of the work in its eval_year (0 if none that year).\n",
    "work_counts AS (\n",
    "  SELECT\n",
    "    p.work_id,\n",
    "    p.eval_year AS year,\n",
    "    COALESCE(b.citation_count, 0) AS citation_count\n",
    "  FROM latest p\n",
    "  LEFT JOIN by_year b\n",
    "    ON b.cited_work_id = p.work_id\n",
    "   AND b.year = p.eval_year\n",
    "),\n",
    "\n",
    "-- Per-year distribution of distinct citation_count → percent_rank.\n",
    "per_year_dist AS (\n",
    "  SELECT\n",
    "    year,\n",
    "    citation_count,\n",
    "    PERCENT_RANK() OVER (PARTITION BY year ORDER BY citation_count) AS pct\n",
    "  FROM (SELECT DISTINCT year, citation_count FROM by_year)\n",
    "),\n",
    "\n",
    "-- Lower/upper percentile bounds for each work’s citation_count in eval_year.\n",
    "bounds AS (\n",
    "  SELECT\n",
    "    w.work_id,\n",
    "    MAX(CASE WHEN d.citation_count <= w.citation_count THEN d.pct END) AS lower_pct,\n",
    "    MIN(CASE WHEN d.citation_count >= w.citation_count THEN d.pct END) AS upper_pct\n",
    "  FROM work_counts w\n",
    "  JOIN per_year_dist d\n",
    "    ON d.year = w.year\n",
    "  GROUP BY w.work_id\n",
    "),\n",
    "\n",
    "-- Format {min,max} per the prod rules (100→99/100; if min==max then min-1; clamp at 0).\n",
    "formatted_year_pct AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    NAMED_STRUCT(\n",
    "      'min',\n",
    "        CASE\n",
    "          WHEN ROUND(COALESCE(lower_pct, 0) * 100) = 100 THEN 99\n",
    "          WHEN ROUND(COALESCE(lower_pct, 0) * 100) = ROUND(COALESCE(upper_pct, 0) * 100)\n",
    "            THEN GREATEST(CAST(ROUND(COALESCE(lower_pct, 0) * 100) AS INT) - 1, 0)\n",
    "          ELSE CAST(ROUND(COALESCE(lower_pct, 0) * 100) AS INT)\n",
    "        END,\n",
    "      'max',\n",
    "        CASE\n",
    "          WHEN ROUND(COALESCE(upper_pct, 0) * 100) = 100 THEN 100\n",
    "          ELSE CAST(ROUND(COALESCE(upper_pct, 0) * 100) AS INT)\n",
    "        END\n",
    "    ) AS cited_by_percentile_year\n",
    "  FROM bounds\n",
    "),\n",
    "\n",
    "updates AS (\n",
    "  SELECT\n",
    "    p.work_id,\n",
    "    p.fwci,\n",
    "    NAMED_STRUCT(\n",
    "      'value', p.citation_pct,\n",
    "      'is_in_top_1_percent',(p.citation_pct >= 0.99),\n",
    "      'is_in_top_10_percent',(p.citation_pct >= 0.90)\n",
    "    ) AS citation_normalized_percentile,\n",
    "    y.cited_by_percentile_year\n",
    "  FROM with_percentile p\n",
    "  LEFT JOIN formatted_year_pct y\n",
    "    ON y.work_id = p.work_id\n",
    "  WHERE p.citation_pct > 0 OR p.fwci > 0\n",
    ")\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING updates AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED\n",
    "  --AND (target.fwci IS NULL OR dayofmonth(current_date()) = 1)\n",
    "THEN UPDATE SET\n",
    "  target.fwci = COALESCE(source.fwci, target.fwci),\n",
    "  target.citation_normalized_percentile =\n",
    "    COALESCE(source.citation_normalized_percentile, target.citation_normalized_percentile),\n",
    "  target.cited_by_percentile_year =\n",
    "    COALESCE(source.cited_by_percentile_year, target.cited_by_percentile_year);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbf6595-e492-47b2-9612-48d1dc64f655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `sustainable_development_goals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2a139e-f3f3-42d0-a305-85b523b7ecfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from SDG backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    paper_id,\n",
    "    sustainable_development_goals\n",
    "  FROM openalex.works.work_sdg_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON target.id = source.paper_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.sustainable_development_goals = source.sustainable_development_goals;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2184bf0-ff09-4205-8868-1786314d51ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `grants`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4488ecd9-c1cb-4c95-9cd3-0953a13595ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  WITH funders_exploded AS (\n",
    "    SELECT \n",
    "      paper_id, funder_id, display_name, explode_outer(award_ids) as award_id\n",
    "    FROM openalex.mid.work_funder\n",
    "    JOIN openalex.common.funder USING (funder_id)\n",
    "  )\n",
    "  SELECT paper_id,\n",
    "    array_sort(\n",
    "      collect_list(\n",
    "        struct(\n",
    "          CONCAT(\"https://openalex.org/F\", funder_id) as funder,\n",
    "          display_name as funder_display_name,\n",
    "          award_id\n",
    "        )\n",
    "      )\n",
    "    ) as grants\n",
    "  FROM funders_exploded\n",
    "  GROUP BY paper_id\n",
    ") as source\n",
    "ON target.id = source.paper_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.grants = source.grants;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c269057d-8277-4bc4-b4d3-b23a5576588c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `awards`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3646b5c3-e567-4a9a-a569-a80ddbb9f855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT work_id,\n",
    "    collect_set(\n",
    "      struct(\n",
    "        CONCAT('https://openalex.org/G', id) as id,\n",
    "        award_id as funder_award_id,\n",
    "        CONCAT('https://openalex.org/F', funder_id) as funder_id,\n",
    "        COALESCE(f.display_name, a.funder_name) as funder_display_name,\n",
    "        doi_url as doi\n",
    "      )\n",
    "    ) as awards\n",
    "  FROM openalex.works.work_awards a\n",
    "  JOIN openalex.common.funder f \n",
    "    ON a.funder_ids.doi = f.doi OR a.funder_ids.ror_id = f.ror_id\n",
    "  WHERE work_id IS NOT NULL\n",
    "  GROUP BY work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.awards = source.awards;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01af4136-9ab3-4150-b55f-14e5d9c77f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `authorships'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294312bf-f88c-4464-8390-552ab98c9720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT paper_id as work_id,\n",
    "    authorships\n",
    "  FROM openalex.authors.work_authorships_backfill\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.authorships IS NOT NULL and size(source.authorships) > 0 THEN UPDATE\n",
    "  SET target.authorships = source.authorships;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9522f03a-d2d4-4a64-a315-850dc7204a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `work.type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c92f069-2c0b-4ed6-82b6-db094fc20e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  SELECT \n",
    "    paper_id as work_id, type\n",
    "  FROM openalex.mid.work\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED \n",
    "  AND target.type <> source.type\n",
    "  AND source.type IS NOT NULL\n",
    "THEN UPDATE SET\n",
    "  target.type = coalesce(source.type, target.type)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateOpenAlexWorks",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "a32b9271-2b7f-475b-8140-bb4789e5a680",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
