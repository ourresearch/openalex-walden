{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdb11992-988b-4aea-be61-4f52efe22c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create `openalex_works` table, include curation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528f31e8-8785-4cc1-986f-74cbc29940b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Register helper function\n",
    "CREATE FUNCTION IF NOT EXISTS get_highest_priority_value(\n",
    "    all_structs ARRAY<STRUCT<field_value: STRING, priority: INT>>, field_name STRING\n",
    "  )\n",
    "  RETURNS STRING\n",
    "  RETURN\n",
    "    (\n",
    "      SELECT\n",
    "        AGGREGATE(\n",
    "          FILTER(all_structs, y -> y.field_value IS NOT NULL),\n",
    "          STRUCT(CAST(NULL AS STRING) AS field_value, 999 AS priority),\n",
    "          (acc, x) -> CASE\n",
    "            WHEN x.priority < acc.priority THEN x\n",
    "            ELSE acc\n",
    "          END\n",
    "        ).field_value\n",
    "    );\n",
    "\n",
    "-- Final pipeline to create openalex_works\n",
    "CREATE\n",
    "OR REPLACE TABLE identifier(\n",
    "  'openalex' || :env_suffix || '.works.openalex_works'\n",
    ") CLUSTER BY AUTO\n",
    "TBLPROPERTIES (\n",
    "  'delta.dataSkippingNumIndexedCols' = 36,\n",
    "  'delta.deletedFileRetentionDuration' = '60 days',\n",
    "  -- default is 7\n",
    "  'delta.logRetentionDuration' = '60 days' -- default is 30\n",
    ") AS (\n",
    "  WITH mat_sources AS (\n",
    "    SELECT\n",
    "      s.id AS source_id,\n",
    "      s.display_name,\n",
    "      s.issn AS issn_l,\n",
    "      s.issns,\n",
    "      s.is_in_doaj,\n",
    "      s.is_core,\n",
    "      s.publisher AS source_publisher,\n",
    "      s.publisher_id,\n",
    "      s.institution_id,\n",
    "      s.repository_id,\n",
    "      s.apc_prices AS apc_prices,\n",
    "      s.apc_usd,\n",
    "      s.type AS source_type,\n",
    "      i.display_name AS institution_name,\n",
    "      p.display_name AS publisher_name,\n",
    "      s.is_in_doaj_start_year,\n",
    "      s.high_oa_rate_start_year,\n",
    "      s.is_oa_high_oa_rate,\n",
    "      s.is_fully_open_in_jstage,\n",
    "      s.doaj_license\n",
    "    FROM\n",
    "      openalex.sources.sources s\n",
    "      LEFT JOIN openalex.institutions.institutions i ON s.institution_id = i.id\n",
    "      LEFT JOIN openalex.publishers.publishers p ON s.publisher_id = p.id\n",
    "  ),\n",
    "  priority_table AS (\n",
    "    -- some comment\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      openalex.system.priority_table\n",
    "  ),\n",
    "  openapc_paid AS (\n",
    "    SELECT\n",
    "      paper_id as work_id,\n",
    "      /* if multiple rows per work, pick the latest yearâ€™s amounts */\n",
    "      MAX_BY(CAST(apc_in_euro AS DOUBLE), year) AS apc_in_euro,\n",
    "      MAX_BY(CAST(apc_in_usd  AS DOUBLE), year) AS apc_in_usd\n",
    "    FROM openalex.mid.work_openapc\n",
    "    GROUP BY paper_id\n",
    "  ),\n",
    "  base AS (\n",
    "    SELECT\n",
    "      a.work_id,\n",
    "      a.provenance,\n",
    "      a.native_id,\n",
    "      a.native_id_namespace,\n",
    "      a.best_doi,\n",
    "      a.title,\n",
    "      a.type,\n",
    "      a.abstract,\n",
    "      a.referenced_works_count,\n",
    "      a.referenced_works,\n",
    "      a.abstract_inverted_index,\n",
    "      b.priority,\n",
    "      a.openalex_created_dt,\n",
    "      a.openalex_updated_dt,\n",
    "      s.source_id,\n",
    "      s.display_name,\n",
    "      s.issn_l,\n",
    "      s.issns,\n",
    "      s.is_in_doaj,\n",
    "      CASE\n",
    "        WHEN GET(s.apc_prices, 0) IS NULL THEN NULL\n",
    "        ELSE s.apc_prices\n",
    "      END AS apc_prices,\n",
    "      s.apc_usd,\n",
    "      s.is_core,\n",
    "      a.is_oa,\n",
    "      COALESCE(a.is_oa, FALSE) AS is_oa_raw,\n",
    "      COALESCE(s.is_in_doaj, FALSE) AS is_in_doaj_raw,\n",
    "      COALESCE(\n",
    "        is_in_doaj_raw\n",
    "        AND (\n",
    "          ISNULL(s.is_in_doaj_start_year)\n",
    "          OR YEAR(a.published_date) >= s.is_in_doaj_start_year\n",
    "        ),\n",
    "        FALSE\n",
    "      ) AS is_in_doaj_stg,\n",
    "      COALESCE(\n",
    "        s.is_oa_high_oa_rate\n",
    "        AND (\n",
    "          ISNULL(s.high_oa_rate_start_year)\n",
    "          OR YEAR(a.published_date) >= s.high_oa_rate_start_year\n",
    "        )\n",
    "        OR s.is_fully_open_in_jstage,\n",
    "        FALSE\n",
    "      ) AS is_oa_high_rate,\n",
    "      (\n",
    "        is_oa_high_rate\n",
    "        or is_in_doaj_stg\n",
    "      ) AS source_is_oa,\n",
    "      (\n",
    "        is_oa_raw\n",
    "        OR source_is_oa\n",
    "      ) AS composite_is_oa,\n",
    "      s.is_in_doaj_start_year,\n",
    "      s.source_type,\n",
    "      a.source_name,\n",
    "      a.publisher,\n",
    "      a.published_date,\n",
    "      a.volume,\n",
    "      a.issue,\n",
    "      a.first_page,\n",
    "      a.last_page,\n",
    "      COALESCE(a.language_classification.language, a.language) as language, --prefer fasttext classified language\n",
    "      a.authors,\n",
    "      TRANSFORM(\n",
    "        a.urls,\n",
    "        x -> STRUCT(\n",
    "          REGEXP_REPLACE(x.url, 'dx.doi.org', 'doi.org') AS url,\n",
    "          x.content_type\n",
    "        )\n",
    "      ) AS urls,\n",
    "      CASE\n",
    "        WHEN is_in_doaj_stg\n",
    "        AND s.doaj_license IS NOT NULL THEN s.doaj_license\n",
    "        ELSE a.license\n",
    "      END AS license,\n",
    "      s.institution_name,\n",
    "      s.publisher_name,\n",
    "      s.institution_id,\n",
    "      s.publisher_id,\n",
    "      a.version,\n",
    "      CASE\n",
    "        WHEN LOWER(a.native_id) LIKE '%arxiv.org%' THEN COALESCE(\n",
    "          GET(\n",
    "            FILTER(a.urls, x -> x.content_type = 'html').url,\n",
    "            0\n",
    "          ),\n",
    "          a.landing_page_url\n",
    "        )\n",
    "        ELSE a.landing_page_url\n",
    "      END AS landing_page_url,\n",
    "      CASE\n",
    "        WHEN LOWER(a.native_id) LIKE '%arxiv.org%' THEN COALESCE(\n",
    "          CONCAT(\n",
    "            'https://arxiv.org/pdf/',\n",
    "            SPLIT_PART(a.native_id, ':', 3)\n",
    "          ),\n",
    "          a.pdf_url\n",
    "        )\n",
    "        ELSE a.pdf_url\n",
    "      END AS pdf_url,\n",
    "      a.is_retracted,\n",
    "      s.repository_id,\n",
    "      a.pdf_s3_id,\n",
    "      a.grobid_s3_id,\n",
    "      ROW_NUMBER() OVER (\n",
    "        PARTITION BY a.work_id,\n",
    "        a.provenance\n",
    "        ORDER BY\n",
    "          a.created_date DESC\n",
    "      ) AS row_num,\n",
    "      CASE\n",
    "        WHEN s.source_id IS NULL THEN NULL\n",
    "        WHEN (\n",
    "          a.provenance = 'crossref'\n",
    "          AND s.source_type != 'repository'\n",
    "        ) THEN 'publisher'\n",
    "        ELSE 'repository'\n",
    "      END AS host_type,\n",
    "      CASE\n",
    "        WHEN composite_is_oa\n",
    "        AND host_type = 'publisher' THEN CASE\n",
    "          WHEN ZEROIFNULL(s.apc_usd) = 0\n",
    "          AND source_is_oa THEN 1\n",
    "          WHEN source_is_oa THEN 2\n",
    "          WHEN a.license IS NOT NULL\n",
    "          AND a.license != 'publisher-specific-oa' THEN 3\n",
    "          ELSE 4\n",
    "        END\n",
    "        WHEN host_type IS NULL\n",
    "        AND (\n",
    "          a.is_oa\n",
    "          OR composite_is_oa\n",
    "        ) THEN 2\n",
    "        WHEN (\n",
    "          a.is_oa\n",
    "          OR composite_is_oa\n",
    "        )\n",
    "        AND host_type = 'repository' THEN 5\n",
    "        ELSE 6\n",
    "      END AS oa_status\n",
    "    FROM\n",
    "      identifier(\n",
    "        'openalex' || :env_suffix || '.works.locations_mapped'\n",
    "      ) a\n",
    "      LEFT JOIN priority_table b USING (provenance)\n",
    "      LEFT JOIN mat_sources s ON a.source_id = s.source_id QUALIFY row_num <= 10\n",
    "  ),\n",
    "  -- CURATION BLOCK\n",
    "  curation_requests_clean AS (\n",
    "    WITH ranked AS (\n",
    "      SELECT\n",
    "        LOWER(\n",
    "          TRIM(\n",
    "            REGEXP_REPLACE(doi, '^https?://(dx\\\\.)?doi\\\\.org/', '')\n",
    "          )\n",
    "        ) AS doi,\n",
    "        TRIM(previous_url) AS prev_url,\n",
    "        TRIM(new_url) AS new_url,\n",
    "        ROW_NUMBER() OVER (\n",
    "          PARTITION BY LOWER(\n",
    "            TRIM(\n",
    "              REGEXP_REPLACE(doi, '^https?://(dx\\\\.)?doi\\\\.org/', '')\n",
    "            )\n",
    "          ),\n",
    "          TRIM(previous_url)\n",
    "          ORDER BY\n",
    "            ingestion_timestamp DESC\n",
    "        ) AS rn\n",
    "      FROM\n",
    "        openalex.unpaywall.curation_requests\n",
    "    )\n",
    "    SELECT\n",
    "      doi,\n",
    "      prev_url,\n",
    "      new_url\n",
    "    FROM\n",
    "      ranked\n",
    "    WHERE\n",
    "      rn = 1\n",
    "  ),\n",
    "  cr_matches AS (\n",
    "    SELECT\n",
    "      b.*,\n",
    "      c.new_url\n",
    "    FROM\n",
    "      base b\n",
    "      JOIN curation_requests_clean c ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE\n",
    "      c.prev_url IS NOT NULL\n",
    "      AND (\n",
    "        REGEXP_REPLACE(LOWER(COALESCE(b.pdf_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '')\n",
    "        OR REGEXP_REPLACE(\n",
    "          LOWER(COALESCE(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '')\n",
    "        OR ARRAY_CONTAINS(\n",
    "          TRANSFORM(\n",
    "            b.urls,\n",
    "            u -> REGEXP_REPLACE(LOWER(u.url), '^https?://', '') = REGEXP_REPLACE(LOWER(c.prev_url), '^https?://', '')\n",
    "          ),\n",
    "          TRUE\n",
    "        )\n",
    "      )\n",
    "  ),\n",
    "  cr_upserts AS (\n",
    "    -- curation upserts\n",
    "    SELECT\n",
    "      b.work_id,\n",
    "      b.provenance,\n",
    "      b.native_id,\n",
    "      b.native_id_namespace,\n",
    "      b.best_doi,\n",
    "      b.title,\n",
    "      b.type,\n",
    "      b.abstract,\n",
    "      b.referenced_works_count,\n",
    "      b.referenced_works,\n",
    "      b.abstract_inverted_index,\n",
    "      b.priority,\n",
    "      b.openalex_created_dt,\n",
    "      b.openalex_updated_dt,\n",
    "      b.source_id,\n",
    "      b.display_name,\n",
    "      b.issn_l,\n",
    "      b.issns,\n",
    "      b.is_in_doaj,\n",
    "      b.apc_prices,\n",
    "      b.apc_usd,\n",
    "      b.is_core,\n",
    "      b.is_oa,\n",
    "      b.is_oa_raw,\n",
    "      b.is_in_doaj_raw,\n",
    "      b.is_in_doaj_stg,\n",
    "      b.is_oa_high_rate,\n",
    "      b.source_is_oa,\n",
    "      b.composite_is_oa,\n",
    "      b.is_in_doaj_start_year,\n",
    "      b.source_type,\n",
    "      b.source_name,\n",
    "      b.publisher,\n",
    "      b.published_date,\n",
    "      b.volume,\n",
    "      b.issue,\n",
    "      b.first_page,\n",
    "      b.last_page,\n",
    "      b.language,\n",
    "      b.authors,\n",
    "      /* Update the urls array using normalized comparison */\n",
    "      transform(\n",
    "        b.urls,\n",
    "        u -> struct(\n",
    "          CASE\n",
    "            WHEN regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN c.new_url\n",
    "            ELSE u.url\n",
    "          END as url,\n",
    "          u.content_type\n",
    "        )\n",
    "      ) AS urls,\n",
    "      b.license,\n",
    "      b.institution_name,\n",
    "      b.publisher_name,\n",
    "      b.institution_id,\n",
    "      b.publisher_id,\n",
    "      b.version,\n",
    "      /* 44   landing_page_url  (may be replaced) --------------------- */\n",
    "      CASE\n",
    "        WHEN regexp_replace(\n",
    "          lower(coalesce(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = regexp_replace(lower(c.prev_url), '^https?://', '') THEN c.new_url\n",
    "        ELSE b.landing_page_url\n",
    "      END AS landing_page_url,\n",
    "      /* 45   pdf_url  (may be replaced) ------------------------------ */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN c.new_url\n",
    "        ELSE b.pdf_url\n",
    "      END AS pdf_url,\n",
    "      /* 46â€“52 : trailing columns in correct order -------------------- */\n",
    "      b.is_retracted,\n",
    "      b.repository_id,\n",
    "      b.pdf_s3_id,\n",
    "      b.grobid_s3_id,\n",
    "      b.row_num,\n",
    "      b.host_type,\n",
    "      b.oa_status\n",
    "    FROM\n",
    "      base AS b\n",
    "      JOIN curation_requests_clean c ON lower(b.best_doi) = c.doi\n",
    "      AND (\n",
    "        regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "        OR regexp_replace(\n",
    "          lower(coalesce(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "        OR array_contains(\n",
    "          transform(\n",
    "            b.urls,\n",
    "            u -> regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "          ),\n",
    "          true\n",
    "        )\n",
    "      )\n",
    "    WHERE\n",
    "      c.prev_url IS NOT NULL\n",
    "      AND c.new_url IS NOT NULL -- replacement, not nullification\n",
    "  ),\n",
    "  cr_nullify AS (\n",
    "    SELECT\n",
    "      b.work_id,\n",
    "      b.provenance,\n",
    "      b.native_id,\n",
    "      b.native_id_namespace,\n",
    "      b.best_doi,\n",
    "      b.title,\n",
    "      b.type,\n",
    "      b.abstract,\n",
    "      b.referenced_works_count,\n",
    "      b.referenced_works,\n",
    "      b.abstract_inverted_index,\n",
    "      b.priority,\n",
    "      b.openalex_created_dt,\n",
    "      b.openalex_updated_dt,\n",
    "      b.source_id,\n",
    "      b.display_name,\n",
    "      b.issn_l,\n",
    "      b.issns,\n",
    "      b.is_in_doaj,\n",
    "      b.apc_prices,\n",
    "      b.apc_usd,\n",
    "      b.is_core,\n",
    "      /* Update is_oa to false if pdf_url is being nullified */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN false\n",
    "        ELSE b.is_oa\n",
    "      END AS is_oa,\n",
    "      /* Update is_oa_raw to false if pdf_url is being nullified */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN false\n",
    "        ELSE b.is_oa_raw\n",
    "      END AS is_oa_raw,\n",
    "      b.is_in_doaj_raw,\n",
    "      b.is_in_doaj_stg,\n",
    "      b.is_oa_high_rate,\n",
    "      b.source_is_oa,\n",
    "      /* Update composite_is_oa to account for nullified pdf_url */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN b.source_is_oa\n",
    "        /* When pdf_url is nullified, composite_is_oa depends only on source_is_oa */\n",
    "        ELSE b.composite_is_oa\n",
    "      END AS composite_is_oa,\n",
    "      b.is_in_doaj_start_year,\n",
    "      b.source_type,\n",
    "      b.source_name,\n",
    "      b.publisher,\n",
    "      b.published_date,\n",
    "      b.volume,\n",
    "      b.issue,\n",
    "      b.first_page,\n",
    "      b.last_page,\n",
    "      b.language,\n",
    "      b.authors,\n",
    "      /* Update the urls array to nullify matched URLs using normalized comparison */\n",
    "      transform(\n",
    "        b.urls,\n",
    "        u -> struct(\n",
    "          CASE\n",
    "            WHEN regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN null\n",
    "            ELSE u.url\n",
    "          END as url,\n",
    "          u.content_type\n",
    "        )\n",
    "      ) AS urls,\n",
    "      b.license,\n",
    "      b.institution_name,\n",
    "      b.publisher_name,\n",
    "      b.institution_id,\n",
    "      b.publisher_id,\n",
    "      b.version,\n",
    "      /* 44   landing_page_url  (set to null if matched) ------------- */\n",
    "      CASE\n",
    "        WHEN regexp_replace(\n",
    "          lower(coalesce(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = regexp_replace(lower(c.prev_url), '^https?://', '') THEN null\n",
    "        ELSE b.landing_page_url\n",
    "      END AS landing_page_url,\n",
    "      /* 45   pdf_url  (set to null if matched) ---------------------- */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN null\n",
    "        ELSE b.pdf_url\n",
    "      END AS pdf_url,\n",
    "      /* 46â€“52 : trailing columns in correct order -------------------- */\n",
    "      b.is_retracted,\n",
    "      b.repository_id,\n",
    "      b.pdf_s3_id,\n",
    "      b.grobid_s3_id,\n",
    "      b.row_num,\n",
    "      b.host_type,\n",
    "      /* Update oa_status to closed (6) if pdf_url is nullified */\n",
    "      CASE\n",
    "        WHEN regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '') THEN 6\n",
    "        /* closed */\n",
    "        ELSE b.oa_status\n",
    "      END AS oa_status\n",
    "    FROM\n",
    "      base AS b\n",
    "      JOIN curation_requests_clean c ON lower(b.best_doi) = c.doi\n",
    "      AND (\n",
    "        regexp_replace(lower(coalesce(b.pdf_url, '')), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "        OR regexp_replace(\n",
    "          lower(coalesce(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "        OR array_contains(\n",
    "          transform(\n",
    "            b.urls,\n",
    "            u -> regexp_replace(lower(u.url), '^https?://', '') = regexp_replace(lower(c.prev_url), '^https?://', '')\n",
    "          ),\n",
    "          true\n",
    "        )\n",
    "      )\n",
    "    WHERE\n",
    "      c.prev_url IS NOT NULL\n",
    "      AND c.new_url IS NULL -- nullification, not update\n",
    "  ),\n",
    "  cr_mark_oa AS (\n",
    "    SELECT\n",
    "      b.work_id,\n",
    "      b.provenance,\n",
    "      b.native_id,\n",
    "      b.native_id_namespace,\n",
    "      b.best_doi,\n",
    "      b.title,\n",
    "      b.type,\n",
    "      b.abstract,\n",
    "      b.referenced_works_count,\n",
    "      b.referenced_works,\n",
    "      b.abstract_inverted_index,\n",
    "      b.priority,\n",
    "      b.openalex_created_dt,\n",
    "      b.openalex_updated_dt,\n",
    "      b.source_id,\n",
    "      b.display_name,\n",
    "      b.issn_l,\n",
    "      b.issns,\n",
    "      b.is_in_doaj,\n",
    "      b.apc_prices,\n",
    "      b.apc_usd,\n",
    "      b.is_core,\n",
    "      TRUE AS is_oa,\n",
    "      TRUE AS is_oa_raw,\n",
    "      b.is_in_doaj_raw,\n",
    "      b.is_in_doaj_stg,\n",
    "      b.is_oa_high_rate,\n",
    "      b.source_is_oa,\n",
    "      /* composite_is_oa only matters for publisher rows */\n",
    "      CASE\n",
    "        WHEN b.host_type = 'publisher' THEN TRUE\n",
    "        ELSE b.composite_is_oa\n",
    "      END AS composite_is_oa,\n",
    "      b.is_in_doaj_start_year,\n",
    "      b.source_type,\n",
    "      b.source_name,\n",
    "      b.publisher,\n",
    "      b.published_date,\n",
    "      b.volume,\n",
    "      b.issue,\n",
    "      b.first_page,\n",
    "      b.last_page,\n",
    "      b.language,\n",
    "      b.authors,\n",
    "      b.urls,\n",
    "      b.license,\n",
    "      b.institution_name,\n",
    "      b.publisher_name,\n",
    "      b.institution_id,\n",
    "      b.publisher_id,\n",
    "      b.version,\n",
    "      b.landing_page_url,\n",
    "      b.pdf_url,\n",
    "      b.is_retracted,\n",
    "      b.repository_id,\n",
    "      b.pdf_s3_id,\n",
    "      b.grobid_s3_id,\n",
    "      b.row_num,\n",
    "      b.host_type,\n",
    "      /* recompute oa_status the same way base does */\n",
    "      CASE\n",
    "        WHEN b.host_type = 'publisher' THEN CASE\n",
    "          WHEN ZEROIFNULL(b.apc_usd) = 0\n",
    "          AND b.source_is_oa THEN 1 -- diamond\n",
    "          WHEN b.source_is_oa THEN 2 -- gold\n",
    "          WHEN b.license IS NOT NULL\n",
    "          AND b.license <> 'publisher-specific-oa' THEN 3 -- hybrid\n",
    "          ELSE 4 -- bronze\n",
    "        END\n",
    "        ELSE 5 -- repository => green\n",
    "      END AS oa_status\n",
    "    FROM\n",
    "      base b\n",
    "      JOIN curation_requests_clean c ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE\n",
    "      c.prev_url IS NULL\n",
    "      AND c.new_url IS NOT NULL\n",
    "      AND (\n",
    "        REGEXP_REPLACE(\n",
    "          LOWER(COALESCE(b.pdf_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "        OR REGEXP_REPLACE(\n",
    "          LOWER(COALESCE(b.landing_page_url, '')),\n",
    "          '^https?://',\n",
    "          ''\n",
    "        ) = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "        OR ARRAY_CONTAINS(\n",
    "          TRANSFORM(\n",
    "            b.urls,\n",
    "            u -> REGEXP_REPLACE(LOWER(u.url), '^https?://', '') = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "          ),\n",
    "          TRUE\n",
    "        )\n",
    "      )\n",
    "  ),\n",
    "  base_filtered AS (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      base b\n",
    "    WHERE\n",
    "      NOT EXISTS (\n",
    "        SELECT\n",
    "          1\n",
    "        FROM\n",
    "          cr_matches m\n",
    "        WHERE\n",
    "          m.work_id = b.work_id\n",
    "          AND m.provenance = b.provenance\n",
    "          AND (\n",
    "            REGEXP_REPLACE(LOWER(COALESCE(m.pdf_url, '')), '^https?://', '') = REGEXP_REPLACE(LOWER(COALESCE(b.pdf_url, '')), '^https?://', '')\n",
    "            OR REGEXP_REPLACE(\n",
    "              LOWER(COALESCE(m.landing_page_url, '')),\n",
    "              '^https?://',\n",
    "              ''\n",
    "            ) = REGEXP_REPLACE(\n",
    "              LOWER(COALESCE(b.landing_page_url, '')),\n",
    "              '^https?://',\n",
    "              ''\n",
    "            )\n",
    "          )\n",
    "      )\n",
    "      AND NOT EXISTS (\n",
    "        SELECT\n",
    "          1\n",
    "        FROM\n",
    "          cr_mark_oa o\n",
    "        WHERE\n",
    "          o.work_id = b.work_id\n",
    "          AND o.provenance = b.provenance\n",
    "      )\n",
    "  ),\n",
    "  cr_new_locations AS (\n",
    "    -- new locations for curation requests that don't match existing URLs\n",
    "    SELECT\n",
    "      b.work_id,\n",
    "      'curation' AS provenance,\n",
    "      b.native_id,\n",
    "      b.native_id_namespace,\n",
    "      b.best_doi,\n",
    "      b.title,\n",
    "      b.type,\n",
    "      b.abstract,\n",
    "      b.referenced_works_count,\n",
    "      b.referenced_works,\n",
    "      b.abstract_inverted_index,\n",
    "      999 AS priority,\n",
    "      b.openalex_created_dt,\n",
    "      CURRENT_TIMESTAMP() AS openalex_updated_dt,\n",
    "      b.source_id,\n",
    "      -- Use existing source\n",
    "      b.display_name,\n",
    "      b.issn_l,\n",
    "      b.issns,\n",
    "      b.is_in_doaj,\n",
    "      b.apc_prices,\n",
    "      b.apc_usd,\n",
    "      b.is_core,\n",
    "      TRUE AS is_oa,\n",
    "      TRUE AS is_oa_raw,\n",
    "      b.is_in_doaj_raw,\n",
    "      b.is_in_doaj_stg,\n",
    "      b.is_oa_high_rate,\n",
    "      b.source_is_oa,\n",
    "      TRUE AS composite_is_oa,\n",
    "      b.is_in_doaj_start_year,\n",
    "      b.source_type,\n",
    "      b.source_name,\n",
    "      b.publisher,\n",
    "      b.published_date,\n",
    "      b.volume,\n",
    "      b.issue,\n",
    "      b.first_page,\n",
    "      b.last_page,\n",
    "      b.language,\n",
    "      b.authors,\n",
    "      ARRAY(\n",
    "        STRUCT(\n",
    "          c.new_url AS url,\n",
    "          CASE\n",
    "            WHEN LOWER(c.new_url) LIKE '%.pdf%'\n",
    "            OR LOWER(c.new_url) LIKE '%/pdf/%' THEN 'pdf'\n",
    "            ELSE 'html'\n",
    "          END AS content_type\n",
    "        )\n",
    "      ) AS urls,\n",
    "      NULL AS license,\n",
    "      b.institution_name,\n",
    "      b.publisher_name,\n",
    "      b.institution_id,\n",
    "      b.publisher_id,\n",
    "      'publishedVersion' AS version,\n",
    "      -- Set landing_page_url or pdf_url based on URL type\n",
    "      CASE\n",
    "        WHEN LOWER(c.new_url) LIKE '%.pdf%'\n",
    "        OR LOWER(c.new_url) LIKE '%/pdf/%' THEN NULL\n",
    "        ELSE c.new_url\n",
    "      END AS landing_page_url,\n",
    "      CASE\n",
    "        WHEN LOWER(c.new_url) LIKE '%.pdf%'\n",
    "        OR LOWER(c.new_url) LIKE '%/pdf/%' THEN c.new_url\n",
    "        ELSE NULL\n",
    "      END AS pdf_url,\n",
    "      b.is_retracted,\n",
    "      b.repository_id,\n",
    "      CAST(NULL AS STRING) AS pdf_s3_id,\n",
    "      CAST(NULL AS STRING) AS grobid_s3_id,\n",
    "      1 AS row_num,\n",
    "      b.host_type,\n",
    "      CASE\n",
    "        WHEN b.composite_is_oa\n",
    "        AND b.host_type = 'publisher' THEN CASE\n",
    "          WHEN ZEROIFNULL(b.apc_usd) = 0\n",
    "          AND b.source_is_oa THEN 1\n",
    "          WHEN b.source_is_oa THEN 2 -- gold\n",
    "          ELSE 4\n",
    "        END -- bronze\n",
    "        WHEN b.host_type = 'repository' THEN 5\n",
    "        ELSE 4\n",
    "      END AS oa_status\n",
    "    FROM\n",
    "      curation_requests_clean c\n",
    "      INNER JOIN base b ON LOWER(b.best_doi) = c.doi\n",
    "    WHERE\n",
    "      c.new_url IS NOT NULL\n",
    "      AND c.prev_url IS NULL -- this indicates a new URL addition, not a replacement\n",
    "      AND NOT EXISTS (\n",
    "        -- Ensure this URL doesn't already exist for this work\n",
    "        SELECT\n",
    "          1\n",
    "        FROM\n",
    "          base b2\n",
    "        WHERE\n",
    "          b2.work_id = b.work_id\n",
    "          AND (\n",
    "            REGEXP_REPLACE(\n",
    "              LOWER(COALESCE(b2.pdf_url, '')),\n",
    "              '^https?://',\n",
    "              ''\n",
    "            ) = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "            OR REGEXP_REPLACE(\n",
    "              LOWER(COALESCE(b2.landing_page_url, '')),\n",
    "              '^https?://',\n",
    "              ''\n",
    "            ) = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "            OR ARRAY_CONTAINS(\n",
    "              TRANSFORM(\n",
    "                b2.urls,\n",
    "                u -> REGEXP_REPLACE(LOWER(u.url), '^https?://', '') = REGEXP_REPLACE(LOWER(c.new_url), '^https?://', '')\n",
    "              ),\n",
    "              TRUE\n",
    "            )\n",
    "          )\n",
    "      )\n",
    "  ),\n",
    "  base_with_cr AS (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      base_filtered\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      cr_upserts\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      cr_nullify\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      cr_new_locations\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      cr_mark_oa\n",
    "  ),\n",
    "  -- deduplicate and rank landing page urls\n",
    "  base_with_landing_page_rank AS (\n",
    "    SELECT\n",
    "      *,\n",
    "      row_number() OVER (\n",
    "        PARTITION BY work_id,\n",
    "        coalesce(\n",
    "          landing_page_url,\n",
    "          get(\n",
    "            filter(urls, x -> x.content_type = \"html\").url,\n",
    "            0\n",
    "          ),\n",
    "          ''\n",
    "        )\n",
    "        ORDER BY\n",
    "          case\n",
    "            when provenance = 'crossref'\n",
    "            and best_doi is not null then 1\n",
    "            when provenance = 'crossref' then 2\n",
    "            when version = 'publishedVersion'\n",
    "            and pdf_url is not null then 3\n",
    "            when version = 'publishedVersion' then 4\n",
    "            when version = 'acceptedVersion'\n",
    "            and pdf_url is not null then 5\n",
    "            when version = 'acceptedVersion' then 6\n",
    "            when version = 'submittedVersion'\n",
    "            and pdf_url is not null then 7\n",
    "            when version = 'submittedVersion' then 8\n",
    "            else 9\n",
    "          end,\n",
    "          -- Then by url_sort_score\n",
    "          case\n",
    "            when contains(\n",
    "              coalesce(pdf_url, landing_page_url),\n",
    "              \"europepmc.org\"\n",
    "            ) then 1\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \"/pmc/\") then 2\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \"arxiv\") then 3\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \".edu\") then 4\n",
    "            else 5\n",
    "          end,\n",
    "          -- Finally by priority from priority_table\n",
    "          priority,\n",
    "          case\n",
    "            when provenance in ('repo', 'repo_backfill') then native_id\n",
    "          end\n",
    "      ) AS landing_page_rank\n",
    "    FROM\n",
    "      base_with_cr\n",
    "  ),\n",
    "  collect_all_values AS (\n",
    "    select\n",
    "      work_id,\n",
    "      collect_list(struct(best_doi, priority)) as best_dois,\n",
    "      collect_list(struct(title, priority)) as titles,\n",
    "      collect_list(struct(publisher, priority)) as publishers,\n",
    "      collect_list(struct(abstract, priority)) as abstracts,\n",
    "      array_distinct(flatten(collect_list(referenced_works))) as referenced_works,\n",
    "      -- preserve natural order (whatever it may be), sort in JSON\n",
    "      collect_list(struct(abstract_inverted_index, priority)) as abstract_inverted_indexes,\n",
    "      collect_list(struct(volume, priority)) as volumes,\n",
    "      collect_list(struct(issue, priority)) as issues,\n",
    "      collect_list(struct(first_page, priority)) as first_pages,\n",
    "      collect_list(struct(last_page, priority)) as last_pages,\n",
    "      collect_list(struct(language, priority)) as languages,\n",
    "      collect_list(struct(type, priority)) as types,\n",
    "      filter(\n",
    "        collect_list(struct(published_date, priority)),\n",
    "        x -> x.published_date is not null\n",
    "      ) as published_dates,\n",
    "      filter(\n",
    "        collect_list(struct(openalex_created_dt, priority)),\n",
    "        x -> x.openalex_created_dt is not null\n",
    "      ) as openalex_created_dts,\n",
    "      filter(\n",
    "        collect_list(struct(openalex_updated_dt, priority)),\n",
    "        x -> x.openalex_updated_dt is not null\n",
    "      ) as openalex_updated_dts,\n",
    "      filter(\n",
    "        collect_set(struct(native_id_namespace, native_id)),\n",
    "        x -> lower(x.native_id_namespace) != 'pmh'\n",
    "      ) as ids,\n",
    "      -- locations\n",
    "      collect_set(\n",
    "        struct(\n",
    "          case\n",
    "            when provenance = 'repo_backfill' then 'repo'\n",
    "            else provenance\n",
    "          end as provenance,\n",
    "          native_id,\n",
    "          case\n",
    "            when provenance = 'crossref'\n",
    "            and best_doi is not null then 1 -- publisher with a doi\n",
    "            when provenance = 'crossref' then 2 -- publisher without a doi\n",
    "            when version = 'publishedVersion'\n",
    "            and pdf_url is not null then 3 -- published version with a pdf url\n",
    "            when version = 'publishedVersion' then 4 -- published version without a pdf url\n",
    "            when version = 'acceptedVersion'\n",
    "            and pdf_url is not null then 5 -- accepted version with a pdf url\n",
    "            when version = 'acceptedVersion' then 6 -- accepted version without a pdf url\n",
    "            when version = 'submittedVersion'\n",
    "            and pdf_url is not null then 7 -- submitted version with a pdf url\n",
    "            when version = 'submittedVersion' then 8 -- submitted version without a pdf url\n",
    "            else 9\n",
    "          end as sort_score,\n",
    "          case\n",
    "            when host_type = 'repository' then (\n",
    "              is_oa_raw\n",
    "              OR composite_is_oa\n",
    "            )\n",
    "            else composite_is_oa\n",
    "          end as is_oa,\n",
    "          coalesce(\n",
    "            landing_page_url,\n",
    "            get(\n",
    "              filter(urls, x -> x.content_type = \"html\").url,\n",
    "              0\n",
    "            )\n",
    "          ) as landing_page_url,\n",
    "          pdf_url,\n",
    "          case\n",
    "            when contains(\n",
    "              coalesce(pdf_url, landing_page_url),\n",
    "              \"europepmc.org\"\n",
    "            ) then 1\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \"/pmc/\") then 2\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \"arxiv\") then 3\n",
    "            when contains(coalesce(pdf_url, landing_page_url), \".edu\") then 4\n",
    "            else 5\n",
    "          end as url_sort_score,\n",
    "          oa_status,\n",
    "          version = 'publishedVersion' as is_published,\n",
    "          version in ('acceptedVersion','publishedVersion') as is_accepted,\n",
    "          CASE \n",
    "            WHEN source_id IS NULL THEN NULL\n",
    "            ELSE struct(\n",
    "              concat(\"https://openalex.org/S\", source_id) as id,\n",
    "              display_name AS display_name,\n",
    "              issn_l,\n",
    "              issns as issn,\n",
    "              source_is_oa as is_oa,\n",
    "              is_in_doaj,\n",
    "              is_core,\n",
    "              case\n",
    "                when source_type = 'repository' then concat('https://openalex.org/I', institution_id)\n",
    "                else concat('https://openalex.org/P', publisher_id)\n",
    "              end as host_organization,\n",
    "              case\n",
    "                when source_type = 'repository' then institution_name\n",
    "                else publisher_name\n",
    "              end as host_organization_name,\n",
    "              IF ((source_type = 'repository' or source_type = 'metadata') and institution_id IS NOT NULL,\n",
    "                ARRAY(CONCAT('https://openalex.org/I', institution_id)), \n",
    "                ARRAY(CONCAT('https://openalex.org/P', publisher_id))\n",
    "              ) AS host_organization_lineage,\n",
    "              CAST(ARRAY() AS ARRAY<STRING>) AS host_organization_lineage_names,\n",
    "              source_type as type\n",
    "            )\n",
    "          END as source,\n",
    "          apc_prices,\n",
    "          apc_usd,\n",
    "          license,\n",
    "          IF(\n",
    "            license IS NOT NULL,\n",
    "            CONCAT('https://openalex.org/licenses/', license),\n",
    "            NULL\n",
    "          ) as license_id,\n",
    "          version,\n",
    "          host_type,\n",
    "          case\n",
    "            when provenance in ('repo', 'repo_backfill') then repository_id\n",
    "          end as endpoint_id,\n",
    "          case\n",
    "            when provenance in ('repo', 'repo_backfill') then native_id\n",
    "          end as pmh_id,\n",
    "          provenance = 'crossref' as is_unpaywall_record,\n",
    "          pdf_s3_id,\n",
    "          grobid_s3_id,\n",
    "          type as location_type,\n",
    "          cast(openalex_updated_dt as timestamp) as updated\n",
    "        )\n",
    "      ) as locations,\n",
    "      exists(collect_set(is_retracted), x -> x = True) as is_retracted,\n",
    "      array_contains(collect_set(provenance), 'crossref') as indexed_in_crossref\n",
    "    from\n",
    "      base_with_landing_page_rank\n",
    "    where\n",
    "      landing_page_rank = 1\n",
    "    group by\n",
    "      work_id\n",
    "  ),\n",
    "  abstracts_backfill AS (\n",
    "    SELECT\n",
    "      work_id,\n",
    "      abstract,\n",
    "      abstract_inverted_index\n",
    "    FROM\n",
    "      openalex.abstracts.abstracts_backfill\n",
    "  ),\n",
    "  approved_curations AS (\n",
    "    SELECT\n",
    "      CAST(SUBSTRING(entity_id, 2) AS BIGINT) AS work_id,\n",
    "      MAP_FROM_ENTRIES(COLLECT_LIST(STRUCT(property, property_value))) AS curations\n",
    "    FROM\n",
    "      openalex.curations.approved_curations\n",
    "    WHERE\n",
    "      entity = 'works'\n",
    "      AND property IN ('type', 'language')\n",
    "      AND status = 'approved'\n",
    "    GROUP BY work_id\n",
    "  ),\n",
    "  set_fields AS (\n",
    "    SELECT\n",
    "      work_id as id,\n",
    "      get_highest_priority_value(titles, titles.title) AS title,\n",
    "      CONCAT(\n",
    "        'https://doi.org/',\n",
    "        get_highest_priority_value(best_dois, best_dois.best_doi)\n",
    "      ) AS best_doi,\n",
    "      get_highest_priority_value(publishers, publishers.publisher) AS publisher,\n",
    "      get_highest_priority_value(\n",
    "        concat(\n",
    "          abstracts,\n",
    "          CASE\n",
    "            WHEN bf.abstract IS NOT NULL THEN array(\n",
    "              named_struct('abstract', bf.abstract, 'priority', 998)\n",
    "            )\n",
    "            ELSE array()\n",
    "          END\n",
    "        ),\n",
    "        abstracts.abstract\n",
    "      ) AS abstract,\n",
    "      SIZE(referenced_works) AS referenced_works_count,\n",
    "      referenced_works,\n",
    "      CASE\n",
    "        WHEN (\n",
    "          -- Springer/Elsevier by publisher string or host org id\n",
    "          (\n",
    "            publisher IS NOT NULL\n",
    "            AND lower(publisher) RLIKE '(springer|elsevier)'\n",
    "          )\n",
    "          OR exists(\n",
    "            locations,\n",
    "            x -> x.source.host_organization IS NOT NULL\n",
    "            AND get(split(x.source.host_organization, '/'), 4) IN ('P4310320990', 'P4310319965')\n",
    "          )\n",
    "        ) -- Allow only if best OA is diamond/gold/hybrid (1/2/3)\n",
    "        AND coalesce(\n",
    "          try_element_at(\n",
    "            transform(\n",
    "              filter(locations, x -> x.is_oa),\n",
    "              y -> y.oa_status\n",
    "            ),\n",
    "            1\n",
    "          ),\n",
    "          0\n",
    "        ) NOT IN (1, 2, 3) THEN NULL\n",
    "        ELSE get_highest_priority_value(\n",
    "          concat(\n",
    "            abstract_inverted_indexes,\n",
    "            CASE\n",
    "              WHEN bf.abstract_inverted_index IS NOT NULL THEN array(\n",
    "                named_struct(\n",
    "                  'abstract_inverted_index',\n",
    "                  bf.abstract_inverted_index,\n",
    "                  'priority',\n",
    "                  998\n",
    "                )\n",
    "              )\n",
    "              ELSE array()\n",
    "            END\n",
    "          ),\n",
    "          abstract_inverted_indexes.abstract_inverted_index\n",
    "        )\n",
    "      END AS abstract_inverted_index,\n",
    "      CASE\n",
    "        WHEN id > 6600000000 THEN TRUE\n",
    "        ELSE FALSE\n",
    "      END AS is_xpac,\n",
    "      get_highest_priority_value(volumes, volumes.volume) AS volume,\n",
    "      get_highest_priority_value(issues, issues.issue) AS issue,\n",
    "      get_highest_priority_value(first_pages, first_pages.first_page) AS first_page,\n",
    "      get_highest_priority_value(last_pages, last_pages.last_page) AS last_page,\n",
    "      COALESCE(\n",
    "        ELEMENT_AT(ac.curations, 'language'),\n",
    "        get_highest_priority_value(languages, languages.language)\n",
    "      ) AS language,\n",
    "      COALESCE(\n",
    "        ELEMENT_AT(ac.curations, 'type'),\n",
    "        get_highest_priority_value(types, types.type)\n",
    "      ) AS type,\n",
    "      TRY_CAST(\n",
    "        get_highest_priority_value(\n",
    "          openalex_created_dts,\n",
    "          openalex_created_dts.openalex_created_dt\n",
    "        ) AS DATE\n",
    "      ) AS created_date,\n",
    "      CAST(\n",
    "        get_highest_priority_value(\n",
    "          openalex_updated_dts,\n",
    "          openalex_updated_dts.openalex_updated_dt\n",
    "        ) AS TIMESTAMP\n",
    "      ) AS updated_date,\n",
    "      TRY_CAST(\n",
    "        get_highest_priority_value(published_dates, published_dates.published_date) AS DATE\n",
    "      ) AS publication_date,\n",
    "      YEAR(publication_date) AS publication_year,\n",
    "      MAP_FROM_ENTRIES(\n",
    "        AGGREGATE(\n",
    "          ids,\n",
    "          ARRAY(\n",
    "            NAMED_STRUCT(\n",
    "              'native_id_namespace',\n",
    "              'openalex',\n",
    "              'native_id',\n",
    "              CONCAT(\n",
    "                'https://openalex.org/W',\n",
    "                CAST(work_id AS STRING)\n",
    "              )\n",
    "            )\n",
    "          ),\n",
    "          (acc, x) -> CASE\n",
    "            WHEN SIZE(\n",
    "              FILTER(\n",
    "                acc,\n",
    "                y -> y.native_id_namespace = x.native_id_namespace\n",
    "              )\n",
    "            ) = 0 THEN acc || ARRAY(x)\n",
    "            ELSE acc\n",
    "          END\n",
    "        )\n",
    "      ) AS ids,\n",
    "      ARRAY_SORT(\n",
    "        locations,\n",
    "        (x, y) -> IF(\n",
    "          x.sort_score < y.sort_score,\n",
    "          -1,\n",
    "          IF(\n",
    "            x.sort_score > y.sort_score,\n",
    "            1,\n",
    "            IF(\n",
    "              x.url_sort_score < y.url_sort_score,\n",
    "              -1,\n",
    "              IF(x.url_sort_score > y.url_sort_score, 1, 0)\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      ) AS locations_sorted,\n",
    "      authorships,\n",
    "      (\n",
    "        is_retracted\n",
    "        OR lower(title) like 'retracted article%'\n",
    "        OR lower(title) like 'retracted: %'\n",
    "      ) AS is_retracted,\n",
    "      indexed_in_crossref\n",
    "    FROM\n",
    "      collect_all_values\n",
    "      LEFT JOIN identifier(\n",
    "        'openalex' || :env_suffix || '.works.authors_and_affiliations'\n",
    "      ) USING (work_id)\n",
    "      LEFT JOIN abstracts_backfill bf USING (work_id)\n",
    "      LEFT JOIN approved_curations ac USING (work_id)\n",
    "  )\n",
    "  SELECT\n",
    "    s.id,\n",
    "    s.best_doi AS doi,\n",
    "    s.title,\n",
    "    s.authorships,\n",
    "    -- @TODO make changes later to calculate them upstream - they will have to rely on Walden logic\n",
    "    CAST(ARRAY() AS ARRAY<STRING>) AS corresponding_author_ids,\n",
    "    CAST(ARRAY() AS ARRAY<STRING>) AS corresponding_institution_ids,\n",
    "    COALESCE(SIZE(ARRAY_DISTINCT(FLATTEN(s.authorships.countries))),0) as countries_distinct_count,\n",
    "    s.publication_date,\n",
    "    s.publication_year,\n",
    "    s.abstract,\n",
    "    s.abstract IS NOT NULL AS has_abstract,\n",
    "    s.referenced_works_count,\n",
    "    s.referenced_works,\n",
    "    CAST(ARRAY() AS ARRAY < STRING >) AS related_works,\n",
    "    s.abstract_inverted_index,\n",
    "    CONCAT(\n",
    "      'https://api.openalex.org/works?filter=cites:W',\n",
    "      CAST(s.id AS STRING)\n",
    "    ) AS cited_by_api_url,\n",
    "    CAST(0 AS INT) as cited_by_count,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < year: INT,\n",
    "      cited_by_count: INT > >\n",
    "    ) AS counts_by_year,\n",
    "    CAST(0.0 AS DOUBLE) as fwci,\n",
    "    CAST(\n",
    "      NULL AS STRUCT < value DOUBLE,\n",
    "      is_in_top_1_percent BOOLEAN,\n",
    "      is_in_top_10_percent BOOLEAN >\n",
    "    ) as citation_normalized_percentile,\n",
    "    CAST(NULL AS STRUCT < min INT, max INT >) as cited_by_percentile_year,\n",
    "    MAP_FILTER(\n",
    "      TRANSFORM_VALUES(\n",
    "        MAP_CONCAT(\n",
    "          MAP_FILTER(s.ids, (k, v) -> k != 'mag'),\n",
    "          map('mag', COALESCE(\n",
    "            IF(id < 4200000000, CAST(id AS STRING), NULL),\n",
    "            s.ids['mag']\n",
    "          ))\n",
    "        ),\n",
    "        (k, v) -> IF(k = 'pmid', CONCAT('https://pubmed.ncbi.nlm.nih.gov/', v), v)\n",
    "      ),\n",
    "      (k, v) -> v IS NOT NULL\n",
    "    ) as ids,\n",
    "    -- transform_values(ids, (k, v) -> case when k = 'pmid' then CONCAT('https://pubmed.ncbi.nlm.nih.gov/', v) else v end)\n",
    "    ARRAY_SORT(\n",
    "      ARRAY_DISTINCT(\n",
    "        ARRAY_COMPACT(\n",
    "          FLATTEN(\n",
    "            TRANSFORM(\n",
    "              s.locations_sorted,\n",
    "              loc -> CASE\n",
    "                WHEN loc.provenance IN ('crossref', 'pubmed', 'datacite') THEN array(\n",
    "                  loc.provenance,\n",
    "                  IF(loc.source.is_in_doaj, 'doaj', NULL)\n",
    "                )\n",
    "                WHEN loc.provenance = 'repo'\n",
    "                AND lower(loc.native_id) like 'oai:arxiv.org%' THEN array('arxiv')\n",
    "                WHEN loc.provenance = 'repo'\n",
    "                AND lower(loc.native_id) like 'oai:doaj.org/%' THEN array('doaj')\n",
    "                WHEN loc.provenance = 'mag'\n",
    "                AND lower(loc.source.display_name) = 'pubmed' THEN array('pubmed')\n",
    "                ELSE array()\n",
    "              END\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    ) as indexed_in,\n",
    "    s.language,\n",
    "    s.publisher,\n",
    "    STRUCT(s.volume, s.issue, s.first_page, s.last_page) AS biblio,\n",
    "    CASE\n",
    "      WHEN GET(GET(locations_sorted, 0).apc_prices, 0).price IS NOT NULL THEN STRUCT(\n",
    "        GET(GET(locations_sorted, 0).apc_prices, 0).price AS value,\n",
    "        GET(GET(locations_sorted, 0).apc_prices, 0).currency,\n",
    "        GET(locations_sorted, 0).apc_usd AS value_usd\n",
    "      )\n",
    "    END AS apc_list,\n",
    "    CASE\n",
    "      /* OpenAPC takes precedence whenever present */\n",
    "      WHEN o.apc_in_euro IS NOT NULL OR o.apc_in_usd IS NOT NULL THEN STRUCT(\n",
    "        o.apc_in_euro AS value,\n",
    "        'EUR'         AS currency,\n",
    "        o.apc_in_usd  AS value_usd\n",
    "      )\n",
    "      /* Otherwise: only relevant for gold/hybrid AND if a list price exists */\n",
    "      WHEN GET(FILTER(s.locations_sorted, x -> x.is_oa), 0).oa_status IN (2, 3)\n",
    "        AND GET(GET(s.locations_sorted, 0).apc_prices, 0).price IS NOT NULL \n",
    "        THEN apc_list\n",
    "        ELSE NULL\n",
    "    END AS apc_paid,\n",
    "    CAST(\n",
    "      NULL AS STRUCT < id STRING,\n",
    "      display_name STRING,\n",
    "      score FLOAT,\n",
    "      subfield STRUCT < id STRING,\n",
    "      display_name STRING >,\n",
    "      field STRUCT < id STRING,\n",
    "      display_name STRING >,\n",
    "      domain STRUCT < id STRING,\n",
    "      display_name STRING > >\n",
    "    ) AS primary_topic,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id STRING,\n",
    "      display_name STRING,\n",
    "      score FLOAT,\n",
    "      subfield STRUCT < id STRING,\n",
    "      display_name STRING >,\n",
    "      field STRUCT < id STRING,\n",
    "      display_name STRING >,\n",
    "      domain STRUCT < id STRING,\n",
    "      display_name STRING > > >\n",
    "    ) AS topics,\n",
    "    xxhash64(concat_ws('|', doi, title, abstract, GET(s.locations_sorted, 0).source.display_name)) as topics_key,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id STRING,\n",
    "      display_name STRING,\n",
    "      score FLOAT > >\n",
    "    ) AS keywords,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id BIGINT,\n",
    "      wikidata STRING,\n",
    "      display_name STRING,\n",
    "      level INT,\n",
    "      score FLOAT > >\n",
    "    ) AS concepts,\n",
    "    SIZE(s.locations_sorted) AS locations_count,\n",
    "    TRANSFORM(\n",
    "      s.locations_sorted,\n",
    "      x -> STRUCT(\n",
    "        COALESCE(x.is_oa, FALSE) AS is_oa,\n",
    "        x.landing_page_url,\n",
    "        x.pdf_url,\n",
    "        x.is_published,\n",
    "        x.is_accepted,\n",
    "        x.source,\n",
    "        x.license,\n",
    "        x.license_id,\n",
    "        x.version,\n",
    "        x.oa_status,\n",
    "        x.host_type,\n",
    "        x.endpoint_id,\n",
    "        x.pmh_id,\n",
    "        x.is_unpaywall_record,\n",
    "        x.location_type,\n",
    "        x.pdf_s3_id,\n",
    "        x.grobid_s3_id,\n",
    "        CAST(x.updated AS TIMESTAMP) AS updated,\n",
    "        x.provenance,\n",
    "        x.native_id\n",
    "      )\n",
    "    ) AS locations,\n",
    "    GET(s.locations_sorted, 0) AS primary_location,\n",
    "    GET(FILTER(s.locations_sorted, x -> x.is_oa), 0) AS best_oa_location,\n",
    "    STRUCT(\n",
    "      CASE\n",
    "        WHEN GET(FILTER(s.locations_sorted, x -> x.is_oa), 0) IS NOT NULL\n",
    "            AND GET(FILTER(s.locations_sorted, x -> x.is_oa), 0).pdf_s3_id IS NOT NULL\n",
    "        THEN TRUE ELSE FALSE\n",
    "      END AS pdf,\n",
    "      CASE\n",
    "        WHEN GET(FILTER(s.locations_sorted, x -> x.is_oa), 0) IS NOT NULL\n",
    "            AND GET(FILTER(s.locations_sorted, x -> x.is_oa), 0).grobid_s3_id IS NOT NULL\n",
    "        THEN TRUE ELSE FALSE\n",
    "      END AS `grobid_xml`\n",
    "    ) AS has_content,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id STRING,\n",
    "      display_name STRING,\n",
    "      score FLOAT > >\n",
    "    ) AS sustainable_development_goals,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < funder STRING,\n",
    "      funder_display_name STRING,\n",
    "      award_id STRING > >\n",
    "    ) AS grants,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id STRING,\n",
    "      funder_award_id STRING,\n",
    "      funder_id STRING,\n",
    "      funder_display_name STRING,\n",
    "      doi STRING > >\n",
    "    ) AS awards,\n",
    "    CAST(\n",
    "      ARRAY() AS ARRAY < STRUCT < id STRING,\n",
    "      display_name STRING,\n",
    "      ror STRING > >\n",
    "    ) AS funders,\n",
    "    STRUCT(\n",
    "      best_oa_location IS NOT NULL AS is_oa,\n",
    "      CASE\n",
    "        WHEN best_oa_location.oa_status = 1 THEN 'diamond'\n",
    "        WHEN best_oa_location.oa_status = 2 THEN 'gold'\n",
    "        WHEN best_oa_location.oa_status = 3 THEN 'hybrid'\n",
    "        WHEN best_oa_location.oa_status = 4 THEN 'bronze'\n",
    "        WHEN best_oa_location.oa_status = 5 THEN 'green'\n",
    "        ELSE 'closed'\n",
    "      END AS oa_status,\n",
    "      COALESCE(\n",
    "        best_oa_location.pdf_url,\n",
    "        best_oa_location.landing_page_url\n",
    "      ) AS oa_url,\n",
    "      CAST(NULL AS BOOLEAN) AS any_repository_has_fulltext\n",
    "    ) AS open_access,\n",
    "    s.type,\n",
    "    CAST(NULL as STRING) AS type_crossref,\n",
    "    s.type = 'paratext' AS is_paratext,    \n",
    "    s.is_retracted,\n",
    "    s.indexed_in_crossref,\n",
    "    s.is_xpac,\n",
    "    m.mesh_formatted AS mesh,\n",
    "    CAST(NULL AS STRING) AS fulltext,\n",
    "    s.created_date,\n",
    "    s.updated_date\n",
    "  FROM\n",
    "    set_fields s\n",
    "    LEFT JOIN openapc_paid o ON s.id = o.work_id\n",
    "    LEFT JOIN (\n",
    "      SELECT\n",
    "        pmid,\n",
    "        COLLECT_LIST(\n",
    "          STRUCT(\n",
    "            descriptor_ui,\n",
    "            descriptor_name,\n",
    "            qualifiers._UI AS qualifier_ui,\n",
    "            qualifiers._VALUE AS qualifier_name,\n",
    "            CASE\n",
    "              WHEN is_major_topic = 'Y' THEN TRUE\n",
    "              ELSE FALSE\n",
    "            END AS is_major_topic\n",
    "          )\n",
    "        ) AS mesh_formatted\n",
    "      FROM\n",
    "        (\n",
    "          SELECT\n",
    "            pmid,\n",
    "            EXPLODE(mesh.MeshHeading) AS mesh_exploded,\n",
    "            mesh_exploded.DescriptorName._UI AS descriptor_ui,\n",
    "            mesh_exploded.DescriptorName._VALUE AS descriptor_name,\n",
    "            EXPLODE_OUTER(\n",
    "              ARRAYS_ZIP(\n",
    "                mesh_exploded.QualifierName._UI,\n",
    "                mesh_exploded.QualifierName._VALUE\n",
    "              )\n",
    "            ) AS qualifiers,\n",
    "            mesh_exploded.DescriptorName._MajorTopicYN AS is_major_topic\n",
    "          FROM\n",
    "            (\n",
    "              SELECT\n",
    "                FILTER(\n",
    "                  PubmedData.ArticleIdList.ArticleId,\n",
    "                  x -> x._IdType = 'pubmed'\n",
    "                )._VALUE [0] AS pmid,\n",
    "                MedlineCitation.MeshHeadingList AS mesh\n",
    "              FROM\n",
    "                openalex.pubmed.pubmed_items\n",
    "            )\n",
    "        )\n",
    "      GROUP BY\n",
    "        pmid\n",
    "    ) m ON s.ids.pmid = m.pmid\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85827ffa-dabe-4213-a08a-8774c527ef81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### End CREATE Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd34be96-351d-4d39-895e-81d4f90571d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- UPDATE identifier('openalex' || :env_suffix || '.works.openalex_works') \n",
    "-- SET topics_key = xxhash64(concat_ws('|', doi, title, abstract, primary_location.source.display_name));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e71ad0a-4c88-4d60-9fff-2b8f9e8dafef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- OPTIMIZE identifier('openalex' || :env_suffix || '.works.openalex_works') FULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c22e0a6-ec93-458d-a819-2cabfa10b1d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### `MERGE` other fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd34f75-6351-4ab0-b52a-c16149b44069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956bead7-87d8-4966-b14e-b422329749bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE Backfill referenced_works (mid.citation)\n",
    "WITH prod_ref_works AS (\n",
    "  SELECT \n",
    "    paper_id as id,\n",
    "    collect_set(paper_reference_id) as referenced_works\n",
    "  FROM openalex.mid.citation\n",
    "  GROUP BY paper_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING prod_ref_works as source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  referenced_works = array_union(target.referenced_works, source.referenced_works),\n",
    "  referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));\n",
    "\n",
    "-- Calculate and MERGE the citations\n",
    "-- Far fewer changes than propagating through locations_mapped and 17 CTEs, no need to select distinct work_id data\n",
    "-- runtime about 1 min, updates 67M rows\n",
    "WITH exploded_references AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    publication_year,\n",
    "    EXPLODE(referenced_works) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE referenced_works_count > 0\n",
    "    AND publication_year <= YEAR(CURRENT_DATE())\n",
    "),\n",
    "citation_counts AS (\n",
    "  SELECT\n",
    "    cited_work_id,\n",
    "    publication_year,\n",
    "    COUNT(*) AS cited_by_count\n",
    "  FROM exploded_references\n",
    "  GROUP BY cited_work_id, publication_year\n",
    "),\n",
    "citation_counts_by_work AS (\n",
    "  SELECT \n",
    "    cited_work_id,\n",
    "    FILTER(\n",
    "      SORT_ARRAY(\n",
    "        COLLECT_LIST(\n",
    "          NAMED_STRUCT(\n",
    "            'year', publication_year,\n",
    "            'cited_by_count', cited_by_count\n",
    "          )\n",
    "        ),\n",
    "        false\n",
    "      ),\n",
    "      x -> x.year >= 2012\n",
    "    ) AS counts_by_year,\n",
    "    SUM(cited_by_count) AS cited_by_count -- total across all years\n",
    "  FROM citation_counts\n",
    "  GROUP BY cited_work_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING citation_counts_by_work AS source\n",
    "ON target.id = source.cited_work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.cited_by_count = source.cited_by_count,\n",
    "  target.counts_by_year = source.counts_by_year;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b98cb5d-5d25-446b-a200-41a67a2c9995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge full-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9a12ef-50c6-41f1-8420-e2fd0b70424c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------- Merge fulltext from PDFs --------\n",
    "WITH pdf_fulltext_for_merge AS (\n",
    "    -- DOI-based matching\n",
    "    SELECT \n",
    "        CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) AS doi_normalized,\n",
    "        NULL AS pmh_id,\n",
    "        fulltext,\n",
    "        'doi' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'doi')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID-based matching\n",
    "    SELECT \n",
    "        NULL AS doi_normalized,\n",
    "        FILTER(ids, x -> x.namespace = 'pmh')[0].id AS pmh_id,\n",
    "        fulltext,\n",
    "        'pmh' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY FILTER(ids, x -> x.namespace = 'pmh')[0].id ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'pmh')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "      -- Only include PMH records that don't have DOIs (to avoid duplicates)\n",
    "      AND SIZE(FILTER(ids, x -> x.namespace = 'doi')) = 0\n",
    "),\n",
    "pdf_fulltext_deduped AS (\n",
    "    SELECT doi_normalized, pmh_id, fulltext, match_type\n",
    "    FROM pdf_fulltext_for_merge\n",
    "    WHERE rn = 1\n",
    "),\n",
    "works_with_locations AS (\n",
    "    SELECT \n",
    "        w.id,\n",
    "        w.doi,\n",
    "        EXPLODE_OUTER(w.locations) AS location\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "),\n",
    "matched_fulltext AS (\n",
    "    -- DOI matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM (SELECT DISTINCT id, doi FROM works_with_locations) w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON LOWER(w.doi) = p.doi_normalized\n",
    "    WHERE p.doi_normalized IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM works_with_locations w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON w.location.pmh_id = p.pmh_id\n",
    "    WHERE p.pmh_id IS NOT NULL\n",
    "      AND w.location.pmh_id IS NOT NULL\n",
    "),\n",
    "final_fulltext AS (\n",
    "    -- Deduplicate in case a work matches on both DOI and PMH\n",
    "    -- Prefer DOI matches over PMH matches\n",
    "    SELECT \n",
    "        work_id,\n",
    "        fulltext,\n",
    "        ROW_NUMBER() OVER (PARTITION BY work_id ORDER BY CASE WHEN match_type = 'doi' THEN 1 ELSE 2 END) AS priority_rn\n",
    "    FROM matched_fulltext\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (SELECT work_id, fulltext FROM final_fulltext WHERE priority_rn = 1) AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.fulltext = source.fulltext;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c438dd8-62f4-48f2-843d-2ed5fe4c297d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cc4afd-bb7a-4f80-bcc2-8cd568dacffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "---------- MERGE aggregated and sorted by score Concepts from backfill --------\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING openalex.works.work_concepts_backfill AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "  target.concepts = source.concepts,\n",
    "  target.keywords = filter(source.keywords, k -> k.score > 0);\n",
    "\n",
    "---------- MERGE from predicted Concepts using concept_key --------\n",
    "-- ============= Tunable parameters =============\n",
    "DECLARE OR REPLACE VARIABLE filter_threshold FLOAT DEFAULT 0.20;  -- score cutoff for filtering\n",
    "DECLARE OR REPLACE VARIABLE base_mid         FLOAT DEFAULT 5.0;   -- target median size (bell center)\n",
    "DECLARE OR REPLACE VARIABLE half_range       FLOAT DEFAULT 6.0;   -- maximum deviation from median (-+ range)\n",
    "DECLARE OR REPLACE VARIABLE center_size      INT   DEFAULT 7;     -- where the tanh crosses 0 (inflection point)\n",
    "DECLARE OR REPLACE VARIABLE slope            FLOAT DEFAULT 0.05;  -- steepness of the tanh curve\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  SELECT concept_key,\n",
    "         FIRST(concepts_enriched) AS concepts,\n",
    "         FIRST(keywords) as keywords\n",
    "  FROM openalex.works.openalex_works_concepts_predicted\n",
    "  WHERE size(concepts_enriched) > 0 OR size(keywords) > 0\n",
    "  GROUP BY concept_key\n",
    ") as source\n",
    "ON (target.concepts IS NULL OR size(target.concepts) = 0)\n",
    "   AND xxhash64(\n",
    "     -- sanitize later\n",
    "     concat_ws('|',\n",
    "       target.title,\n",
    "       target.abstract,\n",
    "       target.primary_location.source.display_name,\n",
    "       target.primary_location.source.type\n",
    "     )\n",
    "   ) = source.concept_key\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.concepts = slice(source.concepts, 1, 40), -- too many concepts from the model - up to 130\n",
    "    target.keywords = slice(\n",
    "      filter(source.keywords, k -> k.score > 0), 1,\n",
    "      greatest(2, least(12, round(base_mid + \n",
    "          half_range * tanh((\n",
    "            size(filter(source.keywords, \n",
    "              k -> k.score > filter_threshold)) - center_size) * slope)))\n",
    "      )\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff904bd-c78d-45e3-b0a7-3035442f3cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a54451e-0a37-4306-9953-1b16e4be8fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "-- MERGE from Topics backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    topics\n",
    "  FROM openalex.works.work_topics_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON id < 6600000000\n",
    "  AND target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];\n",
    "\n",
    "-- MERGE from Topics frontfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    topics_key,\n",
    "    FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  GROUP BY topics_key\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON id > 6600000000 -- speed this up\n",
    "  AND (target.topics IS NULL or size(target.topics) = 0)\n",
    "  AND target.topics_key = source.topics_key \n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];\n",
    "\n",
    "-- MERGE Topics BY DOI\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    lower(doi) as doi,\n",
    "    FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  WHERE doi is not null\n",
    "  GROUP BY doi\n",
    ") AS source\n",
    "-- don't force update if topics are populated already (@TODO - should we revisit this)\n",
    "ON (target.topics IS NULL or size(target.topics) = 0)\n",
    "  AND target.doi = source.doi\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ac29702-1f81-461a-b39c-e988465b99a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MERGE fwci and citation percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724a1f41-81a3-4c95-bf0e-1b2f9aba7495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- FWCI + cohort percentile (pub+3 within pub_year/subfield_id/work_type)\n",
    "-- + cited_by_percentile_year (global by eval_year)\n",
    "-- Computes everything from citation edges (referenced_works); no counts_by_year usage.\n",
    "\n",
    "WITH base AS (  -- candidate works + work_type mapping\n",
    "  SELECT\n",
    "    id AS work_id,\n",
    "    CASE\n",
    "      WHEN type = 'article'\n",
    "           AND primary_location.source.type = 'conference' THEN 'conference_article'\n",
    "      WHEN type IN ('article', 'book', 'review', 'book-chapter') THEN type\n",
    "      ELSE NULL\n",
    "    END AS work_type,\n",
    "    COALESCE(publication_year, YEAR(publication_date)) AS pub_year,\n",
    "    primary_topic.subfield.id AS subfield_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE primary_topic.subfield.id IS NOT NULL\n",
    "    AND COALESCE(publication_year, YEAR(publication_date)) IS NOT NULL\n",
    "),\n",
    "\n",
    "-- All citation edges: (citing_year -> cited_work_id)\n",
    "edges AS (\n",
    "  SELECT\n",
    "    w.publication_year AS citing_year,\n",
    "    EXPLODE(COALESCE(w.referenced_works, ARRAY())) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works') AS w\n",
    "  WHERE w.referenced_works_count > 0\n",
    "    AND w.publication_year IS NOT NULL\n",
    "    AND w.publication_year <= YEAR(CURRENT_DATE())\n",
    "),\n",
    "\n",
    "-- Per-work pub+3 citations via edges (join + conditional sum)\n",
    "three_years AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.subfield_id,\n",
    "    b.pub_year,\n",
    "    b.work_type,\n",
    "    SUM(\n",
    "      CASE\n",
    "        WHEN e.citing_year BETWEEN b.pub_year AND LEAST(b.pub_year + 3, YEAR(CURRENT_DATE()))\n",
    "        THEN 1 ELSE 0\n",
    "      END\n",
    "    ) AS pub_plus_3_citations\n",
    "  FROM base b\n",
    "  LEFT JOIN edges e\n",
    "    ON e.cited_work_id = b.work_id\n",
    "  WHERE b.work_type IS NOT NULL\n",
    "  GROUP BY b.work_id, b.subfield_id, b.pub_year, b.work_type\n",
    "),\n",
    "\n",
    "-- Join monthly cohort means to compute FWCI and carry p90/p99 thresholds\n",
    "with_fwci AS (\n",
    "  SELECT\n",
    "    t.work_id,\n",
    "    t.subfield_id,\n",
    "    t.pub_year,\n",
    "    t.work_type,\n",
    "    t.pub_plus_3_citations,\n",
    "    CASE\n",
    "      WHEN d.mean_citations IS NULL OR d.mean_citations <= 0 THEN NULL\n",
    "      ELSE t.pub_plus_3_citations / d.mean_citations\n",
    "    END AS fwci,\n",
    "    d.p90_threshold,\n",
    "    d.p99_threshold\n",
    "  FROM three_years t\n",
    "  LEFT JOIN openalex.common.citations_mean_pub_year_type d\n",
    "    ON d.publication_year = t.pub_year\n",
    "   AND d.subfield_id      = t.subfield_id\n",
    "   AND d.work_type        = t.work_type\n",
    "),\n",
    "\n",
    "-- Cohort percentile for pub+3 within (pub_year, subfield_id, work_type) + top-1/10 flags\n",
    "with_percentile AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    subfield_id,\n",
    "    pub_year,\n",
    "    work_type,\n",
    "    pub_plus_3_citations,\n",
    "    ROUND(fwci, 8) AS fwci,\n",
    "    ROUND(\n",
    "      PERCENT_RANK() OVER (\n",
    "        PARTITION BY pub_year, subfield_id, work_type\n",
    "        ORDER BY pub_plus_3_citations, work_id\n",
    "      ), 8\n",
    "    ) AS citation_pct_cohort,\n",
    "    (p99_threshold IS NOT NULL AND pub_plus_3_citations >= p99_threshold) AS is_in_top_1_percent,\n",
    "    (p90_threshold IS NOT NULL AND pub_plus_3_citations >= p90_threshold) AS is_in_top_10_percent\n",
    "  FROM with_fwci\n",
    "),\n",
    "\n",
    "/* ===== cited_by_percentile_year (global by eval_year), computed from edges ===== */\n",
    "\n",
    "by_year AS (\n",
    "  SELECT\n",
    "    e.cited_work_id,\n",
    "    e.citing_year,\n",
    "    COUNT(*) AS citation_count\n",
    "  FROM edges e\n",
    "  GROUP BY e.cited_work_id, e.citing_year\n",
    "),\n",
    "\n",
    "latest AS (\n",
    "  SELECT\n",
    "    cited_work_id AS work_id,\n",
    "    GREATEST(MAX(citing_year), 1920) AS eval_year\n",
    "  FROM by_year\n",
    "  GROUP BY cited_work_id\n",
    "),\n",
    "\n",
    "work_counts AS (\n",
    "  -- citation_count for that work in its eval_year (0 if none)\n",
    "  SELECT\n",
    "    l.work_id,\n",
    "    l.eval_year,\n",
    "    COALESCE(MAX(CASE WHEN b.citing_year = l.eval_year THEN b.citation_count END), 0) AS citation_count\n",
    "  FROM latest l\n",
    "  LEFT JOIN by_year b\n",
    "    ON b.cited_work_id = l.work_id\n",
    "  GROUP BY l.work_id, l.eval_year\n",
    "),\n",
    "\n",
    "per_year_dist AS (\n",
    "  SELECT\n",
    "    citing_year,\n",
    "    citation_count,\n",
    "    PERCENT_RANK() OVER (PARTITION BY citing_year ORDER BY citation_count) AS pct\n",
    "  FROM (SELECT DISTINCT citing_year, citation_count FROM by_year)\n",
    "),\n",
    "\n",
    "bounds AS (\n",
    "  SELECT\n",
    "    w.work_id,\n",
    "    MAX(CASE WHEN d.citation_count <= w.citation_count THEN d.pct END) AS lower_pct,\n",
    "    MIN(CASE WHEN d.citation_count >= w.citation_count THEN d.pct END) AS upper_pct\n",
    "  FROM work_counts w\n",
    "  JOIN per_year_dist d\n",
    "    ON d.citing_year = w.eval_year\n",
    "  GROUP BY w.work_id\n",
    "),\n",
    "\n",
    "formatted_year_pct AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    NAMED_STRUCT(\n",
    "      'min',\n",
    "        CASE\n",
    "          WHEN ROUND(COALESCE(lower_pct, 0) * 100) = 100 THEN 99\n",
    "          WHEN ROUND(COALESCE(lower_pct, 0) * 100) = ROUND(COALESCE(upper_pct, 0) * 100)\n",
    "            THEN GREATEST(CAST(ROUND(COALESCE(lower_pct, 0) * 100) AS INT) - 1, 0)\n",
    "          ELSE CAST(ROUND(COALESCE(lower_pct, 0) * 100) AS INT)\n",
    "        END,\n",
    "      'max',\n",
    "        CASE\n",
    "          WHEN ROUND(COALESCE(upper_pct, 0) * 100) = 100 THEN 100\n",
    "          ELSE CAST(ROUND(COALESCE(upper_pct, 0) * 100) AS INT)\n",
    "        END\n",
    "    ) AS cited_by_percentile_year\n",
    "  FROM bounds\n",
    "),\n",
    "\n",
    "updates AS (\n",
    "  SELECT\n",
    "    p.work_id,\n",
    "    p.fwci,\n",
    "    NAMED_STRUCT(\n",
    "      'value', p.citation_pct_cohort,\n",
    "      'is_in_top_1_percent', p.is_in_top_1_percent,\n",
    "      'is_in_top_10_percent', p.is_in_top_10_percent\n",
    "    ) AS citation_normalized_percentile,\n",
    "    y.cited_by_percentile_year\n",
    "  FROM with_percentile p\n",
    "  LEFT JOIN formatted_year_pct y\n",
    "    ON y.work_id = p.work_id\n",
    ")\n",
    "-- Preview:\n",
    "-- SELECT * FROM updates;\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING updates AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED\n",
    "THEN UPDATE SET\n",
    "  target.fwci = COALESCE(source.fwci, target.fwci),\n",
    "  target.citation_normalized_percentile =\n",
    "    COALESCE(source.citation_normalized_percentile, target.citation_normalized_percentile),\n",
    "  target.cited_by_percentile_year =\n",
    "    COALESCE(source.cited_by_percentile_year, target.cited_by_percentile_year);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afbf6595-e492-47b2-9612-48d1dc64f655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `sustainable_development_goals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2a139e-f3f3-42d0-a305-85b523b7ecfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from SDG backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    paper_id,\n",
    "    sustainable_development_goals\n",
    "  FROM openalex.works.work_sdg_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON target.id = source.paper_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.sustainable_development_goals = source.sustainable_development_goals;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2184bf0-ff09-4205-8868-1786314d51ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `grants`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4488ecd9-c1cb-4c95-9cd3-0953a13595ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  WITH funders_exploded AS (\n",
    "    SELECT \n",
    "      paper_id, funder_id, display_name, explode_outer(award_ids) as award_id\n",
    "    FROM openalex.mid.work_funder\n",
    "    JOIN openalex.common.funder USING (funder_id)\n",
    "  )\n",
    "  SELECT paper_id,\n",
    "    array_sort(\n",
    "      collect_list(\n",
    "        struct(\n",
    "          CONCAT(\"https://openalex.org/F\", funder_id) as funder,\n",
    "          display_name as funder_display_name,\n",
    "          award_id\n",
    "        )\n",
    "      )\n",
    "    ) as grants\n",
    "  FROM funders_exploded\n",
    "  GROUP BY paper_id\n",
    ") as source\n",
    "ON target.id = source.paper_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.grants = source.grants;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c269057d-8277-4bc4-b4d3-b23a5576588c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `awards`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3646b5c3-e567-4a9a-a569-a80ddbb9f855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT work_id,\n",
    "    collect_set(\n",
    "      struct(\n",
    "        CONCAT('https://openalex.org/G', id) as id,\n",
    "        award_id as funder_award_id,\n",
    "        CONCAT('https://openalex.org/F', funder_id) as funder_id,\n",
    "        COALESCE(f.display_name, a.funder_name) as funder_display_name,\n",
    "        doi_url as doi\n",
    "      )\n",
    "    ) as awards\n",
    "  FROM openalex.works.work_awards a\n",
    "  JOIN openalex.common.funder f \n",
    "    ON a.funder_ids.doi = f.doi OR a.funder_ids.ror_id = f.ror_id\n",
    "  WHERE work_id IS NOT NULL\n",
    "  GROUP BY work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.awards = source.awards;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8babb83-6f0f-43bc-a6c3-7e6447a05a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `funders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e744f175-0132-495a-89e4-afcd0cdbf58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Build rolled funders from AWARDS + FULLTEXT (no lateral view; explode in SELECT)\n",
    "WITH from_awards AS (\n",
    "  SELECT\n",
    "    id AS work_id,\n",
    "    explode(\n",
    "      array_distinct(\n",
    "        array_compact(\n",
    "          awards.funder_id\n",
    "        )\n",
    "      )\n",
    "    ) AS funder_id\n",
    "  FROM openalex.works.openalex_works\n",
    "  WHERE size(awards) > 0\n",
    "),\n",
    "from_awards_enriched AS (\n",
    "  SELECT\n",
    "    a.work_id,\n",
    "    a.funder_id,\n",
    "    mf.ror_id AS ror,\n",
    "    mf.display_name AS display_name\n",
    "  FROM from_awards a\n",
    "  LEFT JOIN openalex.mid.funder mf\n",
    "    ON CONCAT(\"https://openalex.org/F\", mf.funder_id) = a.funder_id\n",
    "),\n",
    "from_grants AS (\n",
    "  SELECT\n",
    "    id AS work_id,\n",
    "    explode(\n",
    "      array_distinct(\n",
    "        array_compact(\n",
    "          grants.funder\n",
    "        )\n",
    "      )\n",
    "    ) AS funder_id\n",
    "  FROM openalex.works.openalex_works\n",
    "  WHERE size(grants) > 0\n",
    "),\n",
    "from_grants_enriched AS (\n",
    "  SELECT\n",
    "    a.work_id,\n",
    "    a.funder_id,\n",
    "    mf.ror_id AS ror,\n",
    "    mf.display_name AS display_name\n",
    "  FROM from_grants a\n",
    "  LEFT JOIN openalex.mid.funder mf\n",
    "    ON CONCAT(\"https://openalex.org/F\", mf.funder_id) = a.funder_id\n",
    "),\n",
    "from_fulltext_enriched AS (\n",
    "  SELECT\n",
    "    ft.work_id,\n",
    "    ft.funder_id,\n",
    "    /* fulltext already has both name & ror */\n",
    "    ft.ror_id AS ror,\n",
    "    ft.funder_display_name AS display_name\n",
    "  FROM openalex.works.fulltext_work_funders ft\n",
    "  JOIN openalex.common.funder_names_keep keep ON keep.name = ft.funder_name\n",
    "),\n",
    "unioned AS (\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_awards_enriched\n",
    "  UNION ALL\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_grants_enriched\n",
    "  UNION ALL  \n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_fulltext_enriched\n",
    "),\n",
    "dedup AS (\n",
    "  -- one row per (work_id, funder_id), pick deterministic values\n",
    "  SELECT\n",
    "    work_id,\n",
    "    funder_id,\n",
    "    MAX(display_name) AS display_name,\n",
    "    MAX(ror) AS ror\n",
    "  FROM unioned\n",
    "  GROUP BY work_id, funder_id\n",
    "),\n",
    "rolled_up AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    -- order by funder_id via lexicographic struct ordering (id is first field)\n",
    "    sort_array(\n",
    "      collect_list(\n",
    "        struct(\n",
    "          funder_id as id,\n",
    "          display_name,\n",
    "          ror\n",
    "        )\n",
    "      )\n",
    "    ) AS funders\n",
    "  FROM dedup\n",
    "  GROUP BY work_id\n",
    ")\n",
    "-- SELECT * from rolled;\n",
    "-- 2) Merge into openalex_works.funders (array<struct<id:string, ror:string, display_name:string>>)\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING rolled_up AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET target.funders = source.funders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01af4136-9ab3-4150-b55f-14e5d9c77f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `authorships'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294312bf-f88c-4464-8390-552ab98c9720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT paper_id as work_id,\n",
    "    authorships,\n",
    "    corresponding_author_ids,\n",
    "    corresponding_institution_ids\n",
    "  FROM openalex.authors.work_authorships_backfill_moderated\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.authorships IS NOT NULL and size(source.authorships) > 0 THEN UPDATE\n",
    "  SET\n",
    "    target.authorships = source.authorships,\n",
    "    target.corresponding_author_ids = source.corresponding_author_ids,\n",
    "    target.corresponding_institution_ids = source.corresponding_institution_ids;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9522f03a-d2d4-4a64-a315-850dc7204a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `work.type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c92f069-2c0b-4ed6-82b6-db094fc20e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  WITH approved_curations AS (\n",
    "    SELECT\n",
    "      CAST(SUBSTRING(entity_id, 2) AS BIGINT) AS work_id,\n",
    "      MAP_FROM_ENTRIES(COLLECT_LIST(STRUCT(property, property_value))) AS curations\n",
    "    FROM\n",
    "      openalex.curations.approved_curations\n",
    "    WHERE\n",
    "      entity = 'works'\n",
    "      AND property IN ('type', 'language')\n",
    "      AND status = 'approved'\n",
    "    GROUP BY CAST(SUBSTRING(entity_id, 2) AS BIGINT)\n",
    "  )\n",
    "  SELECT \n",
    "    w.paper_id as work_id,\n",
    "    w.type,\n",
    "    w.type_crossref,\n",
    "    ac.work_id IS NOT NULL as has_curation\n",
    "  FROM openalex.mid.work w\n",
    "  LEFT JOIN approved_curations ac ON w.paper_id = ac.work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED \n",
    "  AND target.type <> source.type\n",
    "  AND source.type IS NOT NULL\n",
    "  AND source.has_curation = FALSE\n",
    "THEN UPDATE SET\n",
    "  target.type = COALESCE(source.type, target.type),\n",
    "  target.type_crossref = source.type_crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfdc6724-f0ac-488b-a838-55fbecb097fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MERGE `related_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a893b4d-c53d-41ac-851d-1dad836488bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  SELECT \n",
    "    work_id, related_works\n",
    "  FROM openalex.works.related_works_backfill\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.related_works IS NOT NULL AND SIZE(source.related_works) > 0\n",
    "THEN UPDATE SET\n",
    "  target.related_works = source.related_works"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateOpenAlexWorks",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "a32b9271-2b7f-475b-8140-bb4789e5a680",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
