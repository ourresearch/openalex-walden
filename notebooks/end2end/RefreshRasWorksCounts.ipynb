{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Refresh RAS Works Counts\n\nRebuilds the `affiliation_strings_lookup_with_counts` table with fresh works counts\nfrom `OpenAlex_works` and institution IDs from the MV (which includes curations).\n\nUses a MERGE with content hashing to detect changes â€” only rows with changed data\nget a new `refreshed_at` timestamp, enabling incremental ES sync downstream.\n\n**Runs after**: Guardrails (needs finalized works data)\n**Feeds**: `sync_affiliation_strings_to_elastic_v2` (ES sync for dashboard)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Rebuild works counts per RAS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "-- Rebuild works counts by exploding authorships from OpenAlex_works.\n-- This replaces the entire counts table with fresh data.\nCREATE OR REPLACE TABLE openalex.institutions.affiliation_string_works_counts AS\nSELECT\n    raw_aff_string,\n    COUNT(DISTINCT w.id) as works_count\nFROM openalex.works.OpenAlex_works w\nLATERAL VIEW EXPLODE(authorships) AS authorship\nLATERAL VIEW EXPLODE(authorship.raw_affiliation_strings) AS raw_aff_string\nGROUP BY raw_aff_string",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "-- Quick sanity check\nSELECT\n  COUNT(*) AS total_unique_ras,\n  SUM(works_count) AS total_works_count,\n  MIN(works_count) AS min_works,\n  MAX(works_count) AS max_works\nFROM openalex.institutions.affiliation_string_works_counts",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: MERGE lookup with counts (hash-based change detection)\n\nBuilds a staging table with a `content_hash` of key fields, then MERGEs into the\ntarget. Only rows where the hash changed get `refreshed_at` updated, enabling\nincremental ES sync. New rows are inserted, removed rows are deleted."
  },
  {
   "cell_type": "code",
   "source": "-- Enable schema auto-merge so the MERGE can add content_hash and refreshed_at\n-- columns to the existing table on first run (they'll start as NULLs).\nSET spark.databricks.delta.schema.autoMerge.enabled = true",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "-- Build staging table with content hash for change detection\nCREATE OR REPLACE TABLE openalex.institutions._ras_lookup_staging AS\nSELECT\n    mv.raw_affiliation_string,\n    mv.institution_ids AS institution_ids_final,\n    mv.model_institution_ids AS institution_ids_from_model,\n    mv.institution_ids_override,\n    mv.countries,\n    mv.source,\n    mv.created_datetime,\n    mv.updated_datetime,\n    c.works_count,\n    SHA2(TO_JSON(NAMED_STRUCT(\n        'iif', mv.institution_ids,\n        'iim', mv.model_institution_ids,\n        'iio', mv.institution_ids_override,\n        'c', mv.countries,\n        'wc', c.works_count\n    )), 256) AS content_hash\nFROM openalex.institutions.raw_affiliation_strings_institutions_mv mv\nINNER JOIN openalex.institutions.affiliation_string_works_counts c\n    ON mv.raw_affiliation_string = c.raw_aff_string",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "-- MERGE with hash-based change detection.\n-- Only updates rows where content actually changed (new refreshed_at).\n-- Inserts new rows, deletes rows no longer in source.\n-- On first run, COALESCE(target.content_hash, '') handles NULLs from schema migration.\nMERGE INTO openalex.institutions.affiliation_strings_lookup_with_counts AS target\nUSING openalex.institutions._ras_lookup_staging AS source\nON target.raw_affiliation_string = source.raw_affiliation_string\nWHEN MATCHED AND COALESCE(target.content_hash, '') <> source.content_hash THEN\n    UPDATE SET\n        institution_ids_final = source.institution_ids_final,\n        institution_ids_from_model = source.institution_ids_from_model,\n        institution_ids_override = source.institution_ids_override,\n        countries = source.countries,\n        source = source.source,\n        created_datetime = source.created_datetime,\n        updated_datetime = source.updated_datetime,\n        works_count = source.works_count,\n        content_hash = source.content_hash,\n        refreshed_at = CURRENT_TIMESTAMP()\nWHEN NOT MATCHED THEN\n    INSERT (raw_affiliation_string, institution_ids_final, institution_ids_from_model,\n            institution_ids_override, countries, source, created_datetime, updated_datetime,\n            works_count, content_hash, refreshed_at)\n    VALUES (source.raw_affiliation_string, source.institution_ids_final, source.institution_ids_from_model,\n            source.institution_ids_override, source.countries, source.source, source.created_datetime,\n            source.updated_datetime, source.works_count, source.content_hash, CURRENT_TIMESTAMP())\nWHEN NOT MATCHED BY SOURCE THEN DELETE",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "DROP TABLE IF EXISTS openalex.institutions._ras_lookup_staging",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "-- Verify rebuild + change detection stats\nSELECT\n  COUNT(*) AS total_rows,\n  COUNT(CASE WHEN SIZE(institution_ids_final) > 0 THEN 1 END) AS rows_with_institutions,\n  ROUND(COUNT(CASE WHEN SIZE(institution_ids_final) > 0 THEN 1 END) * 100.0 / COUNT(*), 1) AS pct_with_institutions,\n  COUNT(CASE WHEN refreshed_at >= CURRENT_DATE() THEN 1 END) AS rows_refreshed_today,\n  MIN(refreshed_at) AS oldest_refresh,\n  MAX(refreshed_at) AS newest_refresh\nFROM openalex.institutions.affiliation_strings_lookup_with_counts",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}