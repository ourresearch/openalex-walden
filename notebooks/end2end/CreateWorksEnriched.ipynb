{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c1149f-4741-4f09-b8df-c333d3c6a54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create and enrich `openalex.works.openalex_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8aeae97-55b1-4aad-b5ed-114c15f0f9d1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765986655708}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE openalex.works.openalex_works \n",
    "DEEP CLONE openalex.works.openalex_works_base  -- unable to use env_suffix with deep clone, set manually\n",
    "TBLPROPERTIES (\n",
    "  'delta.dataSkippingNumIndexedCols' = 36,\n",
    "  'delta.deletedFileRetentionDuration' = '30 days',\n",
    "  'delta.logRetentionDuration' = '30 days'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfd34f75-6351-4ab0-b52a-c16149b44069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge citations and referenced_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd4e4e3e-96b1-433f-953c-c5d2f5c31f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE Backfill referenced_works (mid.citation) - 95,305,004 works updated\n",
    "WITH prod_ref_works AS (\n",
    "  SELECT \n",
    "    paper_id as id,\n",
    "    collect_set(paper_reference_id) as referenced_works\n",
    "  FROM openalex.mid.citation\n",
    "  GROUP BY paper_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING prod_ref_works as source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  referenced_works = array_union(target.referenced_works, source.referenced_works),\n",
    "  referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc98aad-f096-44b2-a340-99a59a21df19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- use newly refreshed parsed data (overlap with mid.citation backfill above, add more if exists) -- 102,749,754\n",
    "MERGE INTO openalex.works.openalex_works AS target\n",
    "USING openalex.works.referenced_works AS source\n",
    "ON target.id = source.citing_work_id\n",
    "WHEN MATCHED -- AND (target.referenced_works is null OR size(target.referenced_works) = 0) -- either don't overwrite or union\n",
    "THEN UPDATE SET\n",
    "  target.referenced_works = array_union(target.referenced_works, source.referenced_works),\n",
    "  target.referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269f8620-ab83-416d-bf69-d3eb1401ce8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge cited_by_count and counts_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956bead7-87d8-4966-b14e-b422329749bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Calculate and MERGE the citations\n",
    "-- Far fewer changes than propagating through locations_mapped and 17 CTEs, no need to select distinct work_id data\n",
    "-- runtime about 1 min, updates 67M rows\n",
    "WITH exploded_references AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    publication_year,\n",
    "    EXPLODE(referenced_works) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE referenced_works_count > 0\n",
    "    AND publication_year <= YEAR(CURRENT_DATE())\n",
    "    AND type != 'dataset'\n",
    "),\n",
    "citation_counts AS (\n",
    "  SELECT\n",
    "    cited_work_id,\n",
    "    publication_year,\n",
    "    COUNT(*) AS cited_by_count\n",
    "  FROM exploded_references\n",
    "  GROUP BY cited_work_id, publication_year\n",
    "),\n",
    "citation_counts_by_work AS (\n",
    "  SELECT \n",
    "    cited_work_id,\n",
    "    FILTER(\n",
    "      SORT_ARRAY(\n",
    "        COLLECT_LIST(\n",
    "          NAMED_STRUCT(\n",
    "            'year', publication_year,\n",
    "            'cited_by_count', cited_by_count\n",
    "          )\n",
    "        ),\n",
    "        false\n",
    "      ),\n",
    "      x -> x.year >= 2012\n",
    "    ) AS counts_by_year,\n",
    "    SUM(cited_by_count) AS cited_by_count -- total across all years\n",
    "  FROM citation_counts\n",
    "  GROUP BY cited_work_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING citation_counts_by_work AS source\n",
    "ON target.id = source.cited_work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.cited_by_count = source.cited_by_count,\n",
    "  target.counts_by_year = source.counts_by_year;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b98cb5d-5d25-446b-a200-41a67a2c9995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge full-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9a12ef-50c6-41f1-8420-e2fd0b70424c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------- Merge fulltext from PDFs --------\n",
    "WITH pdf_fulltext_for_merge AS (\n",
    "    -- DOI-based matching\n",
    "    SELECT \n",
    "        CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) AS doi_normalized,\n",
    "        NULL AS pmh_id,\n",
    "        fulltext,\n",
    "        'doi' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'doi')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID-based matching\n",
    "    SELECT \n",
    "        NULL AS doi_normalized,\n",
    "        FILTER(ids, x -> x.namespace = 'pmh')[0].id AS pmh_id,\n",
    "        fulltext,\n",
    "        'pmh' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY FILTER(ids, x -> x.namespace = 'pmh')[0].id ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'pmh')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "      -- Only include PMH records that don't have DOIs (to avoid duplicates)\n",
    "      AND SIZE(FILTER(ids, x -> x.namespace = 'doi')) = 0\n",
    "),\n",
    "pdf_fulltext_deduped AS (\n",
    "    SELECT doi_normalized, pmh_id, fulltext, match_type\n",
    "    FROM pdf_fulltext_for_merge\n",
    "    WHERE rn = 1\n",
    "),\n",
    "works_with_locations AS (\n",
    "    SELECT \n",
    "        w.id,\n",
    "        w.doi,\n",
    "        EXPLODE_OUTER(w.locations) AS location\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "),\n",
    "matched_fulltext AS (\n",
    "    -- DOI matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM (SELECT DISTINCT id, doi FROM works_with_locations) w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON LOWER(w.doi) = p.doi_normalized\n",
    "    WHERE p.doi_normalized IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM works_with_locations w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON w.location.pmh_id = p.pmh_id\n",
    "    WHERE p.pmh_id IS NOT NULL\n",
    "      AND w.location.pmh_id IS NOT NULL\n",
    "),\n",
    "final_fulltext AS (\n",
    "    -- Deduplicate in case a work matches on both DOI and PMH\n",
    "    -- Prefer DOI matches over PMH matches\n",
    "    SELECT \n",
    "        work_id,\n",
    "        fulltext,\n",
    "        ROW_NUMBER() OVER (PARTITION BY work_id ORDER BY CASE WHEN match_type = 'doi' THEN 1 ELSE 2 END) AS priority_rn\n",
    "    FROM matched_fulltext\n",
    "),\n",
    "cleaned_fulltext AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        TRIM(\n",
    "            REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                    REGEXP_REPLACE(\n",
    "                        SUBSTRING(fulltext, 1, 200000),\n",
    "                        '<[^>]+>',  -- Remove HTML tags\n",
    "                        ' '\n",
    "                    ),\n",
    "                    '\\\\s+',         -- Replace multiple whitespace with single space\n",
    "                    ' '\n",
    "                ),\n",
    "                '(^\\\\s+|\\\\s+$)',    -- Additional trim for safety\n",
    "                ''\n",
    "            )\n",
    "        ) AS cleaned_fulltext\n",
    "    FROM final_fulltext \n",
    "    WHERE priority_rn = 1\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        work_id, \n",
    "        cleaned_fulltext AS fulltext\n",
    "    FROM cleaned_fulltext\n",
    "    WHERE cleaned_fulltext IS NOT NULL \n",
    "      AND LENGTH(cleaned_fulltext) > 0\n",
    ") AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.fulltext = source.fulltext;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c438dd8-62f4-48f2-843d-2ed5fe4c297d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a47ce009-7525-436f-97f9-e528c5ca914e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cc4afd-bb7a-4f80-bcc2-8cd568dacffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "---------- MERGE aggregated and sorted by score Concepts from backfill --------\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING openalex.works.work_concepts_backfill AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "  target.concepts = source.concepts,\n",
    "  target.keywords = filter(source.keywords, k -> k.score > 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7ced136-ec40-4a5f-84f0-5eb401e80200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6aad29-e0ad-44a5-b75c-e026a96f5c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---------- MERGE from predicted Concepts using concept_key --------\n",
    "-- ============= Tunable parameters =============\n",
    "DECLARE OR REPLACE VARIABLE filter_threshold FLOAT DEFAULT 0.20;  -- score cutoff for filtering\n",
    "DECLARE OR REPLACE VARIABLE base_mid         FLOAT DEFAULT 5.0;   -- target median size (bell center)\n",
    "DECLARE OR REPLACE VARIABLE half_range       FLOAT DEFAULT 6.0;   -- maximum deviation from median (-+ range)\n",
    "DECLARE OR REPLACE VARIABLE center_size      INT   DEFAULT 7;     -- where the tanh crosses 0 (inflection point)\n",
    "DECLARE OR REPLACE VARIABLE slope            FLOAT DEFAULT 0.05;  -- steepness of the tanh curve\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  SELECT concept_key,\n",
    "         FIRST(concepts_enriched) AS concepts,\n",
    "         FIRST(keywords) as keywords\n",
    "  FROM openalex.works.openalex_works_concepts_predicted\n",
    "  WHERE size(concepts_enriched) > 0 OR size(keywords) > 0\n",
    "  GROUP BY concept_key\n",
    ") as source\n",
    "ON -- (target.concepts IS NULL OR size(target.concepts) = 0) AND \n",
    "   xxhash64(\n",
    "     concat_ws('|',\n",
    "       target.title,\n",
    "       target.abstract,\n",
    "       target.primary_location.source.display_name,\n",
    "       target.primary_location.source.type\n",
    "     )\n",
    "   ) = source.concept_key\n",
    "WHEN MATCHED AND id > 6600000000 THEN\n",
    "  UPDATE SET\n",
    "    target.concepts = slice(source.concepts, 1, 40), -- too many concepts from the model - up to 130\n",
    "    target.keywords = slice(\n",
    "      filter(source.keywords, k -> k.score > 0), 1,\n",
    "      greatest(2, least(12, round(base_mid + \n",
    "          half_range * tanh((\n",
    "            size(filter(source.keywords, \n",
    "              k -> k.score > filter_threshold)) - center_size) * slope)))\n",
    "      )\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff904bd-c78d-45e3-b0a7-3035442f3cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "058148d5-6fca-46ec-b42d-a4146016d53d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72bfc45-46c4-41ec-ad5d-bebc80d2a12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from Topics backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    topics\n",
    "  FROM openalex.works.work_topics_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON id < 6600000000\n",
    "  AND target.id = source.work_id AND (target.topics IS NULL or SIZE(target.topics) = 0)\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff40579-2819-4267-a225-92bbd4fbcce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Frontfill by work_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a54451e-0a37-4306-9953-1b16e4be8fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from Topics frontfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  GROUP BY work_id\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON target.id = source.work_id\n",
    "  AND id > 6600000000 -- speed this up\n",
    "  AND (target.topics IS NULL or size(target.topics) = 0)\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.topics = source.topics,\n",
    "    target.primary_topic = source.topics[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac29702-1f81-461a-b39c-e988465b99a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calculate fwci and citation percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724a1f41-81a3-4c95-bf0e-1b2f9aba7495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- FWCI + cohort percentile (pub+3 within pub_year/subfield_id/work_type) -- 257,176,397 updated\n",
    "-- + cited_by_percentile_year (global by eval_year)\n",
    "-- Computes everything from citation edges (referenced_works); no counts_by_year usage.\n",
    "\n",
    "WITH base AS (  -- candidate works + work_type mapping\n",
    "  SELECT\n",
    "    id AS work_id,\n",
    "    CASE\n",
    "      WHEN type = 'article'\n",
    "           AND primary_location.source.type = 'conference' THEN 'conference_article'\n",
    "      WHEN type IN ('article', 'book', 'review', 'book-chapter') THEN type\n",
    "      ELSE NULL\n",
    "    END AS work_type,\n",
    "    COALESCE(publication_year, YEAR(publication_date)) AS pub_year,\n",
    "    primary_topic.subfield.id AS subfield_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE primary_topic.subfield.id IS NOT NULL\n",
    "    AND COALESCE(publication_year, YEAR(publication_date)) IS NOT NULL\n",
    "),\n",
    "\n",
    "-- All citation edges: (citing_year -> cited_work_id)\n",
    "edges AS (\n",
    "  SELECT\n",
    "    w.publication_year AS citing_year,\n",
    "    EXPLODE(COALESCE(w.referenced_works, ARRAY())) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works') AS w\n",
    "  WHERE w.referenced_works_count > 0\n",
    "    AND w.publication_year IS NOT NULL\n",
    "    AND w.publication_year <= YEAR(CURRENT_DATE())\n",
    "),\n",
    "\n",
    "-- Per-work pub+3 citations via edges (join + conditional sum)\n",
    "three_years AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    b.subfield_id,\n",
    "    b.pub_year,\n",
    "    b.work_type,\n",
    "    SUM(\n",
    "      CASE\n",
    "        WHEN e.citing_year BETWEEN b.pub_year AND LEAST(b.pub_year + 3, YEAR(CURRENT_DATE()))\n",
    "        THEN 1 ELSE 0\n",
    "      END\n",
    "    ) AS pub_plus_3_citations\n",
    "  FROM base b\n",
    "  LEFT JOIN edges e\n",
    "    ON e.cited_work_id = b.work_id\n",
    "  WHERE b.work_type IS NOT NULL\n",
    "  GROUP BY b.work_id, b.subfield_id, b.pub_year, b.work_type\n",
    "),\n",
    "\n",
    "-- Join monthly cohort means to compute FWCI and carry p90/p99 thresholds\n",
    "with_fwci AS (\n",
    "  SELECT\n",
    "    t.work_id,\n",
    "    t.subfield_id,\n",
    "    t.pub_year,\n",
    "    t.work_type,\n",
    "    t.pub_plus_3_citations,\n",
    "    CASE\n",
    "      WHEN d.mean_citations IS NULL OR d.mean_citations <= 0 THEN NULL\n",
    "      ELSE t.pub_plus_3_citations / d.mean_citations\n",
    "    END AS fwci,\n",
    "    d.p90_threshold,\n",
    "    d.p99_threshold\n",
    "  FROM three_years t\n",
    "  LEFT JOIN openalex.common.citations_mean_pub_year_type d\n",
    "    ON d.publication_year = t.pub_year\n",
    "   AND d.subfield_id      = t.subfield_id\n",
    "   AND d.work_type        = t.work_type\n",
    "),\n",
    "\n",
    "-- Cohort percentile for pub+3 within (pub_year, subfield_id, work_type) + top-1/10 flags\n",
    "with_percentile AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    subfield_id,\n",
    "    pub_year,\n",
    "    work_type,\n",
    "    pub_plus_3_citations,\n",
    "    ROUND(fwci, 8) AS fwci,\n",
    "    ROUND(\n",
    "      PERCENT_RANK() OVER (\n",
    "        PARTITION BY pub_year, subfield_id, work_type\n",
    "        ORDER BY pub_plus_3_citations, work_id\n",
    "      ), 8\n",
    "    ) AS citation_pct_cohort,\n",
    "    (p99_threshold IS NOT NULL AND pub_plus_3_citations >= p99_threshold) AS is_in_top_1_percent,\n",
    "    (p90_threshold IS NOT NULL AND pub_plus_3_citations >= p90_threshold) AS is_in_top_10_percent\n",
    "  FROM with_fwci\n",
    "),\n",
    "\n",
    "/* ===== cited_by_percentile_year (global by eval_year), computed from edges ===== */\n",
    "/* ===== cited_by_percentile_year (global, min/max across years)\n",
    "   Build a proper year-level distribution that includes zeros and preserves frequencies ===== */\n",
    "\n",
    "/* All candidate works and their pub_year (global, not filtered by work_type/subfield) */\n",
    "-- All works with their pub_year\n",
    "all_works AS (\n",
    "  SELECT id AS work_id,\n",
    "         coalesce(publication_year, year(publication_date)) AS pub_year\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE coalesce(publication_year, year(publication_date)) IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Years universe\n",
    "years AS (\n",
    "  SELECT explode(sequence(1920, year(current_date()))) AS year\n",
    "),\n",
    "\n",
    "-- Total alive works per year (eligible to receive citations)\n",
    "alive_per_year AS (\n",
    "  SELECT y.year,\n",
    "         count(*) AS alive_works\n",
    "  FROM years y\n",
    "  JOIN all_works w\n",
    "    ON y.year >= w.pub_year\n",
    "  GROUP BY y.year\n",
    "),\n",
    "\n",
    "-- Non-zero citation buckets from counts_by_year (use existing precomputed counts)\n",
    "nonzero_year_freq AS (\n",
    "  SELECT\n",
    "    cy.year,\n",
    "    cy.cited_by_count AS citation_count,\n",
    "    count(*) AS freq\n",
    "  FROM (\n",
    "    SELECT\n",
    "      explode(coalesce(w.counts_by_year, array())) AS cy\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "  )\n",
    "  WHERE cy.year BETWEEN 1920 AND year(current_date())\n",
    "    AND cy.cited_by_count > 0\n",
    "  GROUP BY cy.year, cy.cited_by_count\n",
    "),\n",
    "\n",
    "-- Sum of non-zero frequencies per year\n",
    "nonzero_sum AS (\n",
    "  SELECT year, sum(freq) AS nonzero_total\n",
    "  FROM nonzero_year_freq\n",
    "  GROUP BY year\n",
    "),\n",
    "\n",
    "-- Zero bucket derived as alive - nonzero_total\n",
    "zero_bucket AS (\n",
    "  SELECT a.year,\n",
    "         0 AS citation_count,\n",
    "         greatest(a.alive_works - coalesce(n.nonzero_total, 0), 0) AS freq\n",
    "  FROM alive_per_year a\n",
    "  LEFT JOIN nonzero_sum n USING (year)\n",
    "),\n",
    "\n",
    "-- Full frequency table including zero bucket\n",
    "year_count_freq AS (\n",
    "  SELECT * FROM nonzero_year_freq\n",
    "  UNION ALL\n",
    "  SELECT * FROM zero_bucket\n",
    "),\n",
    "\n",
    "-- Cumulative distribution per year\n",
    "year_count_cume AS (\n",
    "  SELECT\n",
    "    year,\n",
    "    citation_count,\n",
    "    freq,\n",
    "    sum(freq) OVER (PARTITION BY year) AS total_freq,\n",
    "    sum(freq) OVER (PARTITION BY year ORDER BY citation_count\n",
    "                    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_freq_inclusive\n",
    "  FROM year_count_freq\n",
    "),\n",
    "\n",
    "-- Bounds for each (year, count)\n",
    "year_count_bounds AS (\n",
    "  SELECT\n",
    "    year,\n",
    "    citation_count,\n",
    "    case when total_freq <= 1 then 0.0\n",
    "         else (cum_freq_inclusive - freq) / total_freq end AS lower_pct,\n",
    "    case when total_freq = 0 then 0.0\n",
    "         else cum_freq_inclusive / total_freq end AS upper_pct\n",
    "  FROM year_count_cume\n",
    "),\n",
    "\n",
    "-- Map each workâ€™s counts_by_year to bounds\n",
    "work_year_bands AS (\n",
    "  SELECT\n",
    "    w.id AS work_id,\n",
    "    cy.year,\n",
    "    b.lower_pct,\n",
    "    b.upper_pct\n",
    "  FROM (\n",
    "    SELECT\n",
    "      w.id,\n",
    "      explode(coalesce(w.counts_by_year, array())) AS cy\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "  ) w\n",
    "  JOIN year_count_bounds b\n",
    "    ON b.year = cy.year AND b.citation_count = cy.cited_by_count\n",
    "),\n",
    "\n",
    "-- Collapse to min/max across years per work\n",
    "year_pct_minmax AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    min(lower_pct) AS lower_pct_min,\n",
    "    max(upper_pct) AS upper_pct_max\n",
    "  FROM work_year_bands\n",
    "  GROUP BY work_id\n",
    "),\n",
    "\n",
    "formatted_year_pct AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    named_struct(\n",
    "      'min',\n",
    "        case\n",
    "          when round(coalesce(lower_pct_min,0)*100)=100 then 99\n",
    "          when round(coalesce(lower_pct_min,0)*100)=round(coalesce(upper_pct_max,0)*100)\n",
    "            then greatest(cast(round(coalesce(lower_pct_min,0)*100) as int)-1, 0)\n",
    "          else cast(round(coalesce(lower_pct_min,0)*100) as int)\n",
    "        end,\n",
    "      'max',\n",
    "        case\n",
    "          when round(coalesce(upper_pct_max,0)*100)=100 then 100\n",
    "          else cast(round(coalesce(upper_pct_max,0)*100) as int)\n",
    "        end\n",
    "    ) AS cited_by_percentile_year\n",
    "  FROM year_pct_minmax\n",
    "),\n",
    "\n",
    "updates AS (\n",
    "  SELECT\n",
    "    p.work_id,\n",
    "    p.fwci,\n",
    "    NAMED_STRUCT(\n",
    "      'value', p.citation_pct_cohort,\n",
    "      'is_in_top_1_percent', p.is_in_top_1_percent,\n",
    "      'is_in_top_10_percent', p.is_in_top_10_percent\n",
    "    ) AS citation_normalized_percentile,\n",
    "    y.cited_by_percentile_year\n",
    "  FROM with_percentile p\n",
    "  LEFT JOIN formatted_year_pct y\n",
    "    ON y.work_id = p.work_id\n",
    ")\n",
    "-- Preview:\n",
    "-- SELECT * FROM updates;\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING updates AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED\n",
    "THEN UPDATE SET\n",
    "  target.fwci = COALESCE(source.fwci, target.fwci),\n",
    "  target.citation_normalized_percentile =\n",
    "    COALESCE(source.citation_normalized_percentile, target.citation_normalized_percentile),\n",
    "  target.cited_by_percentile_year =\n",
    "    COALESCE(source.cited_by_percentile_year, target.cited_by_percentile_year);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbf6595-e492-47b2-9612-48d1dc64f655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `sustainable_development_goals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd32c2fe-7c99-45b2-863e-0ad44bb215dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### `work_sdg_backfill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2a139e-f3f3-42d0-a305-85b523b7ecfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from SDG backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    paper_id,\n",
    "    sustainable_development_goals\n",
    "  FROM openalex.works.work_sdg_backfill\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON target.id = source.paper_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.sustainable_development_goals = source.sustainable_development_goals;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b70bca61-286b-431a-ac32-ee785a38e53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### `openalex.works.works_sdg_frontfill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bdf06d-ec10-46a8-968e-bbe75a8e3bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- MERGE from SDG backfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    FIRST(sdg) as sustainable_development_goals\n",
    "  FROM openalex.works.works_sdg_frontfill\n",
    "  GROUP BY work_id\n",
    ") AS source\n",
    "-- don't force update if topics are populated already\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND id > 6600000000 THEN UPDATE\n",
    "  SET target.sustainable_development_goals = source.sustainable_development_goals;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c269057d-8277-4bc4-b4d3-b23a5576588c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `awards`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3646b5c3-e567-4a9a-a569-a80ddbb9f855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT work_id, collect_set(award) as awards\n",
    "  FROM openalex.awards.work_awards\n",
    "  WHERE work_id IS NOT NULL\n",
    "  GROUP BY work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE\n",
    "  SET target.awards = source.awards;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8babb83-6f0f-43bc-a6c3-7e6447a05a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `funders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e744f175-0132-495a-89e4-afcd0cdbf58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Build rolled funders from funders backfill + FULLTEXT\n",
    "WITH from_backfill AS (\n",
    "  SELECT\n",
    "    paper_id AS work_id,\n",
    "    funder_id\n",
    "  FROM openalex.mid.work_funder\n",
    "),\n",
    "from_backfill_enriched AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    CONCAT(\"https://openalex.org/F\", b.funder_id) as funder_id,\n",
    "    mf.ror_id AS ror,\n",
    "    mf.display_name AS display_name\n",
    "  FROM from_backfill b\n",
    "  LEFT JOIN openalex.mid.funder mf\n",
    "    ON mf.funder_id = b.funder_id\n",
    "),\n",
    "from_fulltext_enriched AS (\n",
    "  SELECT\n",
    "    ft.work_id,\n",
    "    ft.funder_id,\n",
    "    ft.ror_id AS ror,\n",
    "    ft.funder_display_name AS display_name\n",
    "  FROM openalex.works.fulltext_work_funders ft\n",
    "  JOIN openalex.common.funder_names_keep keep ON keep.name = ft.funder_name\n",
    "),\n",
    "from_gtr AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    funder.id as funder_id,\n",
    "    funder.ror_id as ror,\n",
    "    funder.display_name as display_name\n",
    "  FROM openalex.awards.gtr_awards\n",
    "  WHERE work_id IS NOT NULL\n",
    "),\n",
    "unioned AS (\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_backfill_enriched\n",
    "  UNION ALL  \n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_fulltext_enriched\n",
    "  UNION ALL\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_gtr\n",
    "),\n",
    "dedup AS (\n",
    "  -- one row per (work_id, funder_id), pick deterministic values\n",
    "  SELECT\n",
    "    work_id,\n",
    "    funder_id,\n",
    "    MAX(display_name) AS display_name,\n",
    "    MAX(ror) AS ror\n",
    "  FROM unioned\n",
    "  GROUP BY work_id, funder_id\n",
    "),\n",
    "rolled_up AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    -- order by funder_id via lexicographic struct ordering (id is first field)\n",
    "    sort_array(\n",
    "      collect_list(\n",
    "        struct(\n",
    "          funder_id as id,\n",
    "          display_name,\n",
    "          ror\n",
    "        )\n",
    "      )\n",
    "    ) AS funders\n",
    "  FROM dedup\n",
    "  GROUP BY work_id\n",
    ")\n",
    "-- 2) Merge into openalex_works.funders (array<struct<id:string, ror:string, display_name:string>>)\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING rolled_up AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET target.funders = source.funders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01af4136-9ab3-4150-b55f-14e5d9c77f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `authorships`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c123a5-6322-45f6-9b1b-3a91339a78f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Frontfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b12d9d-3f5a-4618-b26a-f1acc90516be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING identifier('openalex' || :env_suffix || '.works.authors_and_affiliations') AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.authorships = source.authorships;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3548b792-ad94-41a0-97b4-883b1b15922f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294312bf-f88c-4464-8390-552ab98c9720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works')  AS target\n",
    "USING (\n",
    "  SELECT paper_id as work_id,\n",
    "    authorships,\n",
    "    corresponding_author_ids,\n",
    "    corresponding_institution_ids\n",
    "  FROM openalex.authors.work_authorships_backfill_moderated\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.authorships IS NOT NULL and size(source.authorships) > 0 THEN UPDATE\n",
    "  SET\n",
    "    target.authorships = source.authorships,\n",
    "    target.authors_count = COALESCE(size(source.authorships), 0),\n",
    "    target.corresponding_author_ids = source.corresponding_author_ids,\n",
    "    target.corresponding_institution_ids = source.corresponding_institution_ids;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9933f224-c204-4f27-9f3c-db7abcd5d1c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `institutions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2cc1c2-623d-47ed-9164-80f195f58a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "UPDATE identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  SET institutions_distinct_count = COALESCE(SIZE(authorships.institutions), 0),\n",
    "      countries_distinct_count = COALESCE(SIZE(\n",
    "        ARRAY_DISTINCT(ARRAY_COMPACT(FLATTEN((authorships.institutions.country_code))))), 0)\n",
    "WHERE authorships IS NOT NULL\n",
    "  AND size(authorships) > 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9522f03a-d2d4-4a64-a315-850dc7204a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `work.type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c92f069-2c0b-4ed6-82b6-db094fc20e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  WITH approved_curations AS (\n",
    "    SELECT\n",
    "      CAST(SUBSTRING(entity_id, 2) AS BIGINT) AS work_id,\n",
    "      MAP_FROM_ENTRIES(COLLECT_LIST(STRUCT(property, property_value))) AS curations\n",
    "    FROM\n",
    "      openalex.curations.approved_curations\n",
    "    WHERE\n",
    "      entity = 'works'\n",
    "      AND property IN ('type', 'language')\n",
    "      AND status = 'approved'\n",
    "    GROUP BY CAST(SUBSTRING(entity_id, 2) AS BIGINT)\n",
    "  )\n",
    "  SELECT \n",
    "    w.paper_id as work_id,\n",
    "    w.type,\n",
    "    w.type_crossref,\n",
    "    ac.work_id IS NOT NULL as has_curation\n",
    "  FROM openalex.mid.work w\n",
    "  LEFT JOIN approved_curations ac ON w.paper_id = ac.work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED \n",
    "  AND target.type <> source.type\n",
    "  AND source.type IS NOT NULL\n",
    "  AND source.has_curation = FALSE\n",
    "THEN UPDATE SET\n",
    "  target.type = COALESCE(source.type, target.type),\n",
    "  target.type_crossref = source.type_crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfdc6724-f0ac-488b-a838-55fbecb097fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `related_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a893b4d-c53d-41ac-851d-1dad836488bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  SELECT \n",
    "    work_id, related_works\n",
    "  FROM openalex.works.related_works_backfill\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.related_works IS NOT NULL AND SIZE(source.related_works) > 0\n",
    "THEN UPDATE SET\n",
    "  target.related_works = source.related_works"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateWorksEnriched",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "a32b9271-2b7f-475b-8140-bb4789e5a680",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
