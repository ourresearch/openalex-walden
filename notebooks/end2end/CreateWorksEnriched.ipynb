{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Create Works Enriched\n\n## Overview\n\nThis notebook creates the final `openalex_works` table by enriching `openalex_works_base` with additional data from various sources. It starts by deep cloning the base table, then merges in enrichments.\n\n## Data Flow\n\n```\nopenalex_works_base (from CreateWorksBase)\n    |\n    v [DEEP CLONE]\nopenalex_works\n    |\n    v [MERGE operations]\nopenalex_works (enriched)\n```\n\n## Enrichment Sources\n\n### Referenced Works (two sources)\n1. **Legacy backfill:** `openalex.mid.citation` - historical citation data from MAG\n2. **Parsed references:** `openalex.works.referenced_works` - resolved from raw references by `parse_work_references.ipynb`\n\nBoth are merged using `array_union` to combine without duplicates.\n\n### Citations\n- `cited_by_count` and `counts_by_year` - computed from `referenced_works` edges\n- `fwci` and `citation_normalized_percentile` - computed from pub+3 citations within cohort\n\n### Content\n- **Fulltext:** from `openalex.pdf.pdf_combined` matched by DOI or PMH ID\n- **Concepts/Keywords:** backfill + predicted (using `concept_key` hash)\n- **Topics:** backfill (id < 6.6B) + frontfill (id > 6.6B)\n- **SDG:** backfill + frontfill\n\n### Metadata\n- **Awards:** from `openalex.awards.work_awards`\n- **Funders:** combined from backfill, fulltext extraction, and GTR\n- **Authorships:** enriched with institution matching from `work_authorships`\n- **Related works:** from `related_works_backfill`\n- **Work type:** from `openalex.mid.work` (with curation overrides)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0c1149f-4741-4f09-b8df-c333d3c6a54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create and enrich `openalex.works.openalex_works`"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "-- Hash-based updated_date: Capture previous state before DEEP CLONE\n",
    "-- Checkpoint: Excludes authorships, ids, cited_by_count (not yet deterministic)\n",
    "-- See: https://github.com/ourresearch/oax-jobs/tree/main/active/hash-based-updated-date\n",
    "\n",
    "CREATE OR REPLACE TABLE openalex.works.openalex_works_hash AS\n",
    "SELECT\n",
    "  id,\n",
    "  updated_date,\n",
    "  xxhash64(CONCAT_WS('|',\n",
    "    CAST(id AS STRING),\n",
    "    COALESCE(doi, ''),\n",
    "    COALESCE(title, ''),\n",
    "    COALESCE(CAST(publication_date AS STRING), ''),\n",
    "    COALESCE(CAST(publication_year AS STRING), ''),\n",
    "    COALESCE(type, ''),\n",
    "    COALESCE(language, ''),\n",
    "    COALESCE(abstract, ''),\n",
    "    COALESCE(TO_JSON(referenced_works), '[]'),\n",
    "    COALESCE(TO_JSON(topics), '[]'),\n",
    "    COALESCE(TO_JSON(concepts), '[]'),\n",
    "    COALESCE(TO_JSON(keywords), '[]'),\n",
    "    COALESCE(TO_JSON(funders), '[]'),\n",
    "    COALESCE(TO_JSON(locations), '[]'),\n",
    "    COALESCE(TO_JSON(awards), '[]'),\n",
    "    COALESCE(TO_JSON(open_access), '{}'),\n",
    "    COALESCE(CAST(is_retracted AS STRING), 'false')\n",
    "  )) AS content_hash\n",
    "FROM openalex.works.openalex_works;"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8aeae97-55b1-4aad-b5ed-114c15f0f9d1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765986655708}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE openalex.works.openalex_works \nDEEP CLONE openalex.works.openalex_works_base  -- unable to use env_suffix with deep clone, set manually\nTBLPROPERTIES (\n  'delta.dataSkippingNumIndexedCols' = 36,\n  'delta.deletedFileRetentionDuration' = '30 days',\n  'delta.logRetentionDuration' = '30 days'\n);"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd34f75-6351-4ab0-b52a-c16149b44069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge citations and referenced_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd4e4e3e-96b1-433f-953c-c5d2f5c31f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "-- MERGE Backfill referenced_works (mid.citation) - 95,305,004 works updated\nWITH prod_ref_works AS (\n  SELECT \n    paper_id as id,\n    ARRAY_SORT(collect_set(paper_reference_id)) as referenced_works\n  FROM openalex.mid.citation\n  GROUP BY paper_id\n)\nMERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\nUSING prod_ref_works as source\nON target.id = source.id\nWHEN MATCHED THEN UPDATE SET\n  referenced_works = ARRAY_SORT(array_union(target.referenced_works, source.referenced_works)),\n  referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc98aad-f096-44b2-a340-99a59a21df19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%sql\n-- use newly refreshed parsed data (overlap with mid.citation backfill above, add more if exists) -- 102,749,754\nMERGE INTO openalex.works.openalex_works AS target\nUSING openalex.works.referenced_works AS source\nON target.id = source.citing_work_id\nWHEN MATCHED -- AND (target.referenced_works is null OR size(target.referenced_works) = 0) -- either don't overwrite or union\nTHEN UPDATE SET\n  target.referenced_works = ARRAY_SORT(array_union(target.referenced_works, source.referenced_works)),\n  target.referenced_works_count = size(array_union(target.referenced_works, source.referenced_works));"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "269f8620-ab83-416d-bf69-d3eb1401ce8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Merge cited_by_count and counts_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956bead7-87d8-4966-b14e-b422329749bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Calculate and MERGE the citations\n",
    "-- Far fewer changes than propagating through locations_mapped and 17 CTEs, no need to select distinct work_id data\n",
    "-- runtime about 1 min, updates 67M rows\n",
    "WITH exploded_references AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    publication_year,\n",
    "    EXPLODE(referenced_works) AS cited_work_id\n",
    "  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  WHERE referenced_works_count > 0\n",
    "    AND publication_year <= YEAR(CURRENT_DATE())\n",
    "    AND type != 'dataset'\n",
    "),\n",
    "citation_counts AS (\n",
    "  SELECT\n",
    "    cited_work_id,\n",
    "    publication_year,\n",
    "    COUNT(*) AS cited_by_count\n",
    "  FROM exploded_references\n",
    "  GROUP BY cited_work_id, publication_year\n",
    "),\n",
    "citation_counts_by_work AS (\n",
    "  SELECT \n",
    "    cited_work_id,\n",
    "    FILTER(\n",
    "      SORT_ARRAY(\n",
    "        COLLECT_LIST(\n",
    "          NAMED_STRUCT(\n",
    "            'year', publication_year,\n",
    "            'cited_by_count', cited_by_count\n",
    "          )\n",
    "        ),\n",
    "        false\n",
    "      ),\n",
    "      x -> x.year >= 2012\n",
    "    ) AS counts_by_year,\n",
    "    SUM(cited_by_count) AS cited_by_count -- total across all years\n",
    "  FROM citation_counts\n",
    "  GROUP BY cited_work_id\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING citation_counts_by_work AS source\n",
    "ON target.id = source.cited_work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.cited_by_count = source.cited_by_count,\n",
    "  target.counts_by_year = source.counts_by_year;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b98cb5d-5d25-446b-a200-41a67a2c9995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge full-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9a12ef-50c6-41f1-8420-e2fd0b70424c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-------- Merge fulltext from PDFs --------\n",
    "WITH pdf_fulltext_for_merge AS (\n",
    "    -- DOI-based matching\n",
    "    SELECT \n",
    "        CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) AS doi_normalized,\n",
    "        NULL AS pmh_id,\n",
    "        fulltext,\n",
    "        'doi' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CONCAT('https://doi.org/', LOWER(FILTER(ids, x -> x.namespace = 'doi')[0].id)) ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'doi')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID-based matching\n",
    "    SELECT \n",
    "        NULL AS doi_normalized,\n",
    "        FILTER(ids, x -> x.namespace = 'pmh')[0].id AS pmh_id,\n",
    "        fulltext,\n",
    "        'pmh' AS match_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY FILTER(ids, x -> x.namespace = 'pmh')[0].id ORDER BY LENGTH(fulltext) DESC) AS rn\n",
    "    FROM openalex.pdf.pdf_combined\n",
    "    WHERE SIZE(FILTER(ids, x -> x.namespace = 'pmh')) > 0\n",
    "      AND fulltext IS NOT NULL\n",
    "      AND TRIM(fulltext) != ''\n",
    "      -- Only include PMH records that don't have DOIs (to avoid duplicates)\n",
    "      AND SIZE(FILTER(ids, x -> x.namespace = 'doi')) = 0\n",
    "),\n",
    "pdf_fulltext_deduped AS (\n",
    "    SELECT doi_normalized, pmh_id, fulltext, match_type\n",
    "    FROM pdf_fulltext_for_merge\n",
    "    WHERE rn = 1\n",
    "),\n",
    "works_with_locations AS (\n",
    "    SELECT \n",
    "        w.id,\n",
    "        w.doi,\n",
    "        EXPLODE_OUTER(w.locations) AS location\n",
    "    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n",
    "),\n",
    "matched_fulltext AS (\n",
    "    -- DOI matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM (SELECT DISTINCT id, doi FROM works_with_locations) w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON LOWER(w.doi) = p.doi_normalized\n",
    "    WHERE p.doi_normalized IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- PMH ID matches\n",
    "    SELECT \n",
    "        w.id AS work_id,\n",
    "        p.fulltext,\n",
    "        p.match_type\n",
    "    FROM works_with_locations w\n",
    "    INNER JOIN pdf_fulltext_deduped p \n",
    "        ON w.location.pmh_id = p.pmh_id\n",
    "    WHERE p.pmh_id IS NOT NULL\n",
    "      AND w.location.pmh_id IS NOT NULL\n",
    "),\n",
    "final_fulltext AS (\n",
    "    -- Deduplicate in case a work matches on both DOI and PMH\n",
    "    -- Prefer DOI matches over PMH matches\n",
    "    SELECT \n",
    "        work_id,\n",
    "        fulltext,\n",
    "        ROW_NUMBER() OVER (PARTITION BY work_id ORDER BY CASE WHEN match_type = 'doi' THEN 1 ELSE 2 END) AS priority_rn\n",
    "    FROM matched_fulltext\n",
    "),\n",
    "cleaned_fulltext AS (\n",
    "    SELECT \n",
    "        work_id,\n",
    "        TRIM(\n",
    "            REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                    REGEXP_REPLACE(\n",
    "                        SUBSTRING(fulltext, 1, 200000),\n",
    "                        '<[^>]+>',  -- Remove HTML tags\n",
    "                        ' '\n",
    "                    ),\n",
    "                    '\\\\s+',         -- Replace multiple whitespace with single space\n",
    "                    ' '\n",
    "                ),\n",
    "                '(^\\\\s+|\\\\s+$)',    -- Additional trim for safety\n",
    "                ''\n",
    "            )\n",
    "        ) AS cleaned_fulltext\n",
    "    FROM final_fulltext \n",
    "    WHERE priority_rn = 1\n",
    ")\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        work_id, \n",
    "        cleaned_fulltext AS fulltext\n",
    "    FROM cleaned_fulltext\n",
    "    WHERE cleaned_fulltext IS NOT NULL \n",
    "      AND LENGTH(cleaned_fulltext) > 0\n",
    ") AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET\n",
    "  target.fulltext = source.fulltext;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c438dd8-62f4-48f2-843d-2ed5fe4c297d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a47ce009-7525-436f-97f9-e528c5ca914e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4cc4afd-bb7a-4f80-bcc2-8cd568dacffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "---------- MERGE aggregated and sorted by score Concepts from backfill --------\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING openalex.works.work_concepts_backfill AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "  target.concepts = source.concepts,\n",
    "  target.keywords = filter(source.keywords, k -> k.score > 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7ced136-ec40-4a5f-84f0-5eb401e80200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6aad29-e0ad-44a5-b75c-e026a96f5c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---------- MERGE from predicted Concepts using concept_key --------\n",
    "-- ============= Tunable parameters =============\n",
    "DECLARE OR REPLACE VARIABLE filter_threshold FLOAT DEFAULT 0.20;  -- score cutoff for filtering\n",
    "DECLARE OR REPLACE VARIABLE base_mid         FLOAT DEFAULT 5.0;   -- target median size (bell center)\n",
    "DECLARE OR REPLACE VARIABLE half_range       FLOAT DEFAULT 6.0;   -- maximum deviation from median (-+ range)\n",
    "DECLARE OR REPLACE VARIABLE center_size      INT   DEFAULT 7;     -- where the tanh crosses 0 (inflection point)\n",
    "DECLARE OR REPLACE VARIABLE slope            FLOAT DEFAULT 0.05;  -- steepness of the tanh curve\n",
    "\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  SELECT concept_key,\n",
    "         FIRST(concepts_enriched) AS concepts,\n",
    "         FIRST(keywords) as keywords\n",
    "  FROM openalex.works.openalex_works_concepts_predicted\n",
    "  WHERE size(concepts_enriched) > 0 OR size(keywords) > 0\n",
    "  GROUP BY concept_key\n",
    ") as source\n",
    "ON -- (target.concepts IS NULL OR size(target.concepts) = 0) AND \n",
    "   xxhash64(\n",
    "     concat_ws('|',\n",
    "       target.title,\n",
    "       target.abstract,\n",
    "       target.primary_location.source.display_name,\n",
    "       target.primary_location.source.type\n",
    "     )\n",
    "   ) = source.concept_key\n",
    "WHEN MATCHED AND id > 6600000000 THEN\n",
    "  UPDATE SET\n",
    "    target.concepts = slice(source.concepts, 1, 40), -- too many concepts from the model - up to 130\n",
    "    target.keywords = slice(\n",
    "      filter(source.keywords, k -> k.score > 0), 1,\n",
    "      greatest(2, least(12, round(base_mid + \n",
    "          half_range * tanh((\n",
    "            size(filter(source.keywords, \n",
    "              k -> k.score > filter_threshold)) - center_size) * slope)))\n",
    "      )\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff904bd-c78d-45e3-b0a7-3035442f3cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72bfc45-46c4-41ec-ad5d-bebc80d2a12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Combined MERGE for Topics (backfill + frontfill)\n",
    "-- Backfill and frontfill are mutually exclusive (backfill: id < 6600000000, frontfill: id > 6600000000)\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  -- Backfill: old works only\n",
    "  SELECT work_id, topics\n",
    "  FROM openalex.works.work_topics_backfill\n",
    "  WHERE work_id < 6600000000\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  -- Frontfill: new works only\n",
    "  SELECT work_id, FIRST(topics) as topics\n",
    "  FROM openalex.works.work_topics_frontfill\n",
    "  WHERE work_id > 6600000000\n",
    "  GROUP BY work_id\n",
    ") AS source\n",
    "ON target.id = source.work_id\n",
    "   AND (target.topics IS NULL OR SIZE(target.topics) = 0)\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.topics = source.topics,\n",
    "  target.primary_topic = source.topics[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724a1f41-81a3-4c95-bf0e-1b2f9aba7495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "-- FWCI + cohort percentile (pub+3 within pub_year/subfield_id/work_type) -- 257,176,397 updated\n-- + cited_by_percentile_year (global by eval_year)\n-- Computes everything from citation edges (referenced_works); no counts_by_year usage.\n\nWITH base AS (  -- candidate works + work_type mapping\n  SELECT\n    id AS work_id,\n    CASE\n      WHEN type = 'article'\n           AND primary_location.source.type = 'conference' THEN 'conference_article'\n      WHEN type IN ('article', 'book', 'review', 'book-chapter') THEN type\n      ELSE NULL\n    END AS work_type,\n    COALESCE(publication_year, YEAR(publication_date)) AS pub_year,\n    primary_topic.subfield.id AS subfield_id\n  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n  WHERE primary_topic.subfield.id IS NOT NULL\n    AND COALESCE(publication_year, YEAR(publication_date)) IS NOT NULL\n),\n\n-- All citation edges: (citing_year -> cited_work_id)\nedges AS (\n  SELECT\n    w.publication_year AS citing_year,\n    EXPLODE(COALESCE(w.referenced_works, ARRAY())) AS cited_work_id\n  FROM identifier('openalex' || :env_suffix || '.works.openalex_works') AS w\n  WHERE w.referenced_works_count > 0\n    AND w.publication_year IS NOT NULL\n    AND w.publication_year <= YEAR(CURRENT_DATE())\n),\n\n-- Per-work pub+3 citations via edges (join + conditional sum)\nthree_years AS (\n  SELECT\n    b.work_id,\n    b.subfield_id,\n    b.pub_year,\n    b.work_type,\n    SUM(\n      CASE\n        WHEN e.citing_year BETWEEN b.pub_year AND LEAST(b.pub_year + 3, YEAR(CURRENT_DATE()))\n        THEN 1 ELSE 0\n      END\n    ) AS pub_plus_3_citations\n  FROM base b\n  LEFT JOIN edges e\n    ON e.cited_work_id = b.work_id\n  WHERE b.work_type IS NOT NULL\n  GROUP BY b.work_id, b.subfield_id, b.pub_year, b.work_type\n),\n\n-- Join monthly cohort means to compute FWCI\nwith_fwci AS (\n  SELECT\n    t.work_id,\n    t.subfield_id,\n    t.pub_year,\n    t.work_type,\n    t.pub_plus_3_citations,\n    CASE\n      WHEN d.mean_citations IS NULL OR d.mean_citations <= 0 THEN NULL\n      ELSE t.pub_plus_3_citations / d.mean_citations\n    END AS fwci\n  FROM three_years t\n  LEFT JOIN openalex.common.citations_mean_pub_year_type d\n    ON d.publication_year = t.pub_year\n   AND d.subfield_id      = t.subfield_id\n   AND d.work_type        = t.work_type\n),\n\n-- Cohort percentile for pub+3 within (pub_year, subfield_id, work_type) + top-1/10 flags\n-- Note: is_in_top_1_percent and is_in_top_10_percent are derived directly from citation_pct_cohort\n-- to ensure they always match the displayed percentile value (fixes inconsistency bug)\nwith_percentile AS (\n  SELECT\n    work_id,\n    subfield_id,\n    pub_year,\n    work_type,\n    pub_plus_3_citations,\n    ROUND(fwci, 8) AS fwci,\n    ROUND(\n      PERCENT_RANK() OVER (\n        PARTITION BY pub_year, subfield_id, work_type\n        ORDER BY pub_plus_3_citations, work_id\n      ), 8\n    ) AS citation_pct_cohort,\n    (PERCENT_RANK() OVER (\n      PARTITION BY pub_year, subfield_id, work_type\n      ORDER BY pub_plus_3_citations, work_id\n    ) >= 0.99) AS is_in_top_1_percent,\n    (PERCENT_RANK() OVER (\n      PARTITION BY pub_year, subfield_id, work_type\n      ORDER BY pub_plus_3_citations, work_id\n    ) >= 0.90) AS is_in_top_10_percent\n  FROM with_fwci\n),\n\n/* ===== cited_by_percentile_year (global by eval_year), computed from edges ===== */\n/* ===== cited_by_percentile_year (global, min/max across years)\n   Build a proper year-level distribution that includes zeros and preserves frequencies ===== */\n\n/* All candidate works and their pub_year (global, not filtered by work_type/subfield) */\n-- All works with their pub_year\nall_works AS (\n  SELECT id AS work_id,\n         coalesce(publication_year, year(publication_date)) AS pub_year\n  FROM identifier('openalex' || :env_suffix || '.works.openalex_works')\n  WHERE coalesce(publication_year, year(publication_date)) IS NOT NULL\n),\n\n-- Years universe\nyears AS (\n  SELECT explode(sequence(1920, year(current_date()))) AS year\n),\n\n-- Total alive works per year (eligible to receive citations)\nalive_per_year AS (\n  SELECT y.year,\n         count(*) AS alive_works\n  FROM years y\n  JOIN all_works w\n    ON y.year >= w.pub_year\n  GROUP BY y.year\n),\n\n-- Non-zero citation buckets from counts_by_year (use existing precomputed counts)\nnonzero_year_freq AS (\n  SELECT\n    cy.year,\n    cy.cited_by_count AS citation_count,\n    count(*) AS freq\n  FROM (\n    SELECT\n      explode(coalesce(w.counts_by_year, array())) AS cy\n    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n  )\n  WHERE cy.year BETWEEN 1920 AND year(current_date())\n    AND cy.cited_by_count > 0\n  GROUP BY cy.year, cy.cited_by_count\n),\n\n-- Sum of non-zero frequencies per year\nnonzero_sum AS (\n  SELECT year, sum(freq) AS nonzero_total\n  FROM nonzero_year_freq\n  GROUP BY year\n),\n\n-- Zero bucket derived as alive - nonzero_total\nzero_bucket AS (\n  SELECT a.year,\n         0 AS citation_count,\n         greatest(a.alive_works - coalesce(n.nonzero_total, 0), 0) AS freq\n  FROM alive_per_year a\n  LEFT JOIN nonzero_sum n USING (year)\n),\n\n-- Full frequency table including zero bucket\nyear_count_freq AS (\n  SELECT * FROM nonzero_year_freq\n  UNION ALL\n  SELECT * FROM zero_bucket\n),\n\n-- Cumulative distribution per year\nyear_count_cume AS (\n  SELECT\n    year,\n    citation_count,\n    freq,\n    sum(freq) OVER (PARTITION BY year) AS total_freq,\n    sum(freq) OVER (PARTITION BY year ORDER BY citation_count\n                    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cum_freq_inclusive\n  FROM year_count_freq\n),\n\n-- Bounds for each (year, count)\nyear_count_bounds AS (\n  SELECT\n    year,\n    citation_count,\n    case when total_freq <= 1 then 0.0\n         else (cum_freq_inclusive - freq) / total_freq end AS lower_pct,\n    case when total_freq = 0 then 0.0\n         else cum_freq_inclusive / total_freq end AS upper_pct\n  FROM year_count_cume\n),\n\n-- Map each work's counts_by_year to bounds\nwork_year_bands AS (\n  SELECT\n    w.id AS work_id,\n    cy.year,\n    b.lower_pct,\n    b.upper_pct\n  FROM (\n    SELECT\n      w.id,\n      explode(coalesce(w.counts_by_year, array())) AS cy\n    FROM identifier('openalex' || :env_suffix || '.works.openalex_works') w\n  ) w\n  JOIN year_count_bounds b\n    ON b.year = cy.year AND b.citation_count = cy.cited_by_count\n),\n\n-- Collapse to min/max across years per work\nyear_pct_minmax AS (\n  SELECT\n    work_id,\n    min(lower_pct) AS lower_pct_min,\n    max(upper_pct) AS upper_pct_max\n  FROM work_year_bands\n  GROUP BY work_id\n),\n\nformatted_year_pct AS (\n  SELECT\n    work_id,\n    named_struct(\n      'min',\n        case\n          when round(coalesce(lower_pct_min,0)*100)=100 then 99\n          when round(coalesce(lower_pct_min,0)*100)=round(coalesce(upper_pct_max,0)*100)\n            then greatest(cast(round(coalesce(lower_pct_min,0)*100) as int)-1, 0)\n          else cast(round(coalesce(lower_pct_min,0)*100) as int)\n        end,\n      'max',\n        case\n          when round(coalesce(upper_pct_max,0)*100)=100 then 100\n          else cast(round(coalesce(upper_pct_max,0)*100) as int)\n        end\n    ) AS cited_by_percentile_year\n  FROM year_pct_minmax\n),\n\nupdates AS (\n  SELECT\n    p.work_id,\n    p.fwci,\n    NAMED_STRUCT(\n      'value', p.citation_pct_cohort,\n      'is_in_top_1_percent', p.is_in_top_1_percent,\n      'is_in_top_10_percent', p.is_in_top_10_percent\n    ) AS citation_normalized_percentile,\n    y.cited_by_percentile_year\n  FROM with_percentile p\n  LEFT JOIN formatted_year_pct y\n    ON y.work_id = p.work_id\n)\n-- Preview:\n-- SELECT * FROM updates;\n\nMERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\nUSING updates AS source\n  ON target.id = source.work_id\nWHEN MATCHED\nTHEN UPDATE SET\n  target.fwci = COALESCE(source.fwci, target.fwci),\n  target.citation_normalized_percentile =\n    COALESCE(source.citation_normalized_percentile, target.citation_normalized_percentile),\n  target.cited_by_percentile_year =\n    COALESCE(source.cited_by_percentile_year, target.cited_by_percentile_year);"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afbf6595-e492-47b2-9612-48d1dc64f655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `sustainable_development_goals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c269057d-8277-4bc4-b4d3-b23a5576588c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Combined MERGE for SDG (backfill + frontfill)\n",
    "-- Verified: Backfill has 0 works with id > 6600000000, so no overlap with frontfill\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  -- Backfill: only contains old works (verified: 0 rows with id > 6600000000)\n",
    "  SELECT paper_id as work_id, sustainable_development_goals\n",
    "  FROM openalex.works.work_sdg_backfill\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  -- Frontfill: new works only\n",
    "  SELECT work_id, FIRST(sdg) as sustainable_development_goals\n",
    "  FROM openalex.works.works_sdg_frontfill\n",
    "  WHERE work_id > 6600000000\n",
    "  GROUP BY work_id\n",
    "  HAVING SIZE(FIRST(sdg)) > 0\n",
    ") AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.sustainable_development_goals = source.sustainable_development_goals;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8babb83-6f0f-43bc-a6c3-7e6447a05a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `awards`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f9f24e1-e8eb-4366-81ba-c2c65296d77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING (\n",
    "  SELECT work_id,\n",
    "    ARRAY_SORT(\n",
    "      collect_set(award),\n",
    "      (left, right) -> CASE\n",
    "        WHEN left.id < right.id THEN -1\n",
    "        WHEN left.id > right.id THEN 1\n",
    "        ELSE 0\n",
    "      END\n",
    "    ) as awards\n",
    "  FROM openalex.awards.work_awards\n",
    "  WHERE work_id IS NOT NULL\n",
    "  GROUP BY work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.awards = source.awards;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9f9ef87-33c8-4cf2-a0f1-c51e76fbdfd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `funders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e744f175-0132-495a-89e4-afcd0cdbf58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Build rolled funders from funders backfill + FULLTEXT\n",
    "WITH from_backfill AS (\n",
    "  SELECT\n",
    "    paper_id AS work_id,\n",
    "    funder_id\n",
    "  FROM openalex.mid.work_funder\n",
    "),\n",
    "from_backfill_enriched AS (\n",
    "  SELECT\n",
    "    b.work_id,\n",
    "    CONCAT(\"https://openalex.org/F\", b.funder_id) as funder_id,\n",
    "    mf.ror_id AS ror,\n",
    "    mf.display_name AS display_name\n",
    "  FROM from_backfill b\n",
    "  LEFT JOIN openalex.mid.funder mf\n",
    "    ON mf.funder_id = b.funder_id\n",
    "),\n",
    "from_fulltext_enriched AS (\n",
    "  SELECT\n",
    "    ft.work_id,\n",
    "    ft.funder_id,\n",
    "    ft.ror_id AS ror,\n",
    "    ft.funder_display_name AS display_name\n",
    "  FROM openalex.works.fulltext_work_funders ft\n",
    "  JOIN openalex.common.funder_names_keep keep ON keep.name = ft.funder_name\n",
    "),\n",
    "from_gtr AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    funder.id as funder_id,\n",
    "    funder.ror_id as ror,\n",
    "    funder.display_name as display_name\n",
    "  FROM openalex.awards.gtr_awards\n",
    "  WHERE work_id IS NOT NULL\n",
    "),\n",
    "unioned AS (\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_backfill_enriched\n",
    "  UNION ALL  \n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_fulltext_enriched\n",
    "  UNION ALL\n",
    "  SELECT work_id, funder_id, ror, display_name FROM from_gtr\n",
    "),\n",
    "dedup AS (\n",
    "  -- one row per (work_id, funder_id), pick deterministic values\n",
    "  SELECT\n",
    "    work_id,\n",
    "    funder_id,\n",
    "    MAX(display_name) AS display_name,\n",
    "    MAX(ror) AS ror\n",
    "  FROM unioned\n",
    "  GROUP BY work_id, funder_id\n",
    "),\n",
    "rolled_up AS (\n",
    "  SELECT\n",
    "    work_id,\n",
    "    -- order by funder_id via lexicographic struct ordering (id is first field)\n",
    "    sort_array(\n",
    "      collect_list(\n",
    "        struct(\n",
    "          funder_id as id,\n",
    "          display_name,\n",
    "          ror\n",
    "        )\n",
    "      )\n",
    "    ) AS funders\n",
    "  FROM dedup\n",
    "  GROUP BY work_id\n",
    ")\n",
    "-- 2) Merge into openalex_works.funders (array<struct<id:string, ror:string, display_name:string>>)\n",
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING rolled_up AS source\n",
    "  ON target.id = source.work_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET target.funders = source.funders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01af4136-9ab3-4150-b55f-14e5d9c77f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `authorships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b12d9d-3f5a-4618-b26a-f1acc90516be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') AS target\n",
    "USING identifier('openalex' || :env_suffix || '.works.work_authorships') AS source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.authorships = source.authorships,\n",
    "  target.authors_count = source.authors_count,\n",
    "  target.corresponding_author_ids = source.corresponding_author_ids,\n",
    "  target.corresponding_institution_ids = source.corresponding_institution_ids;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9933f224-c204-4f27-9f3c-db7abcd5d1c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `institutions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2cc1c2-623d-47ed-9164-80f195f58a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "UPDATE identifier('openalex' || :env_suffix || '.works.openalex_works')\n",
    "  SET institutions_distinct_count = COALESCE(SIZE(authorships.institutions), 0),\n",
    "      countries_distinct_count = COALESCE(SIZE(\n",
    "        ARRAY_DISTINCT(ARRAY_COMPACT(FLATTEN((authorships.institutions.country_code))))), 0)\n",
    "WHERE authorships IS NOT NULL\n",
    "  AND size(authorships) > 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9522f03a-d2d4-4a64-a315-850dc7204a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `work.type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c92f069-2c0b-4ed6-82b6-db094fc20e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  WITH approved_curations AS (\n",
    "    SELECT\n",
    "      CAST(SUBSTRING(entity_id, 2) AS BIGINT) AS work_id,\n",
    "      MAP_FROM_ENTRIES(COLLECT_LIST(STRUCT(property, property_value))) AS curations\n",
    "    FROM\n",
    "      openalex.curations.approved_curations\n",
    "    WHERE\n",
    "      entity = 'works'\n",
    "      AND property IN ('type', 'language')\n",
    "      AND status = 'approved'\n",
    "    GROUP BY CAST(SUBSTRING(entity_id, 2) AS BIGINT)\n",
    "  )\n",
    "  SELECT \n",
    "    w.paper_id as work_id,\n",
    "    w.type,\n",
    "    w.type_crossref,\n",
    "    ac.work_id IS NOT NULL as has_curation\n",
    "  FROM openalex.mid.work w\n",
    "  LEFT JOIN approved_curations ac ON w.paper_id = ac.work_id\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED \n",
    "  AND target.type <> source.type\n",
    "  AND source.type IS NOT NULL\n",
    "  AND source.has_curation = FALSE\n",
    "THEN UPDATE SET\n",
    "  target.type = COALESCE(source.type, target.type),\n",
    "  target.type_crossref = source.type_crossref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfdc6724-f0ac-488b-a838-55fbecb097fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge `related_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a893b4d-c53d-41ac-851d-1dad836488bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO identifier('openalex' || :env_suffix || '.works.openalex_works') as target\n",
    "USING (\n",
    "  SELECT \n",
    "    work_id, related_works\n",
    "  FROM openalex.works.related_works_backfill\n",
    ") as source\n",
    "ON target.id = source.work_id\n",
    "WHEN MATCHED AND source.related_works IS NOT NULL AND SIZE(source.related_works) > 0\n",
    "THEN UPDATE SET\n",
    "  target.related_works = source.related_works"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "-- Hash-based updated_date: Compare and update after all MERGEs\n",
    "-- Only set updated_date to CURRENT_TIMESTAMP() if content actually changed\n",
    "-- Checkpoint: Excludes authorships, ids, cited_by_count (not yet deterministic)\n",
    "-- See: https://github.com/ourresearch/oax-jobs/tree/main/active/hash-based-updated-date\n",
    "\n",
    "WITH new_hashes AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    xxhash64(CONCAT_WS('|',\n",
    "      CAST(id AS STRING),\n",
    "      COALESCE(doi, ''),\n",
    "      COALESCE(title, ''),\n",
    "      COALESCE(CAST(publication_date AS STRING), ''),\n",
    "      COALESCE(CAST(publication_year AS STRING), ''),\n",
    "      COALESCE(type, ''),\n",
    "      COALESCE(language, ''),\n",
    "      COALESCE(abstract, ''),\n",
    "      COALESCE(TO_JSON(referenced_works), '[]'),\n",
    "      COALESCE(TO_JSON(topics), '[]'),\n",
    "      COALESCE(TO_JSON(concepts), '[]'),\n",
    "      COALESCE(TO_JSON(keywords), '[]'),\n",
    "      COALESCE(TO_JSON(funders), '[]'),\n",
    "      COALESCE(TO_JSON(locations), '[]'),\n",
    "      COALESCE(TO_JSON(awards), '[]'),\n",
    "      COALESCE(TO_JSON(open_access), '{}'),\n",
    "      COALESCE(CAST(is_retracted AS STRING), 'false')\n",
    "    )) AS content_hash\n",
    "  FROM openalex.works.openalex_works\n",
    ")\n",
    "MERGE INTO openalex.works.openalex_works AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    n.id,\n",
    "    CASE\n",
    "      WHEN p.id IS NULL THEN CURRENT_TIMESTAMP()              -- new record\n",
    "      WHEN n.content_hash <> p.content_hash THEN CURRENT_TIMESTAMP()  -- changed\n",
    "      ELSE p.updated_date                                      -- unchanged\n",
    "    END AS new_updated_date\n",
    "  FROM new_hashes n\n",
    "  LEFT JOIN openalex.works.openalex_works_hash p ON n.id = p.id\n",
    ") AS source\n",
    "ON target.id = source.id\n",
    "WHEN MATCHED THEN UPDATE SET target.updated_date = source.new_updated_date;"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CreateWorksEnriched",
   "widgets": {
    "env_suffix": {
     "currentValue": "",
     "nuid": "a32b9271-2b7f-475b-8140-bb4789e5a680",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "_dev",
      "label": "",
      "name": "env_suffix",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}