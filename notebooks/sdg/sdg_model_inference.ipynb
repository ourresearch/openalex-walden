{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02b2f855-6cf8-4bba-8277-74ba8a905ebb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor\n",
    "from transformers import TFBertModel\n",
    "\n",
    "# Load from H5 (no Internet; this uses the embedded weights)\n",
    "SRC_H5 = \"/Volumes/openalex/works/models/sdg/SDG-BERT-v1.1-AURORA_v5.h5\"\n",
    "SRC_KERAS = \"/Volumes/openalex/works/models/sdg/SDG-BERT-v1.1-AURORA_v5.keras\"\n",
    "SRC_SAVED_MODEL = \"/Volumes/openalex/works/models/sdg/saved_model\"\n",
    "\n",
    "model = tf.saved_model.load(SRC_SAVED_MODEL)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"/Volumes/openalex/works/models/sdg/tokenizer\")\n",
    "predict = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc190cf2-ff0e-426f-b4dd-d8d23df05760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(model.signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d238b5-4588-4069-8e01-9413c2f826c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "abstract1 = \"\"\"\n",
    "Climate change is intensifying heatwaves and flooding in low-income regions. \n",
    "We quantify national greenhouse-gas mitigation scenarios and model projected temperature anomalies through 2050. \n",
    "Our results show that rapid decarbonization, renewable energy deployment, and reforestation reduce extreme weather risk and improve public health outcomes. \n",
    "Policy implications include carbon pricing, grid-scale storage, and climate adaptation finance for vulnerable communities.\n",
    "\"\"\"  # Likely SDG 13 (Climate action)\n",
    "\n",
    "abstract2 = \"\"\"\n",
    "Access to safely managed drinking water remains unequal across rural districts. \n",
    "We evaluate a low-cost chlorination and filtration intervention using longitudinal water-quality tests and child health surveys. \n",
    "Households receiving the intervention saw significant reductions in diarrheal disease and time spent collecting water, especially among women and girls. \n",
    "Findings support scalable infrastructure and governance reforms for universal and equitable water services.\n",
    "\"\"\"  # Likely SDG 6 (Clean water and sanitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dfbfa47-621d-40db-b4ba-36db933261c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "goal_names = {\n",
    "    \"Goal 1\": \"No poverty\",\n",
    "    \"Goal 2\": \"Zero hunger\",\n",
    "    \"Goal 3\": \"Good health and well-being\",\n",
    "    \"Goal 4\": \"Quality Education\",\n",
    "    \"Goal 5\": \"Gender equality\",\n",
    "    \"Goal 6\": \"Clean water and sanitation\",\n",
    "    \"Goal 7\": \"Affordable and clean energy\",\n",
    "    \"Goal 8\": \"Decent work and economic growth\",\n",
    "    \"Goal 9\": \"Industry, innovation and infrastructure\",\n",
    "    \"Goal 10\": \"Reduced inequalities\",\n",
    "    \"Goal 11\": \"Sustainable cities and communities\",\n",
    "    \"Goal 12\": \"Responsible consumption and production\",\n",
    "    \"Goal 13\": \"Climate action\",\n",
    "    \"Goal 14\": \"Life below water\",\n",
    "    \"Goal 15\": \"Life in Land\",\n",
    "    \"Goal 16\": \"Peace, Justice and strong institutions\",\n",
    "    \"Goal 17\": \"Partnerships for the goals\"\n",
    "}\n",
    "\n",
    "def get_predictions(abstract: str):\n",
    "    # tokenize to tensors\n",
    "    enc = tokenizer(\n",
    "        abstract.lower(),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    # call SavedModel (keys must match signature)\n",
    "    out = predict(\n",
    "        input_ids = enc[\"input_ids\"],\n",
    "        attention_masks = enc[\"attention_mask\"],  # plural per your signature\n",
    "    )\n",
    "    logits = out[\"target_layer\"].numpy()[0]             # float32 [1,17]\n",
    "    #probs = tf.math.sigmoid(logits)[0].numpy()         # multi-label â†’ sigmoid\n",
    "\n",
    "    # build your existing output shape\n",
    "    response = []\n",
    "    for idx, p in enumerate(logits):\n",
    "        sdg_number = idx + 1\n",
    "        sdg_label  = f\"Goal {sdg_number}\"\n",
    "        response.append({\n",
    "            \"prediction\": float(p),\n",
    "            \"sdg\": {\n",
    "                \"@type\": \"sdg\",\n",
    "                \"id\":   f\"https://metadata.un.org/sdg/{sdg_number}\",\n",
    "                \"label\": sdg_label,\n",
    "                \"code\":  str(sdg_number),\n",
    "                \"name\":  goal_names[sdg_label],\n",
    "                \"type\":  \"Goal\",\n",
    "            }\n",
    "        })\n",
    "    # sort by prediction descending\n",
    "    response.sort(key=lambda k: k[\"prediction\"], reverse=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "678af336-2cee-45ab-a277-e7a633d3682c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preds = get_predictions(abstract2)\n",
    "preds[:5]  # top few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3850e476-c7bc-46ca-add6-53dcbfa48817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "layer = tf.keras.layers.TFSMLayer(SRC_SAVED_MODEL, call_endpoint=\"serving_default\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"/Volumes/openalex/works/models/sdg/saved_model/tokenizer\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc7b2ab-5ddb-4e13-ac57-c6fecc1e4c77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "from transformers.models.bert import modeling_tf_bert as tfbert\n",
    "from nltk import tokenize\n",
    "from transformers import BertTokenizer, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor\n",
    "from transformers import TFBertModel\n",
    "\n",
    "\n",
    "# Build a custom_objects map (cover plain and \"Custom>\" names)\n",
    "custom_objects = {\n",
    "    \"TFBertMainLayer\":   tfbert.TFBertMainLayer,\n",
    "    \"TFBertEmbeddings\":  tfbert.TFBertEmbeddings,\n",
    "    \"TFBertEncoder\":     tfbert.TFBertEncoder,\n",
    "    \"TFBertPooler\":      tfbert.TFBertPooler,\n",
    "}\n",
    "# Also register the \"Custom>\" aliases some saves use\n",
    "custom_objects.update({f\"Custom>{k}\": v for k, v in custom_objects.items()})\n",
    "\n",
    "# Load from H5 (no Internet; this uses the embedded weights)\n",
    "SRC_H5 = \"/Volumes/openalex/works/models/sdg/SDG-BERT-v1.1-AURORA_v5.h5\"\n",
    "SRC_KERAS = \"/Volumes/openalex/works/models/sdg/SDG-BERT-v1.1-AURORA_v5.keras\"\n",
    "SRC_SAVED_MODEL = \"/Volumes/openalex/works/models/sdg/saved_model\"\n",
    "\n",
    "# custom_objects={'TFBertMainLayer': TFBertModel, 'Custom>TFBertMainLayer': TFBertModel}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "  model = load_model(SRC_H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116e913d-fda7-4cb7-af47-10da71cd4b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"/Volumes/openalex/works/models/sdg/saved_model\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c43f9b-fe25-4b0d-81b4-c4a5a36ccf95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -la /Volumes/openalex/works/models/sdg/saved_model/variables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06eb19a5-0ca0-4ac5-9aac-ad4a494977f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"/tmp/SDG-BERT-v1.1-AURORA_v5.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275ac309-5f33-4447-b12d-8dd7a96a5633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e6c38b-5666-463f-9980-849bc4b4397c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers.models.bert.modeling_tf_bert import (\n",
    "    TFBertMainLayer, TFBertEmbeddings, TFBertEncoder, TFBertPooler\n",
    ")\n",
    "\n",
    "custom_objects = {\n",
    "    \"TFBertMainLayer\": TFBertMainLayer,\n",
    "    \"TFBertEmbeddings\": TFBertEmbeddings,\n",
    "    \"TFBertEncoder\": TFBertEncoder,\n",
    "    \"TFBertPooler\": TFBertPooler,\n",
    "}\n",
    "# also register the legacy \"Custom>\" aliases some saves used\n",
    "custom_objects.update({f\"Custom>{k}\": v for k, v in custom_objects.items()})\n",
    "\n",
    "SRC_H5 = \"/Volumes/openalex/works/models/sdg/SDG-BERT-v1.1-AURORA_v5.h5\"\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = tf.keras.models.load_model(\n",
    "        SRC_H5,\n",
    "        compile=False,\n",
    "        safe_mode=False,   # <-- important for Keras 3 legacy graphs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e38fa92-dffb-425c-8f9d-26e7049cba0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(SRC_H5, output_hidden_states=True)\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "368647bb-ffd4-41ec-8544-4e13957c8aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clear the custom objects\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "from transformers import TFBertModel\n",
    "\n",
    "model = TFBertModel.from_pretrained(SRC_H5)\n",
    "\n",
    "# model = tf.keras.models.load_model(\n",
    "#     SRC_H5,\n",
    "#     custom_objects={'Custom>TFBertMainLayer': TFBertMainLayer},\n",
    "#     compile=False,\n",
    "#     safe_mode=False,   # <-- important for Keras 3 legacy graphs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc9b0ff9-644b-4713-aed5-ecabe6eb1271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = (spark.table(\"openalex.works.openalex_works\")\n",
    "    .where(\"ids.doi IS NOT NULL\")\n",
    "    .select(\"ids\")\n",
    "    .withColumn(\"ids\", \n",
    "        F.transform_values(\"ids\", \n",
    "            lambda k, v: F.when(k == \"doi\", \n",
    "                    F.concat(F.lit(\"https://doi.org/\"),v)).otherwise(v)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d1386e-7b5a-466b-a10e-a310c547f5c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secret = {'username': dbutils.secrets.get(scope = \"postgres-works\", key = \"user\"),\n",
    "        'password': dbutils.secrets.get(scope = \"postgres-works\", key = \"password\"),\n",
    "        'host': dbutils.secrets.get(scope = \"postgres-works\", key = \"host\"),\n",
    "        'dbname': dbutils.secrets.get(scope = \"postgres-works\", key = \"dbname\"),\n",
    "        'port': dbutils.secrets.get(scope = \"postgres-works\", key = \"port\"),\n",
    "        'engine': dbutils.secrets.get(scope = \"postgres-works\", key = \"engine\")}\n",
    "\n",
    "df = (spark.read\n",
    "        .format(\"postgresql\")\n",
    "        .option(\"dbtable\", f\"(select paper_id, predictions from mid.work_sdg) as new_table\")\n",
    "        .option(\"host\", secret['host'])\n",
    "        .option(\"port\", secret['port'])\n",
    "        .option(\"database\", secret['dbname'])\n",
    "        .option(\"user\", secret['username'])\n",
    "        .option(\"password\", secret['password'])\n",
    "        .option(\"partitionColumn\", \"paper_id\")\n",
    "        .option(\"lowerBound\", \"0\")\n",
    "        .option(\"upperBound\", \"4413863578\")\n",
    "        .option(\"numPartitions\", \"512\").load())\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"openalex.mid.work_sdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a7c098-77e3-4498-8997-6a6a7eb83077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secret = {'username': dbutils.secrets.get(scope = \"postgres-works\", key = \"user\"),\n",
    "        'password': dbutils.secrets.get(scope = \"postgres-works\", key = \"password\"),\n",
    "        'host': dbutils.secrets.get(scope = \"postgres-works\", key = \"host\"),\n",
    "        'dbname': dbutils.secrets.get(scope = \"postgres-works\", key = \"dbname\"),\n",
    "        'port': dbutils.secrets.get(scope = \"postgres-works\", key = \"port\"),\n",
    "        'engine': dbutils.secrets.get(scope = \"postgres-works\", key = \"engine\")}\n",
    "\n",
    "df = (spark.read\n",
    "        .format(\"postgresql\")\n",
    "        .option(\"dbtable\", f\"(select * from mid.institution_ancestors_mv) as new_table\")\n",
    "        .option(\"host\", secret['host'])\n",
    "        .option(\"port\", secret['port'])\n",
    "        .option(\"database\", secret['dbname'])\n",
    "        .option(\"user\", secret['username'])\n",
    "        .option(\"password\", secret['password'])\n",
    "        .option(\"partitionColumn\", \"author_id\")\n",
    "        .option(\"lowerBound\", \"0\")\n",
    "        .option(\"upperBound\", \"10000109602\")\n",
    "        .option(\"numPartitions\", \"256\").load())\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"openalex.mid.institution_ancestors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2647d436-f46b-4c18-a072-813f0f6e1a9b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757691166819}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT count(*) FROM openalex.mid.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adc19ae0-a11c-49ac-b856-f47df257d752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7856509849571568,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "sdg_model_inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
