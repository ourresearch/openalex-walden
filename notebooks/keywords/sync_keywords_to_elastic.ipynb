{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b5a0cb-d716-47b6-b870-63b0b96939d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install opensearch-py boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53192c77-0348-4cfe-af7f-7b4be0e5dbf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "WITH exploded AS (\n",
    "    SELECT id as work_id, cited_by_count, explode(keywords) as keyword\n",
    "    FROM openalex.works.openalex_works\n",
    "),\n",
    "-- one row per (work_id, keyword_id)\n",
    "dedup AS (\n",
    "  SELECT work_id, cited_by_count, keyword\n",
    "  FROM exploded\n",
    "  QUALIFY row_number() OVER (PARTITION BY work_id, keyword.id ORDER BY work_id, keyword.id) = 1\n",
    "),\n",
    "-- Aggregate on unique keywords\n",
    "aggregated_counts AS (\n",
    "  SELECT\n",
    "    keyword.id as id,\n",
    "    keyword.display_name as display_name,\n",
    "    count(DISTINCT work_id) as works_count,\n",
    "    sum(cited_by_count) as cited_by_count\n",
    "  FROM dedup\n",
    "  GROUP BY 1, 2\n",
    ")\n",
    "-- Join with the common keywords table to get metadata\n",
    "SELECT\n",
    "  ac.id as id,\n",
    "  STRUCT(\n",
    "    ac.id,\n",
    "    ac.display_name,\n",
    "    ac.works_count,\n",
    "    ac.cited_by_count,\n",
    "    CONCAT(\"https://api.openalex.org/works?filter=keywords.id:keywords/\", kw.keyword_id) AS works_api_url,\n",
    "    kw.updated_datetime AS updated_date,\n",
    "    date(kw.created_datetime) as created_date\n",
    "  ) as _source\n",
    "FROM aggregated_counts ac\n",
    "JOIN openalex.common.keywords kw\n",
    "  ON kw.keyword_id = replace(ac.id, 'https://openalex.org/keywords/', '')\"\"\")\n",
    "\n",
    "rows = df.collect()\n",
    "\n",
    "print(f\"Keywords count: {len(rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "219e4a3b-cfeb-4c49-a94b-13176aafd642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from opensearchpy import OpenSearch, helpers, Urllib3HttpConnection, RequestsHttpConnection\n",
    "from pyspark.sql import Row\n",
    "\n",
    "OPENSEARCH_INDEX = \"keywords-v1\"\n",
    "OPENSEARCH_URL = dbutils.secrets.get(scope=\"elastic\", key=\"opensearch_url\")\n",
    "client = OpenSearch(\n",
    "    hosts=[OPENSEARCH_URL],\n",
    "    timeout=180,\n",
    "    max_retries=5,\n",
    "    retry_on_timeout=True\n",
    ")\n",
    "if client.indices.exists(index=OPENSEARCH_INDEX):\n",
    "    client.indices.refresh(index=OPENSEARCH_INDEX)\n",
    "\n",
    "def actions_from_spark(rows, op_type = \"index\"):\n",
    "    for row in rows:\n",
    "        yield {\n",
    "            \"_op_type\": op_type,\n",
    "            \"_index\": OPENSEARCH_INDEX,\n",
    "            \"_id\": row.id,\n",
    "            \"_source\": row._source.asDict(True)\n",
    "        }\n",
    "\n",
    "ok = fail = 0\n",
    "for success, info in helpers.streaming_bulk(client, actions_from_spark(rows),\n",
    "    chunk_size=2000, request_timeout=60, max_retries=3):\n",
    "    if success:\n",
    "        ok += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "\n",
    "print(f\"Indexed ok={ok}, failed={fail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ca5877e-6a05-4917-8e46-36a85d5314d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete old index\n",
    "if client.indices.exists(index='keywords-v1'):\n",
    "    client.indices.delete(index='keywords-v1')\n",
    "\n",
    "# Create with only the field you care about\n",
    "client.indices.create(\n",
    "    index=\"keywords-v1\",\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"id\": {\"type\": \"keyword\"}   # âœ… only this is enforced\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6459fc7-304c-4aeb-a498-22c559453868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "resp = client.delete_by_query(\n",
    "    index=\"keywords-v1\",\n",
    "    body={\"query\": {\"match_all\": {}}}\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "911f436c-4dfa-4efb-b841-173394ee4bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sync_keywords_to_elastic",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
