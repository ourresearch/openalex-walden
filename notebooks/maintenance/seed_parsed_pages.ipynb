{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed `parsed_pages` from `taxicab_enriched_new`\n",
    "\n",
    "One-time migration: extracts Parseland response fields + metadata from\n",
    "`openalex.landing_page.taxicab_enriched_new` (~59M records) into\n",
    "`openalex.parseland.parsed_pages`.\n",
    "\n",
    "This ensures zero data loss when the DLT pipeline switches from calling\n",
    "Parseland directly to reading from `parsed_pages`.\n",
    "\n",
    "**Run once, then delete or archive this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read existing enriched data\n",
    "enriched = spark.read.table(\"openalex.landing_page.taxicab_enriched_new\")\n",
    "print(f\"taxicab_enriched_new: {enriched.count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's already in parsed_pages to avoid duplicates\n",
    "already_seeded = spark.read.table(\"openalex.parseland.parsed_pages\").select(\"taxicab_id\")\n",
    "already_count = already_seeded.count()\n",
    "print(f\"Already in parsed_pages: {already_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parseland response fields from the enriched table\n",
    "# and combine with taxicab metadata\n",
    "seed_data = (\n",
    "    enriched\n",
    "    .join(already_seeded, \"taxicab_id\", \"left_anti\")\n",
    "    .select(\n",
    "        F.col(\"taxicab_id\"),\n",
    "        F.col(\"url\"),\n",
    "        F.col(\"resolved_url\"),\n",
    "        F.col(\"native_id\"),\n",
    "        F.col(\"native_id_namespace\"),\n",
    "        F.col(\"parser_response.authors\").alias(\"authors\"),\n",
    "        F.col(\"parser_response.urls\").alias(\"urls\"),\n",
    "        F.col(\"parser_response.license\").alias(\"license\"),\n",
    "        F.col(\"parser_response.version\").alias(\"version\"),\n",
    "        F.col(\"parser_response.abstract\").alias(\"abstract\"),\n",
    "        F.col(\"parser_response.had_error\").alias(\"had_error\"),\n",
    "        F.col(\"created_date\").alias(\"parsed_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "new_count = seed_data.count()\n",
    "print(f\"New records to seed: {new_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to parsed_pages\n",
    "seed_data.write.mode(\"append\").format(\"delta\").saveAsTable(\"openalex.parseland.parsed_pages\")\n",
    "\n",
    "final_count = spark.read.table(\"openalex.parseland.parsed_pages\").count()\n",
    "print(f\"parsed_pages total after seed: {final_count:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}