{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41cee6a7-b306-46f5-9bc6-0734632da473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initialize LM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e871224-93f8-4478-9884-64a8733540ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install tf-keras torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e6638a-17ae-4345-8cb4-9db007e6b38d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "\n",
    "classifier_multi = pipeline(model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\", top_k=3)\n",
    "classifier_multi(\"\"\"<TITLE>Supplemental Material: Estimating paleotidal constituents from Pliocene “tidal gauges”—an example from the paleo-Orinoco Delta, Trinidad\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7481750b-e387-4477-9c32-a0f500bfb2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test with samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59e80d63-3e42-4b84-8a94-5436f2463cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "olfactory_input = \"\"\"<TITLE>The Shape of the Olfactory Bulb Predicts Olfactory Function<ABSTRACT>The olfactory bulb (OB) plays a key role in the processing of olfactory information. A large body of research has shown that OB volumes correlate with olfactory function, which provides diagnostic and prognostic information in olfactory dysfunction. Still, the potential value of the OB shape remains unclear. Based on our clinical experience we hypothesized that the shape of the OB predicts olfactory function, and that it is linked to olfactory loss, age, and gender. The aim of this study was to produce a classification of OB shape in the human brain, scalable to clinical and research applications. Results from patients with the five most frequent causes of olfactory dysfunction (n = 192) as well as age/gender-matched healthy controls (n = 77) were included. Olfactory function was examined in great detail using the extended “Sniffin’ Sticks” test. A high-resolution structural T2-weighted MRI scan was obtained for all. The planimetric contours (surface in mm2) of OB were delineated manually, and then all surfaces were added and multiplied to obtain the OB volume in mm3. OB shapes were outlined manually and characterized on a selected slice through the posterior coronal plane tangential to the eyeballs. We looked at OB shapes in terms of convexity and defined two patterns/seven categories based on OB contours: convex\"\"\"\n",
    "\n",
    "paleotidal_input = \"\"\"<TITLE>Supplemental Material: Estimating paleotidal constituents from Pliocene “tidal gauges”—an example from the paleo-Orinoco Delta, Trinidad\"\"\"\n",
    "\n",
    "print(classifier_multi(olfactory_input))\n",
    "print(classifier_multi(paleotidal_input))\n",
    "\n",
    "# IN PROD (first 2 topics match)\n",
    "# 10971\tOlfactory and Sensory Function Studies\n",
    "# 11667\tAdvanced Chemical Sensor Technologies\n",
    "# 14144\tNeurological Disease Mechanisms and Treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd10460e-5ac1-43a8-a1e5-46d1f32f0b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6db2777-8c0c-4dd2-b232-6668fe0a91b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "class ModelCache:\n",
    "    model = None\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls):\n",
    "        if cls.model is not None:\n",
    "            return\n",
    "\n",
    "        # Determine available GPU count\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        if num_devices == 0:\n",
    "            raise RuntimeError(\"No CUDA devices available.\")\n",
    "\n",
    "        # Assign device using pid hash\n",
    "        pid = os.getpid()\n",
    "        device_id = pid % num_devices\n",
    "        cls.assigned_device = device_id\n",
    "\n",
    "        print(f\"Loading model on GPU:{device_id} for pid:{pid}\")\n",
    "\n",
    "        cls.model = pipeline(\n",
    "            model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\",\n",
    "            tokenizer=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\",\n",
    "            device=device_id,  # ✅ Assign GPU\n",
    "            top_k=5,\n",
    "            batch_size=12,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "def remove_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to remove non-latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    final_char: string of characters with non-latin characters removed\n",
    "    \"\"\"\n",
    "    final_char = []\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI','CYRILLIC']\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script not in groups_to_skip:\n",
    "                final_char.append(char)\n",
    "        except:\n",
    "            pass\n",
    "    return \"\".join(final_char)\n",
    "    \n",
    "def group_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to group non-latin characters and return the number of latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    groups: list of character groups\n",
    "    latin_chars: number of latin characters\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    latin_chars = []\n",
    "    text = text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script == 'LATIN':\n",
    "                latin_chars.append(script)\n",
    "            else:\n",
    "                if script not in groups:\n",
    "                    groups.append(script)\n",
    "        except:\n",
    "            if \"UNK\" not in groups:\n",
    "                groups.append(\"UNK\")\n",
    "    return groups, len(latin_chars)\n",
    "\n",
    "def check_for_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to check if non-latin characters are dominant in a text.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    0: if text should be not used\n",
    "    1: if text should be used\n",
    "    \"\"\"\n",
    "    groups, latin_chars = group_non_latin_characters(str(text))\n",
    "    if name_to_keep_ind(groups) == 1:\n",
    "        return 1\n",
    "    elif latin_chars > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def clean_title(old_title):\n",
    "    \"\"\"\n",
    "    Function to check if title should be kept and then remove non-latin characters. Also\n",
    "    removes some HTML tags from the title.\n",
    "    \n",
    "    Input:\n",
    "    old_title: string of title\n",
    "    \n",
    "    Output:\n",
    "    new_title: string of title with non-latin characters and HTML tags removed\n",
    "    \"\"\"\n",
    "    keep_title = check_for_non_latin_characters(old_title)\n",
    "    if keep_title == 1:\n",
    "        new_title = remove_non_latin_characters(old_title)\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\"<i>\", \"\").replace(\"</i>\",\"\")\\\n",
    "                                 .replace(\"<sub>\", \"\").replace(\"</sub>\",\"\") \\\n",
    "                                 .replace(\"<sup>\", \"\").replace(\"</sup>\",\"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\",\"\") \\\n",
    "                                 .replace(\"<b>\", \"\").replace(\"</b>\",\"\") \\\n",
    "                                 .replace(\"<I>\", \"\").replace(\"</I>\", \"\") \\\n",
    "                                 .replace(\"<SUB>\", \"\").replace(\"</SUB>\", \"\") \\\n",
    "                                 .replace(\"<scp>\", \"\").replace(\"</scp>\", \"\") \\\n",
    "                                 .replace(\"<font>\", \"\").replace(\"</font>\", \"\") \\\n",
    "                                 .replace(\"<inf>\",\"\").replace(\"</inf>\", \"\") \\\n",
    "                                 .replace(\"<i /> \", \"\") \\\n",
    "                                 .replace(\"<p>\", \"\").replace(\"</p>\",\"\") \\\n",
    "                                 .replace(\"<![CDATA[<B>\", \"\").replace(\"</B>]]>\", \"\") \\\n",
    "                                 .replace(\"<italic>\", \"\").replace(\"</italic>\",\"\")\\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<br>\", \"\").replace(\"</br>\",\"\").replace(\"<br/>\",\"\") \\\n",
    "                                 .replace(\"<B>\", \"\").replace(\"</B>\", \"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\", \"\") \\\n",
    "                                 .replace(\"<BR>\", \"\").replace(\"</BR>\", \"\") \\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<strong>\", \"\").replace(\"</strong>\", \"\") \\\n",
    "                                 .replace(\"<formula>\", \"\").replace(\"</formula>\", \"\") \\\n",
    "                                 .replace(\"<roman>\", \"\").replace(\"</roman>\", \"\") \\\n",
    "                                 .replace(\"<SUP>\", \"\").replace(\"</SUP>\", \"\") \\\n",
    "                                 .replace(\"<SSUP>\", \"\").replace(\"</SSUP>\", \"\") \\\n",
    "                                 .replace(\"<sc>\", \"\").replace(\"</sc>\", \"\") \\\n",
    "                                 .replace(\"<subtitle>\", \"\").replace(\"</subtitle>\", \"\") \\\n",
    "                                 .replace(\"<emph/>\", \"\").replace(\"<emph>\", \"\").replace(\"</emph>\", \"\") \\\n",
    "                                 .replace(\"\"\"<p class=\"Body\">\"\"\", \"\") \\\n",
    "                                 .replace(\"<TITLE>\", \"\").replace(\"</TITLE>\", \"\") \\\n",
    "                                 .replace(\"<sub />\", \"\").replace(\"<sub/>\", \"\") \\\n",
    "                                 .replace(\"<mi>\", \"\").replace(\"</mi>\", \"\") \\\n",
    "                                 .replace(\"<bold>\", \"\").replace(\"</bold>\", \"\") \\\n",
    "                                 .replace(\"<mtext>\", \"\").replace(\"</mtext>\", \"\") \\\n",
    "                                 .replace(\"<msub>\", \"\").replace(\"</msub>\", \"\") \\\n",
    "                                 .replace(\"<mrow>\", \"\").replace(\"</mrow>\", \"\") \\\n",
    "                                 .replace(\"</mfenced>\", \"\").replace(\"</math>\", \"\")\n",
    "\n",
    "            if '<mml' in new_title:\n",
    "                all_parts = [x for y in [i.split(\"mml:math>\") for i in new_title.split(\"<mml:math\")] for x in y if x]\n",
    "                final_parts = []\n",
    "                for part in all_parts:\n",
    "                    if re.search(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part):\n",
    "                        pull_out = re.findall(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part)\n",
    "                        final_pieces = []\n",
    "                        for piece in pull_out:\n",
    "                            final_pieces.append(piece.replace(\">\", \"\").replace(\"<\", \"\"))\n",
    "                        \n",
    "                        final_parts.append(\" \"+ \"\".join(final_pieces) + \" \")\n",
    "                    else:\n",
    "                        final_parts.append(part)\n",
    "                \n",
    "                new_title = \"\".join(final_parts).strip()\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if '<xref' in new_title:\n",
    "                new_title = re.sub(r\"\\<xref[^/]*\\/xref\\>\", \"\", new_title)\n",
    "\n",
    "            if '<inline-formula' in new_title:\n",
    "                new_title = re.sub(r\"\\<inline-formula[^/]*\\/inline-formula\\>\", \"\", new_title)\n",
    "\n",
    "            if '<title' in new_title:\n",
    "                new_title = re.sub(r\"\\<title[^/]*\\/title\\>\", \"\", new_title)\n",
    "\n",
    "            if '<p class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<p class=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if '<span class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<span class=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "            if 'mfenced open' in new_title:\n",
    "                new_title = re.sub(r\"\\<mfenced open=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if 'math xmlns' in new_title:\n",
    "                new_title = re.sub(r\"\\<math xmlns=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\">i<\", \"\").replace(\">/i<\", \"\") \\\n",
    "                                 .replace(\">b<\", \"\").replace(\">/b<\", \"\") \\\n",
    "                                 .replace(\"<inline-formula>\", \"\").replace(\"</inline-formula>\",\"\")\n",
    "\n",
    "        return new_title\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def clean_abstract(raw_abstract, inverted=False):\n",
    "    \"\"\"\n",
    "    Function to clean abstract and return it in a format for the model.\n",
    "    \n",
    "    Input:\n",
    "    raw_abstract: string of abstract\n",
    "    inverted: boolean to determine if abstract is inverted index or not\n",
    "    \n",
    "    Output:\n",
    "    final_abstract: string of abstract in format for model\n",
    "    \"\"\"\n",
    "    if inverted:\n",
    "        if isinstance(raw_abstract, dict) | isinstance(raw_abstract, str):\n",
    "            if isinstance(raw_abstract, dict):\n",
    "                invert_abstract = raw_abstract\n",
    "            else:\n",
    "                invert_abstract = json.loads(raw_abstract)\n",
    "            \n",
    "            if invert_abstract.get('IndexLength'):\n",
    "                ab_len = invert_abstract['IndexLength']\n",
    "\n",
    "                if ab_len > 20:\n",
    "                    abstract = [\" \"]*ab_len\n",
    "                    for key, value in invert_abstract['InvertedIndex'].items():\n",
    "                        for i in value:\n",
    "                            abstract[i] = key\n",
    "                    final_abstract = \" \".join(abstract)[:2500]\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "            else:\n",
    "                if len(invert_abstract) > 20:\n",
    "                    abstract = [\" \"]*1200\n",
    "                    for key, value in invert_abstract.items():\n",
    "                        for i in value:\n",
    "                            try:\n",
    "                                abstract[i] = key\n",
    "                            except:\n",
    "                                pass\n",
    "                    final_abstract = \" \".join(abstract)[:2500].strip()\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "                \n",
    "        else:\n",
    "            final_abstract = None\n",
    "    else:\n",
    "        ab_len = len(raw_abstract)\n",
    "        if ab_len > 30:\n",
    "            final_abstract = raw_abstract[:2500]\n",
    "            keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "            if keep_abs == 1:\n",
    "                pass\n",
    "            else:\n",
    "                final_abstract = None\n",
    "        else:\n",
    "            final_abstract = None\n",
    "            \n",
    "    return final_abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb11fe00-21ef-45dd-81dd-43a1f6132dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load inference input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff7dac6-6f5b-4904-8a76-414aeb488291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM openalex.works.works_topics_compare\").repartition(96)\n",
    "print(f\"Input Row Count: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "324b64fc-db9a-49bb-a905-4f2ccf427018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c138b8-ff93-4103-a716-259c0bab8e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def process_partition(rows, batch_size=12):\n",
    "    import torch\n",
    "    ModelCache.load()\n",
    "    model = ModelCache.model\n",
    "\n",
    "    batch_rows = []\n",
    "    batch_texts = []\n",
    "\n",
    "    def yield_batch(rows_batch, texts_batch):\n",
    "        try:\n",
    "            batch_outputs = model(texts_batch)\n",
    "        except Exception as e:\n",
    "            batch_outputs = [[] for _ in texts_batch]  # fail-safe: empty predictions\n",
    "\n",
    "        for row, output in zip(rows_batch, batch_outputs):\n",
    "            row_dict = row.asDict()\n",
    "            lm_output = [\n",
    "                {\n",
    "                    \"topic_id\": 10000 + int(topic[\"label\"].split(\":\")[0]),\n",
    "                    \"score\": float(topic[\"score\"])\n",
    "                }\n",
    "                for topic in output\n",
    "            ] if output else None\n",
    "\n",
    "            row_dict[\"lm_topics\"] = lm_output\n",
    "            yield row_dict\n",
    "\n",
    "    for row in rows:\n",
    "        if row is None:\n",
    "            continue\n",
    "\n",
    "        title = clean_title(row['title']) or \"\"\n",
    "        abstract = clean_abstract(row['abstract']) or \"\"\n",
    "        full_text = f\"<TITLE>{title.strip()}<ABSTRACT>{abstract.strip()}\"\n",
    "\n",
    "        batch_rows.append(row)\n",
    "        batch_texts.append(full_text)\n",
    "\n",
    "        if len(batch_texts) >= batch_size:\n",
    "            yield from yield_batch(batch_rows, batch_texts)\n",
    "            batch_rows = []\n",
    "            batch_texts = []\n",
    "\n",
    "    # Process remaining rows\n",
    "    if batch_rows:\n",
    "        yield from yield_batch(batch_rows, batch_texts)\n",
    "\n",
    "topic_struct = StructType([\n",
    "    StructField(\"topic_id\", IntegerType(), True),\n",
    "    StructField(\"score\", FloatType(), True)\n",
    "])\n",
    "\n",
    "output_schema = StructType([\n",
    "    StructField(\"work_id\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"abstract\", StringType(), True),\n",
    "    StructField(\"journal_name\", StringType(), True),\n",
    "    StructField(\"lm_topics\", ArrayType(topic_struct), True)\n",
    "])\n",
    "\n",
    "res_rdd = df.select(\"work_id\", \"title\", \"abstract\", \"journal_name\").foreachPartition(process_partition)\n",
    "res_df = spark.createDataFrame(res_rdd, output_schema).cache()\n",
    "print(f\"Output Row count: {res_df.count()}\")\n",
    "\n",
    "res_df = (res_df.select(\"work_id\", \"title\", \"abstract\", \"journal_name\", \"lm_topics\")\n",
    "                .withColumn(\"lm_primary_topic\", col(\"lm_topics\")[0])\n",
    "                .withColumn(\"created_timestamp\", current_timestamp()))\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ab7210-1ede-483c-a004-dd9cca9c351e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Profile with Serverless GPU (A10)\n",
    "Batching is effective, but not dramatically so when compared to single inputs (10-15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32bb36aa-8869-407d-a67c-3c8805d05c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Repeat the same input for X iterations\n",
    "X = 1000\n",
    "inputs = [olfactory_input, paleotidal_input] * (X // 2)\n",
    "\n",
    "# Warm up the model (important for GPU / XLA compilation)\n",
    "_ = classifier_multi(inputs[:2])\n",
    "\n",
    "# Time the loop\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(X):\n",
    "    _ = classifier_multi(inputs[i]) # run with single input only\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"🔥 Ran {X} inferences in {total_time:.2f} seconds\")\n",
    "print(f\"⚡ Avg per inference: {total_time / X:.3f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bedff7dd-5fd6-4e0a-9110-63d4c650e79f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "# Prepare inputs\n",
    "X = 640\n",
    "inputs = [olfactory_input, paleotidal_input] * (X // 2)\n",
    "\n",
    "# Try different batch sizes\n",
    "for bs in [4, 8, 16, 32, 64]:\n",
    "    print(f\"\\n🚀 Testing batch_size={bs}\")\n",
    "\n",
    "    # Re-initialize pipeline with new batch size\n",
    "    classifier_multi = pipeline(\n",
    "        model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\",\n",
    "        top_k=5,\n",
    "        batch_size=bs\n",
    "    )\n",
    "\n",
    "    # Warm-up (important for GPU/XLA)\n",
    "    _ = classifier_multi(inputs[:2])\n",
    "\n",
    "    # Time batch inference\n",
    "    start = time.time()\n",
    "    _ = classifier_multi(inputs) # takes in the whole dataset and batches internally\n",
    "    duration = time.time() - start\n",
    "\n",
    "    print(f\"⏱️  Total time: {duration:.2f} sec for {X} inputs\")\n",
    "    print(f\"⚡ Avg time per input: {duration / X:.3f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "transformers",
     "tensorflow",
     "sentence_transformers",
     "torch"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "topics_bert_serverless_gpu_poc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
