{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3befb9e-adfd-4207-9ad3-da37e4771841",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73d86860-b6b5-4b4f-95d5-5b0ab2963339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from topic_predictor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e5d522-89b7-48e8-93a7-3e0794a41248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, pipeline, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import model_config as cfg\n",
    "\n",
    "# Load all artifacts\n",
    "with open(os.path.join(cfg.model_path, \"target_vocab.pkl\"), \"rb\") as f:\n",
    "    cfg.target_vocab = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(cfg.model_path, \"inv_target_vocab.pkl\"), \"rb\") as f:\n",
    "    cfg.inv_target_vocab = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(cfg.model_path, \"citation_feature_vocab.pkl\"), \"rb\") as f:\n",
    "    cfg.citation_feature_vocab = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(cfg.model_path, \"gold_to_id_mapping_dict.pkl\"), \"rb\") as f:\n",
    "    cfg.gold_to_label_mapping = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(cfg.model_path, \"gold_citations_dict.pkl\"), \"rb\") as f:\n",
    "    cfg.gold_dict = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(cfg.model_path, \"non_gold_citations_dict.pkl\"), \"rb\") as f:\n",
    "    cfg.non_gold_dict = pickle.load(f)\n",
    "\n",
    "cfg.emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.language_model_name, truncate=True)\n",
    "\n",
    "print(\"✅ All model artifacts loaded into model_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282bf0ab-d425-4c06-8a97-e38d887554ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from topic_predictor import *\n",
    "\n",
    "# Loading the models\n",
    "pred_model = create_model(len(cfg.target_vocab), \n",
    "                          len(cfg.citation_feature_vocab)+2)\n",
    "#status = pred_model.load_weights(\"/Volumes/openalex/works/models/topic_classifier_v1/model_checkpoint/citation_part_only.keras\",\n",
    "#                        skip_mismatch=True)\n",
    "\n",
    "print(\"✅ Model created.\")\n",
    "cfg.xla_predict = tf.function(pred_model, jit_compile=True)\n",
    "\n",
    "#pt_model = AutoModelForSequenceClassification.from_pretrained(language_model_name, output_hidden_states=True)\n",
    "#pt_model.eval()\n",
    "\n",
    "language_model = TFAutoModelForSequenceClassification.from_pretrained(cfg.language_model_name, output_hidden_states=True)\n",
    "language_model.trainable = False\n",
    "cfg.xla_predict_lang_model = tf.function(language_model, jit_compile=True)\n",
    "\n",
    "# # Sending a blank prediction through the model in order to get it \"warmed up\"\n",
    "# _ = xla_predict(create_input_feature([[101, 102] + [0]*510, \n",
    "#                                       [1, 1] + [0]*510,\n",
    "#                                       [1]+[0]*15, \n",
    "#                                       [1]+[0]*127,\n",
    "#                                       np.zeros(384, dtype=np.float32)]))\n",
    "print(\"✅ Model initialized\")\n",
    "\n",
    "\n",
    "# model.save(\"/dbfs/models/citation_part_only_full.keras\")\n",
    "# print(\"✅ Full model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20a2d9dc-5237-4ca6-a8f4-4080f2de93be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1364099-bf13-4d5d-8ccc-a30a588478d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Weights seem to be defined OK if though there are warnings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ffd4802-4f51-47f7-96b2-53d43b48e321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for layer in pred_model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"{layer.name}: {len(weights)} weights, shapes: {[w.shape for w in weights]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3d93a49-12df-446f-9547-464f41170a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df6c157-ec8a-4752-b250-3dc661f4b491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "open_req = \"https://api.openalex.org/works/W4205779344\"\n",
    "resp = requests.get(open_req).json()\n",
    "print(resp['id'])\n",
    "\n",
    "if resp['primary_location']['source']:\n",
    "    journal_display_name = resp['primary_location']['source']['display_name']\n",
    "else:\n",
    "    journal_display_name = \"\"\n",
    "\n",
    "\n",
    "input_json = {'title': resp['title'], \n",
    "               'abstract_inverted_index': resp['abstract_inverted_index'], \n",
    "               'journal_display_name': journal_display_name, \n",
    "               'referenced_works': resp['referenced_works'],\n",
    "               'inverted': True}\n",
    "\n",
    "display(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbb3588-e5ba-40b9-a0c1-53a1c4f75b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_str = json.dumps(input_json)\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b1a6db-9edc-4fef-87c1-19088c295f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#json_str = json.dumps(input_json)\n",
    "input_df = pd.DataFrame.from_dict([input_json]).reset_index().rename(columns={'index': 'UID'})\n",
    "result = transform_json(input_df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2385ba13-7f63-4519-b843-6836a8ae00bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PLAIN Test Bed - Needs to work first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88862217-c256-4b0d-b399-24e70e4af048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_model_inference(model, record, ignore_citations_journal=False):\n",
    "    # Step 1: Clean and merge title + abstract\n",
    "    title = clean_title(record['title'])\n",
    "    abstract = clean_abstract(record['abstract_inverted_index'], record['inverted'])\n",
    "    merged_text = merge_title_and_abstract(title, abstract)\n",
    "    print(\"🧹 Cleaned + Merged Text:\\n\", merged_text[:300], \"...\\n\")\n",
    "\n",
    "    # Step 2: Tokenize text\n",
    "    tokenized = tokenize([merged_text])  # expects batch\n",
    "    ids = tokenized[0][0]\n",
    "    attention_mask = tokenized[1][0]\n",
    "    print(\"🧪 Token IDs:\", ids[:20])\n",
    "    print(\"📏 Attention Mask:\", attention_mask[:20])\n",
    "    print(\"📚 Decoded Text from IDs:\", cfg.tokenizer.decode(ids))\n",
    "\n",
    "    # Step 3: Convert citation URLs to integers\n",
    "    raw_refs = record.get(\"referenced_works\", [])\n",
    "    citation_ids = [int(x.split(\"https://openalex.org/W\")[1]) for x in raw_refs]\n",
    "    print(\"🔗 Raw Citation IDs:\", citation_ids)\n",
    "\n",
    "    if ignore_citations_journal:\n",
    "        citation_0 = np.zeros(16, dtype=np.float32)\n",
    "        citation_1 = np.zeros(128, dtype=np.float32)\n",
    "    else:\n",
    "        citation_0_ids, citation_1_ids = get_gold_citations_from_all_citations(citation_ids, cfg.gold_dict, cfg.non_gold_dict)\n",
    "        print(\"🏅 Gold Citation IDs:\", citation_0_ids)\n",
    "        print(\"🥈 Non-Gold Citation IDs:\", citation_1_ids)\n",
    "        citation_0 = get_final_citations_feature(citation_0_ids, 16)\n",
    "        citation_1 = get_final_citations_feature(citation_1_ids, 128)\n",
    "\n",
    "    print(\"🧾 Citation_0 Features:\", citation_0[:10])\n",
    "    print(\"🧾 Citation_1 Features:\", citation_1[:10])\n",
    "\n",
    "    # Step 4: Get journal embedding\n",
    "    if ignore_citations_journal:\n",
    "        journal_emb = np.zeros(384, dtype=np.float32)\n",
    "    else:\n",
    "        journal_emb = get_journal_emb(record.get(\"journal_display_name\", \"\"))\n",
    "\n",
    "    print(\"📄 Journal Embedding (first 10):\", journal_emb[:10])\n",
    "\n",
    "    # Step 5: Prepare tensors\n",
    "    tensor_inputs = create_input_feature([ids, attention_mask, citation_0, citation_1, journal_emb])\n",
    "    all_rows = [tf.convert_to_tensor([tensor_inputs[i][0]]) for i in range(5)]\n",
    "\n",
    "    lang_model_inputs = cfg.tokenizer(text, max_length=512, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    lang_output = cfg.xla_predict_lang_model(**lang_model_inputs).hidden_states[-1]\n",
    "    # Step 6: Get language model output and make prediction\n",
    "    # lang_output = get_lang_model_output(all_rows[0], all_rows[1])\n",
    "    print(\"🧠 Lang Model Output Shape:\", lang_output.shape)\n",
    "\n",
    "    preds = model((all_rows[2], all_rows[3], all_rows[4], lang_output))\n",
    "    print(\"📈 Raw Prediction Tensor Shape:\", preds.shape)\n",
    "\n",
    "    # Step 7: Get top-k\n",
    "    topk = tf.math.top_k(preds, k=5)\n",
    "    indices = topk.indices.numpy().tolist()[0]\n",
    "    scores = topk.values.numpy().tolist()[0]\n",
    "    labels = [cfg.inv_target_vocab.get(i, f\"UNKNOWN_{i}\") for i in indices]\n",
    "\n",
    "    print(\"🏷️ Predicted Label IDs:\", indices)\n",
    "    print(\"🔥 Scores:\", scores)\n",
    "    print(\"🏷️ Labels:\", labels)\n",
    "\n",
    "    # Step 8: Return enriched record\n",
    "    return {\n",
    "        \"UID\": record.get(\"UID\", 0),\n",
    "        \"preds\": indices,\n",
    "        \"scores\": scores,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "results = run_model_inference(pred_model, input_json, ignore_citations_journal=False)\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91154a97-499c-40f5-be9a-371c87ed6f03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.config.id2label[2149]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0a94b4-6038-4e26-afff-13efd4a142ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Uuse `process_data_as_df` he model output does not look correct - look more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1178e090-ca9d-44cb-bf9b-4ec65b488e99",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"scores\":321,\"pred_labels\":431},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753315431190}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_df = pd.DataFrame.from_dict([input_json]).reset_index().rename(columns={'index': 'UID'})\n",
    "final_preds = process_data_as_df(input_df)\n",
    "\n",
    "def map_preds_to_labels(preds_list, vocab_dict):\n",
    "    return [[vocab_dict.get(i, f\"UNKNOWN_{i}\") for i in preds] for preds in preds_list]\n",
    "\n",
    "final_preds[\"pred_labels\"] = map_preds_to_labels(final_preds[\"preds\"], cfg.inv_target_vocab)\n",
    "final_preds[\"pred_labels_auto\"] = map_preds_to_labels(final_preds[\"preds\"], model.config.id2label)\n",
    "\n",
    "\n",
    "display(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e361ace-a9a0-4771-ad3b-738d6c9569fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = postprocess_predictions(final_preds.iloc[0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fe06bf-dad6-4e03-9302-44445fd17051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "classifier_multi = pipeline(model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\", top_k=5)\n",
    "classifier_multi(\"\"\"<TITLE>Supplemental Material: Estimating paleotidal constituents from Pliocene “tidal gauges”—an example from the paleo-Orinoco Delta, Trinidad\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bf8d99b-c8aa-4432-a8aa-9b958fe49568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4d6952d-218c-4a0b-a5a7-8e5ae20eeac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "olfactory_input = \"\"\"<TITLE>The Shape of the Olfactory Bulb Predicts Olfactory Function<ABSTRACT>The olfactory bulb (OB) plays a key role in the processing of olfactory information. A large body of research has shown that OB volumes correlate with olfactory function, which provides diagnostic and prognostic information in olfactory dysfunction. Still, the potential value of the OB shape remains unclear. Based on our clinical experience we hypothesized that the shape of the OB predicts olfactory function, and that it is linked to olfactory loss, age, and gender. The aim of this study was to produce a classification of OB shape in the human brain, scalable to clinical and research applications. Results from patients with the five most frequent causes of olfactory dysfunction (n = 192) as well as age/gender-matched healthy controls (n = 77) were included. Olfactory function was examined in great detail using the extended “Sniffin’ Sticks” test. A high-resolution structural T2-weighted MRI scan was obtained for all. The planimetric contours (surface in mm2) of OB were delineated manually, and then all surfaces were added and multiplied to obtain the OB volume in mm3. OB shapes were outlined manually and characterized on a selected slice through the posterior coronal plane tangential to the eyeballs. We looked at OB shapes in terms of convexity and defined two patterns/seven categories based on OB contours: convex\"\"\"\n",
    "\n",
    "paleotidal_input = \"\"\"<TITLE>Supplemental Material: Estimating paleotidal constituents from Pliocene “tidal gauges”—an example from the paleo-Orinoco Delta, Trinidad\"\"\"\n",
    "\n",
    "print(classifier_multi(olfactory_input))\n",
    "print(classifier_multi(paleotidal_input))\n",
    "\n",
    "# 10971\tOlfactory and Sensory Function Studies\n",
    "# 11667\tAdvanced Chemical Sensor Technologies\n",
    "# 14144\tNeurological Disease Mechanisms and Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257e8ab8-b28e-42ab-8201-3f2213cda4a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "# Prepare inputs\n",
    "X = 64\n",
    "inputs = [olfactory_input, paleotidal_input] * (X // 2)\n",
    "\n",
    "# Try different batch sizes\n",
    "for bs in [32,64]:\n",
    "    print(f\"\\n🚀 Testing batch_size={bs}\")\n",
    "\n",
    "    # Re-initialize pipeline with new batch size\n",
    "    classifier_multi = pipeline(\n",
    "        model=\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\",\n",
    "        top_k=5,\n",
    "        batch_size=bs\n",
    "    )\n",
    "\n",
    "    # Warm-up (important for GPU/XLA)\n",
    "    _ = classifier_multi(inputs[:2])\n",
    "\n",
    "    # Time batch inference\n",
    "    start = time.time()\n",
    "    _ = classifier_multi(inputs)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    print(f\"⏱️  Total time: {duration:.2f} sec for {X} inputs\")\n",
    "    print(f\"⚡ Avg time per input: {duration / X:.3f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b2d28b-36a7-4f1f-80b3-40e20bd6953f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "label2id = classifier_multi.model.config.label2id\n",
    "print(label2id[\"971: Olfactory Dysfunction in Health and Disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1832ff71-0e00-4a18-aa1c-ccbe59028d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(classifier_multi.model.config.id2label[1733])\n",
    "print(cfg.inv_target_vocab[1733])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2c217e-233c-459e-9f38-c6b30f182725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "matches = [(k, v) for k, v in cfg.inv_target_vocab.items() if v.startswith(\"971: \")]\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "369956c4-3a25-4a22-a26a-bd88f226289e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Use BERT Model Only for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7402cae7-b776-4b3b-9a42-26ebeca881a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "auto_conf = AutoConfig.from_pretrained(\"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "430b993b-753a-4a05-b401-7d70542a13cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(auto_conf.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbf3431f-5469-44fb-aa30-68b0189112b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cfg.inv_target_vocab[972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64caf248-bf32-44d9-bacf-57ee2ea65def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # /Volumes/openalex/works/models/topic_classifier_v1/full_model.keras\n",
    "# pred_model.save(\"/dbfs/tmp/full_model.keras\")\n",
    "# print(\"✅ Full Keras model saved.\")\n",
    "\n",
    "#pred_model.save(\"/Volumes/openalex/works/models/topic_classifier_v1/tf_savedmodel\", save_format=\"tf\")\n",
    "#print(\"✅ Saved model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9160a664-1bd5-4d0f-86e2-f55dc3f0e924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#size 39,654,502 (checkpoint 39,650,086)\n",
    "test_model = load_model(\"/Volumes/openalex/works/models/topic_classifier_v1/full_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf16e04-f342-4ac6-b11d-b9042b5094c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3093f59-208c-4fac-90d8-862b3ddf10a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for layer in test_model.layers:\n",
    "    if \"output_layer\" in layer.name:\n",
    "        weights = layer.get_weights()\n",
    "        print(f\"{layer.name}: {[w.shape for w in weights]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f3b5bc3-3891-43db-a3e3-625b7a6b28df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SUCCESS - raw BERT use (no hugging_face pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0d984ff-f3ff-49b8-b886-361ff8c68030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Example text\n",
    "text = olfactory_input\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(text, max_length=512, truncation=True, padding='max_length', return_tensors='tf')\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape [1, num_classes]\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probs = tf.nn.softmax(logits, axis=1)\n",
    "\n",
    "# Get top-5 predictions\n",
    "topk = tf.math.top_k(probs, k=5)\n",
    "indices = topk.indices.numpy()[0]\n",
    "scores = topk.values.numpy()[0]\n",
    "\n",
    "# Map indices to labels\n",
    "labels = [model.config.id2label[i] for i in indices]\n",
    "\n",
    "# Create readable output\n",
    "readable = [{\"label\": lbl, \"score\": round(float(scr), 4)} for lbl, scr in zip(labels, scores)]\n",
    "\n",
    "print(readable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfd7ffe0-348c-4f62-941c-61fa64245134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "keras",
     "tensorflow"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7164684470295333,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "topics_build_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
