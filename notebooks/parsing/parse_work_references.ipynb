{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f91c1a82-c7d3-4162-aea5-5e103607661b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create `openalex.works.work_references` table (if not exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48ed9a6-c9a9-4b91-a183-c96101b68e2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- looks like a few fields have been added after - citing_work_id, cited_work_id, etc.\n",
    "CREATE TABLE IF NOT EXISTS openalex.works.work_references \n",
    "CLUSTER BY AUTO\n",
    "AS\n",
    "  WITH references_exploded AS (\n",
    "    SELECT \n",
    "      native_id, \n",
    "      native_id_namespace,\n",
    "      work_id as citing_work_id,\n",
    "      provenance,\n",
    "      posexplode(references) as (ref_ind, ref)\n",
    "    FROM openalex.works.locations_mapped\n",
    "  )\n",
    "  SELECT\n",
    "    native_id, \n",
    "    native_id_namespace,\n",
    "    citing_work_id,\n",
    "    ref_ind,\n",
    "    ref.doi as doi,\n",
    "    ref.pmid as pmid,\n",
    "    ref.arxiv as arxiv,\n",
    "    ref.title as title,\n",
    "    ref.authors as authors,\n",
    "    ref.year as year,\n",
    "    ref.raw as raw,\n",
    "    provenance,\n",
    "    current_timestamp() as created_timestamp,\n",
    "    current_timestamp() as updated_timestamp\n",
    "  FROM references_exploded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "697be13a-4c28-4915-8100-2471f5e9be28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Insert fresh records for Parsing into `work_references`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567d7915-cb93-49dd-82fa-886cfc4fb6f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Insert new references into work_references table\n",
    "-- Strategy: INSERT ONLY for new (citing_work_id, ref_ind) combinations\n",
    "-- Rationale: References don't change often; avoids data shift issues\n",
    "-- For full re-processing of a work, delete its references first, then insert\n",
    "-- 10/23 \n",
    "    -- 84,848,991 records inserted\n",
    "    -- 3,758,687,070 total records\n",
    "    -- 1,526,343,813 cited_work_id is NULL\n",
    "\n",
    "INSERT INTO openalex.works.work_references (\n",
    "  native_id,\n",
    "  native_id_namespace,\n",
    "  citing_work_id,\n",
    "  cited_work_id,\n",
    "  ref_ind,\n",
    "  doi,\n",
    "  pmid,\n",
    "  arxiv,\n",
    "  title,\n",
    "  normalized_title,\n",
    "  authors,\n",
    "  year,\n",
    "  raw,\n",
    "  parsed_doi,\n",
    "  parsed_first_author,\n",
    "  parsed_title,\n",
    "  title_author,\n",
    "  provenance,\n",
    "  created_timestamp,\n",
    "  updated_timestamp\n",
    ")\n",
    "WITH works_to_process AS (\n",
    "  SELECT \n",
    "    lm.native_id,\n",
    "    lm.native_id_namespace,\n",
    "    lm.work_id as citing_work_id,\n",
    "    lm.provenance,\n",
    "    posexplode(lm.references) as (ref_ind, ref)\n",
    "  FROM openalex.works.locations_mapped lm\n",
    "  LEFT ANTI JOIN openalex.works.work_references wr\n",
    "    ON lm.work_id = wr.citing_work_id\n",
    ")\n",
    "SELECT \n",
    "  native_id,\n",
    "  native_id_namespace,\n",
    "  citing_work_id,\n",
    "  CAST(null as BIGINT), -- cited_work_id (calculated later)\n",
    "  ref_ind,\n",
    "  ref.doi as doi,\n",
    "  ref.pmid as pmid,\n",
    "  ref.arxiv as arxiv,\n",
    "  ref.title as title,\n",
    "  CAST(null as STRING), -- normalized_title (calculated later)\n",
    "  ref.authors as authors,\n",
    "  ref.year as year,\n",
    "  ref.raw as raw,\n",
    "  CAST(null as STRING), -- parsed_doi (calculated later)\n",
    "  CAST(null as STRING), -- parsed_first_author (calculated later)\n",
    "  CAST(null as STRING), -- parsed_title (calculated later)\n",
    "  CAST(null as STRING), -- title_author (calculated later)\n",
    "  provenance,\n",
    "  current_timestamp() as created_timestamp,\n",
    "  current_timestamp() as updated_timestamp\n",
    "FROM works_to_process;\n",
    "-- For full re-processing of specific works, run this first:\n",
    "-- DELETE FROM openalex.works.work_references\n",
    "-- WHERE citing_work_id IN (SELECT work_id FROM openalex.works.locations_mapped WHERE ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "477d6ec4-4cc7-45d1-a780-d77e02612d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge with `work_id_map.doi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e3202e4-3891-4e5c-aae2-5bb478c2daaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- ============================================================\n",
    "-- STEP 2: Link references to cited works via DOI matching\n",
    "-- ============================================================\n",
    "-- Update cited_work_id and title_author for references where DOI matches work_id_map\n",
    "-- Prefer paper_id, fall back to id within work_id_map\n",
    "-- Only updates records where cited_work_id is still NULL\n",
    "-- 10/23 added 29,913,749 IDs for 84,848,991 new records, recovered 39,496 pmid\n",
    "\n",
    "MERGE INTO openalex.works.work_references AS target\n",
    "USING (\n",
    "  SELECT \n",
    "    LOWER(doi) as doi,\n",
    "    MIN(paper_id) as paper_id,\n",
    "    MIN(id) as work_id,\n",
    "    MIN(pmid) as pmid,\n",
    "    MAX(title_author) as title_author \n",
    "  FROM openalex.works.work_id_map\n",
    "  WHERE doi IS NOT NULL\n",
    "  GROUP BY lower(doi)\n",
    ") AS source\n",
    "ON lower(target.doi) = source.doi\n",
    "WHEN MATCHED AND target.cited_work_id IS NULL\n",
    "THEN UPDATE SET\n",
    "  target.cited_work_id = COALESCE(source.paper_id, source.work_id),\n",
    "  target.pmid = COALESCE(source.pmid, target.pmid), -- bring it in if exists\n",
    "  target.title_author = COALESCE(source.title_author, target.title_author), -- bring it in if exists\n",
    "  target.updated_timestamp = current_timestamp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4bc567e-f032-46ff-9139-d860b77363af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge with `work_id_map.pmid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63abcef0-acf8-4034-89fc-86c029220782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 10/23 added 11,311,131 IDs (where doi was null) for 84,848,991 new records \n",
    "MERGE INTO openalex.works.work_references AS target\n",
    "USING (\n",
    "  SELECT DISTINCT\n",
    "    lower(pmid) as pmid,\n",
    "    MIN(paper_id) AS paper_id,\n",
    "    MIN(id) as work_id,\n",
    "    MAX(title_author) as title_author\n",
    "  FROM openalex.works.work_id_map\n",
    "  WHERE pmid IS NOT NULL and doi is NULL -- keep doi is null because it otherwise adds a lot of erroneous refs\n",
    "  GROUP BY pmid\n",
    ") as source\n",
    "ON lower(target.pmid) = source.pmid\n",
    "WHEN MATCHED AND target.cited_work_id IS NULL\n",
    "THEN UPDATE SET\n",
    "  target.cited_work_id = COALESCE(source.paper_id, source.work_id),\n",
    "  target.title_author = COALESCE(source.title_author, target.title_author), -- bring it in if exists\n",
    "  target.updated_timestamp = current_timestamp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86d9e5cc-b5cd-4aba-b42f-b18f233432e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merge with `work_id_map.title_author`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2981664c-f416-47d0-a2de-34518fbf8d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 10/23 added 11,311,131 IDs for 84,848,991 new records\n",
    "MERGE INTO openalex.works.work_references AS target\n",
    "USING (\n",
    "  SELECT DISTINCT\n",
    "    lower(pmid) as pmid,\n",
    "    MIN(paper_id) AS paper_id,\n",
    "    MIN(id) as work_id,\n",
    "    MAX(title_author) as title_author\n",
    "  FROM openalex.works.work_id_map\n",
    "  WHERE pmid IS NOT NULL AND doi is NULL\n",
    "  GROUP BY pmid\n",
    ") as source\n",
    "ON lower(target.pmid) = source.pmid\n",
    "WHEN MATCHED AND target.cited_work_id IS NULL\n",
    "THEN UPDATE SET\n",
    "  target.cited_work_id = COALESCE(source.paper_id, source.work_id),\n",
    "  target.title_author = COALESCE(source.title_author, target.title_author), -- bring it in if exists\n",
    "  target.updated_timestamp = current_timestamp();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbba8c1e-5126-4fd3-a3c5-aa26a15ad819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "  SELECT provenance, native_id, native_id_namespace, references\n",
    "  FROM openalex.works.locations_parsed\n",
    "  WHERE references is not null and size(references) > 0\n",
    "  AND NOT(size(references) = 1 and references[0].doi is null \n",
    "    and references[0].pmid is null and references[0].title is null and references[0].arxiv is null and references[0].raw is null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b15fbea8-57e4-482c-9d62-05a91ac900d1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"provenance\":108,\"total_record_count\":155,\"total_reference_count\":170,\"total_dois\":104,\"total_pmids\":114,\"total_titles\":104,\"total_raw_strings\":144,\"total_authors\":117,\"has_any_dois\":119,\"has_any_pmids\":132,\"has_any_titles\":126},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761243781775}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH filtered_refs AS (\n",
    "  SELECT provenance, native_id, native_id_namespace, \n",
    "    references,\n",
    "    size(array_compact(references.doi)) as num_dois,\n",
    "    size(array_compact(references.pmid)) as num_pmids,\n",
    "    size(array_compact(references.title)) as num_titles,\n",
    "    size(array_compact(references.raw)) as num_raw,\n",
    "    size(array_compact(references.authors)) as num_authors\n",
    "  FROM openalex.works.locations_parsed\n",
    "  WHERE references is not null and size(references) > 0\n",
    "  AND NOT(size(references) = 1 and references[0].doi is null \n",
    "    and references[0].pmid is null and references[0].title is null \n",
    "    and references[0].arxiv is null and references[0].raw is null)\n",
    ")\n",
    "SELECT provenance,\n",
    "  format_number(count(*),0) as total_record_count,\n",
    "  format_number(sum(size(references)),0) as total_reference_count,\n",
    "  format_number(sum(num_dois),0) as total_dois, \n",
    "  format_number(sum(num_pmids),0) as total_pmids, \n",
    "  format_number(sum(num_titles),0) as total_titles,   \n",
    "  format_number(sum(num_authors),0) as total_authors,\n",
    "  format_number(sum(num_raw),0) as total_raw_strings,  \n",
    "  format_number(count_if(num_dois > 0),0) as has_any_dois,\n",
    "  format_number(count_if(num_pmids > 0),0) as has_any_pmids, \n",
    "  format_number(count_if(num_titles > 0),0) as has_any_titles,  \n",
    "  format_number(count_if(num_authors > 0),0) as has_any_authors,\n",
    "  format_number(count_if(num_raw > 0),0) as has_any_raw_strings\n",
    "FROM filtered_refs group by provenance order by 2 desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee466efb-76a4-4a0a-9820-293eeb4dfccb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Aggregate before `openalex_works`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0a15919-09c3-4c0f-856c-8e8b32f59e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE openalex.works.referenced_works\n",
    "SELECT\n",
    "  citing_work_id,\n",
    "  TRANSFORM(\n",
    "    SORT_ARRAY(COLLECT_LIST(STRUCT(ref_ind, cited_work_id))),\n",
    "    x -> x.cited_work_id\n",
    "  ) AS referenced_works\n",
    "FROM openalex.works.work_references\n",
    "WHERE cited_work_id IS NOT NULL\n",
    "GROUP BY citing_work_id;\n",
    "OPTIMIZE openalex.works.referenced_works ZORDER BY (citing_work_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f70d192-ee18-4451-bc27-3e2750061c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PARSING ENHANCEMENTS - TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af51e430-5c8d-4bbd-868c-0716bc845a4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %python\n",
    "# %pip install /Volumes/openalex/default/libraries/openalex_dlt_utils-0.2.3-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2347c3ae-4a23-4e65-bc9e-6d467ab613ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from nameparser import HumanName # Will be installed via pipeline libraries\n",
    "# from openalex.dlt.normalize import normalize_title_udf, udf_last_name_only\n",
    "# spark.udf.register(\"normalize_title_udf\", normalize_title_udf)\n",
    "# spark.udf.register(\"udf_last_name_only\", udf_last_name_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce7d4885-c104-4842-b2cb-38113b7b9519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extract `DOI`\n",
    "There are more than a dozen edge cases recovering additional 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566268fb-c44f-40f3-b9b5-61311f85bf07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %python\n",
    "# import re\n",
    "# from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "# # allow spaces in the registry digits: (?:\\d\\s*){4,9}\n",
    "# _DOI_PREFIX = r'10\\s*\\.\\s*(?:\\d\\s*){4,9}\\s*/\\s*'\n",
    "# _DOI_BODY   = r'(?:[-._;()/:A-Za-z0-9%]|\\s)+'\n",
    "\n",
    "# # https://... (tolerant of spaces, and supports (dx|doi).org)\n",
    "# _URL_DOI_OPT = re.compile(\n",
    "#     r'https?\\s*:?\\s*//\\s*(?:[a-z0-9-]+\\s*\\.)*(?:doi|dx)\\.org/\\s*(' + _DOI_PREFIX + _DOI_BODY + r')',\n",
    "#     re.IGNORECASE\n",
    "# )\n",
    "\n",
    "# # no-scheme \"... (dx|doi).org/10...\"\n",
    "# _NOSCHEME_DOI = re.compile(\n",
    "#     r'(?:(?<=\\s)|^|[\\(\\[\\{])(?:[a-z0-9-]+\\s*\\.)*(?:doi|dx)\\.org/\\s*(' + _DOI_PREFIX + _DOI_BODY + r')',\n",
    "#     re.IGNORECASE\n",
    "# )\n",
    "\n",
    "# # doi: org/10...   OR   doi: doi.org/10...   OR   doi: dx.org/10...\n",
    "# _COLON_DOI_ORG = re.compile(\n",
    "#     r'\\bdoi\\s*:\\s*(?:(?:[a-z0-9-]+\\s*\\.)*(?:doi|dx)\\s*\\.\\s*)?org\\s*/\\s*(' + _DOI_PREFIX + _DOI_BODY + r')',\n",
    "#     re.IGNORECASE\n",
    "# )\n",
    "\n",
    "# # direct \"doi: 10....\"\n",
    "# _COLON_DOI_DIRECT = re.compile(\n",
    "#     r'\\bdoi\\s*:\\s*(' + _DOI_PREFIX + _DOI_BODY + r')',\n",
    "#     re.IGNORECASE\n",
    "# )\n",
    "\n",
    "# _TRAIL = re.compile(r'[\\]\\)\\}\\.,;:]+$')\n",
    "\n",
    "# def _normalize_after_gate(s: str) -> str:\n",
    "#     s = s.replace('\\r', ' ').replace('\\n', ' ')\n",
    "#     s = ' '.join(s.split())\n",
    "#     s = re.sub(r'(?i)(doi\\.)\\s*org', r'\\1org', s)\n",
    "#     s = re.sub(r'(?i)(dx\\.)\\s*org', r'\\1org', s)\n",
    "#     s = re.sub(r'(?i)\\bhttps\\s*//', 'https://', s)\n",
    "#     s = re.sub(r'(?i)\\bhttp\\s*//', 'http://', s)\n",
    "#     # decode URL-encoded slashes anywhere\n",
    "#     s = re.sub(r'(?i)%\\s*2\\s*f', '/', s)\n",
    "#     return s\n",
    "\n",
    "# def extract_doi(text: str):\n",
    "#     \"\"\"\n",
    "#     Return DOI only if raw contains 'doi:', 'doi.' (e.g., doi.org), or 'dx.'.\n",
    "#     Accepts `doi: org/10...` as well as `doi: doi.org/10...` and `doi: dx.org/10...`.\n",
    "#     \"\"\"\n",
    "#     if not text:\n",
    "#         return None\n",
    "#     low = text.lower()\n",
    "#     if ('doi:' not in low) and ('doi.' not in low) and ('dx.' not in low):\n",
    "#         return None\n",
    "\n",
    "#     s = _normalize_after_gate(text)\n",
    "\n",
    "#     m = (_NOSCHEME_DOI.search(s) or\n",
    "#          _URL_DOI_OPT.search(s) or\n",
    "#          _COLON_DOI_ORG.search(s) or\n",
    "#          _COLON_DOI_DIRECT.search(s))\n",
    "#     if not m:\n",
    "#         return None\n",
    "\n",
    "#     doi = re.sub(r'\\s+', '', m.group(1))   # strip internal spaces\n",
    "#     doi = _TRAIL.sub('', doi)              # trim trailing .,;:)]}\n",
    "#     return doi or None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "810d4394-6f6a-4d19-b899-365a5b201600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Register UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4629b793-cd02-4baf-93e3-df34bed625e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# extract_doi_udf = udf(extract_doi, StringType())\n",
    "# spark.udf.register(\"extract_doi_udf\", extract_doi_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58fc8339-72f5-481d-ac9a-11ed6ad9c4b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9497a156-d8fb-452b-b33c-10865de10e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %python\n",
    "# raw_input = [\n",
    "#     \"McGrath, R. (2015). Character strengths in 75 nations: An update. The Journal of Positive Psychology, 10(1), 41-52. https://doi.org/10.1080/17439760.2014.888580\",\n",
    "#     \"Sun J, Ajwani D, Nicholson PK, Sala A and Parthasarathy S (2017) Breaking Cycles In Noisy Hierarchies. Proceedings of the 2017 ACM on Web Science Conference: 151-160 http://dx.doi. org/10.1145/3091478.3091495\",\n",
    "#     \"Banks PA, Bollen TL, Dervenis C, Gooszen HG, Johnson CD, Sarr MG, Tsiotos GG, Vege SS; Acute Pancreatitis Classification Working Group. Classification of acute pancreatitis--2012: revision of the Atlanta classification and definitions by international consensus. Gut. 2013;62(1):102-11. doi: 10.1136/gutjnl-2012-302779. [bleh]\",\n",
    "#     \"Araujo MCR, da Silva DA, Wilson AMMM. Nursing interven- tions in palliative care in the intensive care unit: A system- atic review. Enfermeria Intensiva. 2023 34: 156-172. https: //doi.org/10.1016/j.enfie.2023.08.008.\",\n",
    "#     \"LEMASTER James C., \\\"Zwizek midzy Baconem, teleologi i analogi a doktryn naturali- zmu metodologicznego\\\", prze. Dariusz Sagan, Filozoficzne Aspekty Genezy 2017, t. 14, s. 99-133, http://www.nauka-a-religia.uz.zgora.pl/images/FAG/2017.t.14/art.04.pdf (14.10. 2018). MAYR Ersnt, \\\"Cause and Effect in Biology\\\", Science 1961, vol. 134, s. 1501-1506, doi:10. 1126/science.134.3489.1501.\",\n",
    "#     \"Mazumder, M.A.R., Hossain, M. M. and Akhtar, S. 1998. Effect of levels of concentrate supplement on live weight gain and carcass characteristics in sheep on restricted grazing. Asian Aust. J. Anim. Sci., 11: 17-21. doi.org/10.5713/ajas.1998.\",\n",
    "#     \"Lima RF, Toledo MI, Naves JOS. Avaliao de servios far- macuticos hospitalares: uma reviso integrativa. Rev Bras Farm Hosp Serv Sade, 2019; 9(2):01-08. DOI: 10.3068/ rbfhss.2018.092.005\",\n",
    "#     \"A. Buonomo, A. Lo Schiavo. Divide-by-Three Injection-Locked Frequency Dividers with Direct Forcing Signal // Hindawi Publishing Corporation Journal of Electrical and Computer Engineering, article ID 145314, 9 p., 2013, doi: org/10.1155/2013/145314.\",\n",
    "#     \"Fernndez, H., & Macbeth, G. (2018). Perspectiva de tiempo futuro, metas y sub-metas: su rol en la toma de decisiones. Revista Latinoamericana de Cien- cia Psicolgica, 10, https//doi.org/10.5872/psien- cia/10.2.23\",\n",
    "#     \"Hakanson, L. (1980). An ecological risk index for aquatic pollution control.a sedimentological approach. Water ________________________ Egypt. J. Geo. Vol. 67 (2023) Research, 14(8), 975-1001. https://doi.org/10.101 6/0043-1354(80)90143-8.\",\n",
    "#     \"Davidson MH, Christine M, Ballantyne CM, Jacobson TA, Bittner VA, Braun LT, et al. (2011). Clinical utility of inflammatory markers and advanced lipoprotein testing: advice from an expert panel of lipid specialists. J Clin Lipidol 5(5): 338-367. DOI: https://dx.org/10.1016/J.Jacl.2011.07.005\",\n",
    "#     \"Ren J, Hong T, He C, Sun L, Li X, Ma Y, et al. Coexistence of Intracranial and Spinal Cord Cavernous Malformations Predict Aggressive Clinical Presentation. Presentation. Front. Neurol. 2019; 10:618. https://doi.org/10.3389%2Ffneur.2019.00618\"\n",
    "# ]\n",
    "\n",
    "# for i in raw_input:\n",
    "#     print(extract_doi(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5d131e1-e88e-4fca-b185-a7c3eb078b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Spotcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76b7678-1ed3-40be-bbb6-e7e7890d1071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT *\n",
    "# FROM openalex.works.work_references\n",
    "# WHERE doi IS NULL\n",
    "#   AND parsed_doi IS NULL\n",
    "#   AND raw IS NOT NULL\n",
    "#   AND (CONTAINS(lower(raw), 'doi:') OR CONTAINS(lower(raw), 'doi.'))\n",
    "# LIMIT 2000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e4abe32-d478-4da5-ad10-dc64c2669ba7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extract `FIRST AUTHOR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8131973e-c607-4bac-82e1-037d1bfd9284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # One initial (we’ll keep only the first), allowing dots/hyphens/spaces between letters\n",
    "# _INITIALS = r'(?:[A-Z](?:[.\\-]?\\s*)?){1,3}'\n",
    "\n",
    "# # A LAST-NAME TOKEN must either contain a lowercase somewhere OR be ALL-CAPS (≥3 chars).\n",
    "# # This prevents \"AJ\" / \"BT\" from being misread as surnames, while allowing \"LEMASTER\".\n",
    "# _LAST_TOKEN = r\"(?:[A-Z][A-Za-z'’\\-]*[a-z][A-Za-z'’\\-]*|[A-Z]{3,}[A-Za-z'’\\-]*)\"\n",
    "# _LAST_MULTI = rf\"(?:{_LAST_TOKEN}(?:\\s+{_LAST_TOKEN}){{0,2}})\"\n",
    "\n",
    "# # A spelled given name must include a lowercase (blocks 'LEMASTER' from counting as given)\n",
    "# _GIVENWORD = r\"[A-Z][a-z][A-Za-z'’\\-]*\"\n",
    "\n",
    "# # Patterns (anchored at start)\n",
    "# P_COMMA_GIVEN  = re.compile(rf'^\\s*(?P<last>{_LAST_MULTI})\\s*,\\s*(?P<given>{_GIVENWORD})\\b')\n",
    "# P_COMMA_INIT   = re.compile(rf'^\\s*(?P<last>{_LAST_MULTI})\\s*,\\s*(?P<inits>{_INITIALS})\\b')\n",
    "# P_GIVEN_LAST   = re.compile(rf'^\\s*(?P<inits>{_INITIALS})\\s+(?P<last>{_LAST_MULTI})\\b')\n",
    "# P_LAST_INIT    = re.compile(rf'^\\s*(?P<last>{_LAST_MULTI})\\s+(?P<inits>{_INITIALS})\\b')\n",
    "# P_LAST_GIVENI  = re.compile(rf'^\\s*(?P<last>{_LAST_MULTI})\\s+(?P<given>{_GIVENWORD})(?:\\s+(?P<inits>{_INITIALS}))?\\b')\n",
    "# P_GIVENWORD_LAST = re.compile(rf'^\\s*(?P<given>{_GIVENWORD})\\s+(?P<last>{_LAST_MULTI})\\b')\n",
    "\n",
    "# # Hard separators between *authors* (don’t split on comma—needed for \"Last, I\")\n",
    "# _SEP = re.compile(r'\\s*(?:;|&|\\band\\b)\\s*', re.IGNORECASE)\n",
    "\n",
    "# def _norm(s: str) -> str:\n",
    "#     if not s:\n",
    "#         return \"\"\n",
    "#     s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "#     s = re.sub(r\"([A-Za-z])\\s*-\\s*([A-Za-z])\", r\"\\1\\2\", s)  # heal \"prob- lem\"\n",
    "#     return \" \".join(s.split()).strip()\n",
    "\n",
    "# def _first_initial(*chunks: str) -> str | None:\n",
    "#     \"\"\"Return the first A–Z found across chunks (prefer given over initials).\"\"\"\n",
    "#     for c in chunks:\n",
    "#         if not c:\n",
    "#             continue\n",
    "#         m = re.search(r'[A-Z]', c)\n",
    "#         if m:\n",
    "#             return m.group(0)\n",
    "#     return None\n",
    "\n",
    "# def first_author_last_initial(text: str) -> str | None:\n",
    "#     \"\"\"\n",
    "#     Return 'Last, I' (single initial, no dots) for the first author in `text`.\n",
    "#     \"\"\"\n",
    "#     s = _norm(text or \"\")\n",
    "#     head = _SEP.split(s, maxsplit=1)[0]  # only the first author segment\n",
    "\n",
    "#     # Order matters:\n",
    "#     # 1) \"Last, Given\" (e.g., \"Bravetti, Margarita\")\n",
    "#     m = P_COMMA_GIVEN.match(head)\n",
    "#     if m:\n",
    "#         ini = _first_initial(m.group('given'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\" if ini else m.group('last').strip()\n",
    "\n",
    "#     # 2) \"GivenInitials Last\" (e.g., \"AJ Smith\", \"A.J. Smith\")\n",
    "#     m = P_GIVEN_LAST.match(head)\n",
    "#     if m:\n",
    "#         ini = _first_initial(m.group('inits'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\"\n",
    "\n",
    "#     # 3) \"Last Initials\" (e.g., \"Smith AJ\", \"Del Fabbro M\")\n",
    "#     m = P_LAST_INIT.match(head)\n",
    "#     if m:\n",
    "#         ini = _first_initial(m.group('inits'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\"\n",
    "\n",
    "#     # 4) \"Last, Initials\" (e.g., \"Smith, AJ\")\n",
    "#     m = P_COMMA_INIT.match(head)\n",
    "#     if m:\n",
    "#         ini = _first_initial(m.group('inits'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\"\n",
    "\n",
    "#     # 5) \"Last Given [Initials]\" (e.g., \"LEMASTER James C.\", \"Del Fabbro Mario C.\")\n",
    "#     m = P_LAST_GIVENI.match(head)\n",
    "#     if m:\n",
    "#         # prefer the initial from the GIVEN word, not the trailing initials\n",
    "#         ini = _first_initial(m.group('given'), m.group('inits'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\" if ini else m.group('last').strip()\n",
    "\n",
    "#     # 6) \"Given Last\" (e.g., \"Nicole Johnson\")\n",
    "#     m = P_GIVENWORD_LAST.match(head)\n",
    "#     if m:\n",
    "#         ini = _first_initial(m.group('given'))\n",
    "#         return f\"{m.group('last').strip()}, {ini}\"\n",
    "\n",
    "#     # Fallback: first capitalized token as last\n",
    "#     m = re.match(r\"^\\s*([A-Z][A-Za-z'’\\-]+)\", head)\n",
    "#     return m.group(1) if m else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "663b0ef2-7ea2-4316-85cb-e677a580fc9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Register UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1042381-a1b9-4381-a455-d3999dc8fcec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# first_author_last_initial_udf = udf(first_author_last_initial, StringType())\n",
    "# spark.udf.register(\"first_author_last_initial\", first_author_last_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ab85c09-8097-4c3f-bd5a-091030e5c187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9389b69d-f507-463b-aafb-0b4255b5b9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tests = [\n",
    "#     \"A Smith\",\n",
    "#     \"AB Smith\",\n",
    "#     \"A Johnson, B Smith\",\n",
    "#     \"AJ Smith, BT Johnson\",\n",
    "#     \"A.J. Smith and B.T. Johnson\",\n",
    "#     \"Smith AJ, Johnson BT\",\n",
    "#     \"Smith A.J., Johnson B.T.\",\n",
    "#     \"Smith, AJ, Johnson, BT\",\n",
    "#     \"Del Fabbro M, Taschieri S\",\n",
    "#     \"H. N. Gabow and R. E. Tarjan, ...\",\n",
    "#     \"LEMASTER James C., ...\",\n",
    "#     \"Nicole Johnson\",\n",
    "#     \"Bravetti, Margarita\",\n",
    "#     \"Cunha HF, Morais PPAM (2010) Relao espcie-rea em cupinzeiros de pastagem, Goinia-GO, Brasil. Entomo Brasilis. 3(3):60-63.\",\n",
    "#     \"Glat, R., Ferreira, J. R., Oliveira, E. S. G., & Senna, L. A. G. (2003). Panorama nacional da educao inclusiva no Brasil. Relatrio de consultoria tcnica, Banco Mundial. Recuperado de www.cnotinfor.pt/projectos/worldbank/inclusiva\"\n",
    "# ]\n",
    "# for t in tests:\n",
    "#     print(t, \"->\", first_author_last_initial(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4b31075-9c10-44f4-a766-f5f5b9d9443e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Spotcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a26bbba-5e9d-41a0-be26-dd7611c5f353",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756191210780}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT title, authors, raw\n",
    "# FROM openalex.works.work_references\n",
    "# WHERE doi IS NULL and title is not null and authors is not null\n",
    "# LIMIT 2000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73b01ec9-d0a4-4d69-9638-636b5bc0f2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# UPDATE openalex.works.work_references\n",
    "# SET parsed_first_author = first_author_last_initial(authors)\n",
    "# WHERE authors IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bdbbd48-135c-450c-96e6-b2892d4068bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extract `TITLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa0bea5-b87c-4b77-8c1f-faff17808b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# _QUOTES = \"'\\\"“”‘’«»\"\n",
    "# BAD_START = re.compile(r\"^(?:doi|dx|https?|www\\.|vol\\.?|volume|article id|issn|isbn)\\b\", re.IGNORECASE)\n",
    "# YEAR_PAREN = re.compile(r\"\\(\\s*(?:19|20)\\d{2}\\s*\\)\")\n",
    "\n",
    "# def _norm(s: str) -> str:\n",
    "#     if not s:\n",
    "#         return \"\"\n",
    "#     s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "#     # heal line-break hyphenation only (keep real hyphens)\n",
    "#     s = re.sub(r\"([A-Za-z])-\\s+([A-Za-z])\", r\"\\1\\2\", s)\n",
    "#     return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "# def _next_nonspace(s: str, i: int) -> str:\n",
    "#     n = len(s)\n",
    "#     while i < n and s[i].isspace():\n",
    "#         i += 1\n",
    "#     return s[i] if i < n else \"\"\n",
    "\n",
    "# def _is_initial_before(s: str, dot_idx: int) -> bool:\n",
    "#     # True if just before '.' there is a single capital letter token (e.g., \"A.\")\n",
    "#     return bool(re.search(r\"[^\\w][A-Z]\\.$|^[A-Z]\\.$\", s[:dot_idx+1]))\n",
    "\n",
    "# def _sentence_break_positions(s: str):\n",
    "#     \"\"\"Yield indices of '.' that are sentence breaks.\"\"\"\n",
    "#     for m in re.finditer(r\"\\.\", s):\n",
    "#         i = m.start()\n",
    "#         if _is_initial_before(s, i):\n",
    "#             continue  # don't break on initials like \"A.\"\n",
    "#         nxt = _next_nonspace(s, i+1)\n",
    "#         if nxt and nxt.isalpha() and nxt.islower():\n",
    "#             continue  # \"control.a\" or \". a\" typo: not a break\n",
    "#         yield i\n",
    "\n",
    "# def _split_sentences(s: str):\n",
    "#     \"\"\"Return list of sentence strings, strictly cut at our sentence breaks.\"\"\"\n",
    "#     breaks = list(_sentence_break_positions(s))\n",
    "#     if not breaks:\n",
    "#         return [s] if s else []\n",
    "#     out = []\n",
    "#     start = 0\n",
    "#     for i in breaks:\n",
    "#         out.append(s[start:i].strip())\n",
    "#         start = i+1\n",
    "#     if start < len(s):\n",
    "#         out.append(s[start:].strip())\n",
    "#     return [seg for seg in out if seg]\n",
    "\n",
    "# def _strip_leading(t: str) -> str:\n",
    "#     # drop leading punctuation, brackets, quotes, and a leading year if present\n",
    "#     t = t.lstrip()\n",
    "#     t = re.sub(r\"^\\(\\s*(?:19|20)\\d{2}\\s*\\)\\s*[.:,]*\\s*\", \"\", t)\n",
    "#     t = re.sub(r\"^(?:19|20)\\d{2}\\s*[.:,]*\\s*\", \"\", t)\n",
    "#     t = re.sub(r\"^[\\(\\)\\[\\]\\.\\:,\\;]+\", \"\", t).lstrip()\n",
    "#     t = t.lstrip(_QUOTES)\n",
    "#     return t\n",
    "\n",
    "# def _cut_at_double_slash(t: str) -> str:\n",
    "#     m = re.search(r\"\\s//\\s|//\", t)\n",
    "#     return t[:m.start()].strip() if m else t.strip()\n",
    "\n",
    "# def _first_quoted_title(s: str) -> str | None:\n",
    "#     q = re.compile(r\"[\" + re.escape(_QUOTES) + r\"]\\s*([^\" + re.escape(_QUOTES) + r\"]{3,}?)\\s*[\" + re.escape(_QUOTES) + r\"]\")\n",
    "#     for m in q.finditer(s):\n",
    "#         cand = m.group(1).strip().strip(_QUOTES).strip().rstrip(\",;:\")\n",
    "#         if \" \" in cand and not BAD_START.match(cand):\n",
    "#             return cand\n",
    "#     return None\n",
    "\n",
    "# def _looks_like_authors(seg: str) -> bool:\n",
    "#     return bool(\n",
    "#         re.search(r\"\\b[A-Z]\\.\", seg) or      # initials\n",
    "#         re.search(r\",\", seg) or              # commas delimiting authors\n",
    "#         re.search(r\"\\band\\b|&|;\", seg, re.IGNORECASE)\n",
    "#     )\n",
    "\n",
    "# def extract_title(text: str) -> str | None:\n",
    "#     try:\n",
    "#         if text is None:\n",
    "#             return None\n",
    "#         s = _norm(text)\n",
    "#         if not s:\n",
    "#             return None\n",
    "\n",
    "#         # 0) Quoted titles take precedence anywhere\n",
    "#         qt = _first_quoted_title(s)\n",
    "#         if qt:\n",
    "#             return qt\n",
    "\n",
    "#         # 1) Split into sentences (strict, first-period rule)\n",
    "#         sentences = _split_sentences(s)\n",
    "#         if not sentences:\n",
    "#             return None\n",
    "\n",
    "#         # 2) If a (YYYY) occurs in sentence k, prefer sentence k+1 as title\n",
    "#         for idx, seg in enumerate(sentences):\n",
    "#             if YEAR_PAREN.search(seg):\n",
    "#                 if idx + 1 < len(sentences):\n",
    "#                     cand = _cut_at_double_slash(_strip_leading(sentences[idx + 1]))\n",
    "#                     return None if not cand or BAD_START.match(cand) else cand\n",
    "#                 break\n",
    "\n",
    "#         # 3) If first sentence looks like authors, pick the next one\n",
    "#         if _looks_like_authors(sentences[0]) and len(sentences) > 1:\n",
    "#             cand = _cut_at_double_slash(_strip_leading(sentences[1]))\n",
    "#             return None if not cand or BAD_START.match(cand) else cand\n",
    "\n",
    "#         # 4) Else use the first sentence\n",
    "#         cand = _cut_at_double_slash(_strip_leading(sentences[0]))\n",
    "#         return None if not cand or BAD_START.match(cand) else cand\n",
    "#     except Exception as e:\n",
    "#         # Handle the exception\n",
    "#         return f\"Exception: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a6fe795-a98c-40f1-b08d-fe3d5d1b7cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0266f1ef-ad3d-443f-a954-9ace25f231b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %python\n",
    "# raw_input = [\n",
    "#     \"McGrath, R. (2015). Character strengths in 75 nations: An update. The Journal of Positive Psychology, 10(1), 41-52. https://doi.org/10.1080/17439760.2014.888580\",\n",
    "#     \"Sun J, Ajwani D, Nicholson PK, Sala A and Parthasarathy S (2017) Breaking Cycles In Noisy Hierarchies. Proceedings of the 2017 ACM on Web Science Conference: 151-160 http://dx.doi. org/10.1145/3091478.3091495\",\n",
    "#     \"Banks PA, Bollen TL, Dervenis C, Gooszen HG, Johnson CD, Sarr MG, Tsiotos GG, Vege SS; Acute Pancreatitis Classification Working Group. Classification of acute pancreatitis--2012: revision of the Atlanta classification and definitions by international consensus. Gut. 2013;62(1):102-11. doi: 10.1136/gutjnl-2012-302779. [bleh]\",\n",
    "#     \"Araujo MCR, da Silva DA, Wilson AMMM. Nursing interven- tions in palliative care in the intensive care unit: A system- atic review. Enfermeria Intensiva. 2023 34: 156-172. https: //doi.org/10.1016/j.enfie.2023.08.008.\",\n",
    "#     \"LEMASTER James C., \\\"Zwizek midzy Baconem, teleologi i analogi a doktryn naturali- zmu metodologicznego\\\", prze. Dariusz Sagan, Filozoficzne Aspekty Genezy 2017, t. 14, s. 99-133, http://www.nauka-a-religia.uz.zgora.pl/images/FAG/2017.t.14/art.04.pdf (14.10. 2018). MAYR Ersnt, \\\"Cause and Effect in Biology\\\", Science 1961, vol. 134, s. 1501-1506, doi:10. 1126/science.134.3489.1501.\",\n",
    "#     \"Mazumder, M.A.R., Hossain, M. M. and Akhtar, S. 1998. Effect of levels of concentrate supplement on live weight gain and carcass characteristics in sheep on restricted grazing. Asian Aust. J. Anim. Sci., 11: 17-21. doi.org/10.5713/ajas.1998.\",\n",
    "#     \"Lima RF, Toledo MI, Naves JOS. Avaliao de servios far- macuticos hospitalares: uma reviso integrativa. Rev Bras Farm Hosp Serv Sade, 2019; 9(2):01-08. DOI: 10.3068/ rbfhss.2018.092.005\",\n",
    "#     \"A. Buonomo, A. Lo Schiavo. Divide-by-Three Injection-Locked Frequency Dividers with Direct Forcing Signal // Hindawi Publishing Corporation Journal of Electrical and Computer Engineering, article ID 145314, 9 p., 2013, doi: org/10.1155/2013/145314.\",\n",
    "#     \"Fernndez, H., & Macbeth, G. (2018). Perspectiva de tiempo futuro, metas y sub-metas: su rol en la toma de decisiones. Revista Latinoamericana de Cien- cia Psicolgica, 10, https//doi.org/10.5872/psien- cia/10.2.23\",\n",
    "#     \"Hakanson, L. (1980). An ecological risk index for aquatic pollution control.a sedimentological approach. Water ________________________ Egypt. J. Geo. Vol. 67 (2023) Research, 14(8), 975-1001. https://doi.org/10.101 6/0043-1354(80)90143-8.\",\n",
    "#     \"Davidson MH, Christine M, Ballantyne CM, Jacobson TA, Bittner VA, Braun LT, et al. (2011). Clinical utility of inflammatory markers and advanced lipoprotein testing: advice from an expert panel of lipid specialists. J Clin Lipidol 5(5): 338-367. DOI: https://dx.org/10.1016/J.Jacl.2011.07.005\",\n",
    "#     \"Ren J, Hong T, He C, Sun L, Li X, Ma Y, et al. Coexistence of Intracranial and Spinal Cord Cavernous Malformations Predict Aggressive Clinical Presentation. Presentation. Front. Neurol. 2019; 10:618. https://doi.org/10.3389%2Ffneur.2019.00618\"\n",
    "# ]\n",
    "\n",
    "# for i in raw_input:\n",
    "#     print(extract_title(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ebd0943-8d4f-48b8-85c4-9802c82f5e68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Register UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "866eb22e-4abb-47ca-9caa-ff9c7b63cd0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pyspark.sql.functions import *\n",
    "\n",
    "# extract_title_udf = udf(extract_title, StringType())\n",
    "# spark.udf.register(\"extract_title_udf\", extract_title_udf)\n",
    "\n",
    "# @pandas_udf(StringType())\n",
    "# def extract_title_pandas_udf(title_series: pd.Series) -> pd.Series:\n",
    "#     # This Pandas UDF calls your original 'normalize_license' Python function\n",
    "#     return title_series.apply(extract_title)\n",
    "# spark.udf.register(\"extract_title_pandas_udf\", extract_title_pandas_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "568f048a-2b95-4683-b65f-b365244e52ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Update `parsed_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41bf20a3-605c-4f98-84e4-68cd13e4d920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# MERGE INTO openalex.works.work_references AS target\n",
    "# USING (\n",
    "#     SELECT ref_ind, citing_work_id, \n",
    "#     extract_title_pandas_udf(substr(raw, 1, 3000)) AS new_parsed_title\n",
    "#     FROM openalex.works.work_references\n",
    "#     WHERE cited_work_id IS NULL AND raw IS NOT NULL\n",
    "#       AND parsed_title IS NULL\n",
    "#       AND title IS NULL\n",
    "#       AND doi IS NULL\n",
    "#       AND parsed_doi IS NULL\n",
    "# ) AS source\n",
    "# ON target.raw = source.raw\n",
    "#   AND target.citing_work_id = source.citing_work_id\n",
    "# WHEN MATCHED THEN\n",
    "#   UPDATE SET target.parsed_title = source.new_parsed_title;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "376f8cba-366c-4c29-8b7a-70c630389990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NORMALIZE TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5b4d29-3d50-4625-92dd-a7026c5cfe92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# UPDATE openalex.works.work_references\n",
    "# SET normalized_title = normalize_title_udf(title)\n",
    "# WHERE title IS NOT NULL and normalized_title IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ad4a153-3052-4df5-9197-8c5ff77de8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# UPDATE openalex.works.work_references\n",
    "# SET normalized_title = normalize_title_udf(coalesce(title, parsed_title))\n",
    "# WHERE normalized_title is null and (parsed_title IS NOT NULL OR title IS NOT NULL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac92bd2-d9be-4ce5-a56d-252ab09afe92",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756169635250}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql \n",
    "# SELECT udf_last_name_only(array(\n",
    "#   named_struct('name', \"Meier, O. and Quille, G. \"),\n",
    "#   named_struct('name', \"Wilson, M. , Stearne, A , Gray, D & Saggers, S\"),\n",
    "#   named_struct('name', \"Schroder, F\"),\n",
    "#   named_struct('name', 'ROLLET, Catherine, MOREL, Marie-France'),\n",
    "#   named_struct('name', 'Ohmoto A, Fuji S.'),\n",
    "#   named_struct('name', 'Araujo MCR, da Silva DA, Wilson AMMM.'),\n",
    "#   named_struct('name', 'S.O. Roberts, E. Mortenson')\n",
    "# )).author_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "443c07f0-f719-4b2a-9dbc-e24e4dbcbbfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# UPDATE openalex.works.work_references\n",
    "# SET author_key = udf_last_name_only(array(named_struct('name', authors)))[0].author_key\n",
    "# WHERE author_key IS NULL and authors is NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd2b5ac-7178-4715-8962-c54ac5138cb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# UPDATE openalex.works.work_references\n",
    "# SET parsed_doi = extract_doi_udf(raw)\n",
    "# WHERE doi IS NULL\n",
    "#   AND parsed_doi IS NULL\n",
    "#   AND raw IS NOT NULL\n",
    "#   AND (CONTAINS(lower(raw), 'doi:') OR CONTAINS(lower(raw), 'doi.'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45c78cab-654c-4d77-ad39-daacfaf9d54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SAMPLE EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b72832b-6185-4645-976e-5bd2d2520622",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"parsed\":410},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756160364877}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT raw, openalex.agents.parse_raw_reference(raw) as parsed\n",
    "# FROM openalex.agents.work_references_raw_sample\n",
    "# LIMIT 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b3cd79f-4c50-451f-b2f8-dd4f4b09fa76",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"authors\":476},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756155324143}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# -- Replace my_db.my_table with your table; expects column `raw`\n",
    "# WITH norm AS (\n",
    "#   SELECT\n",
    "#     raw,\n",
    "#     -- normalize whitespace, fix hyphenated line-break words, and remove spaces after doi.org/\n",
    "#     regexp_replace(\n",
    "#       regexp_replace(\n",
    "#         regexp_replace(\n",
    "#           regexp_replace(raw, '[\\\\r\\\\n]+', ' '),               -- newlines -> space\n",
    "#           '\\\\s+', ' '                                          -- collapse spaces\n",
    "#         ),\n",
    "#         '([A-Za-z])\\\\s*-\\\\s*([A-Za-z])', '\\\\1\\\\2'              -- join \"Ohmu- ra\" -> \"Ohmura\"\n",
    "#       ),\n",
    "#       '(?i)(doi\\\\.org/)\\\\s+', '\\\\1'                            -- kill spaces after doi.org/\n",
    "#     ) AS s\n",
    "#   FROM openalex.agents.work_references_raw_sample\n",
    "# ),\n",
    "# parts AS (\n",
    "#   SELECT\n",
    "#     raw, s,\n",
    "\n",
    "#     -- AUTHORS: everything left of the first 19xx/20xx (optionally in parentheses)\n",
    "#     trim(\n",
    "#       regexp_replace(\n",
    "#         regexp_extract(s, '^(.*?)\\\\s*\\\\(?\\\\b(?:19|20)\\\\d{2}\\\\b', 1),\n",
    "#         '\\\\s*[\\\\.,;:]+\\\\s*$', ''   -- strip trailing punctuation\n",
    "#       )\n",
    "#     ) AS authors_from_year,\n",
    "\n",
    "#     -- TITLE (primary): after year (with (), . or :) up to the next period\n",
    "#     trim(\n",
    "#       regexp_extract(\n",
    "#         s,\n",
    "#         '(?:\\\\(|\\\\b)(?:19|20)\\\\d{2}(?:\\\\))?\\\\s*[\\\\.:]?\\\\s*(.+?)\\\\.',\n",
    "#         1\n",
    "#       )\n",
    "#     ) AS title_after_year,\n",
    "\n",
    "#     -- TITLE (fallback): second sentence (helps when year is after the journal block)\n",
    "#     trim(regexp_extract(s, '^[^.]*\\\\.\\\\s*([^.]+?)\\\\.', 1)) AS title_second_sentence,\n",
    "\n",
    "#     -- DOI to end-of-string (prefer URL, then \"doi: 10...\", then bare \"10...\")\n",
    "#     trim(regexp_extract(s, '(?i)(https?://\\\\s*doi\\\\.org/\\\\S.*)$', 1)) AS doi_url_eos,\n",
    "#     trim(regexp_extract(s, '(?i)(doi\\\\s*:\\\\s*10\\\\.\\\\d{4,9}/\\\\S.*)$', 1)) AS doi_colon_eos,\n",
    "#     trim(regexp_extract(s, '(?i)\\\\b(10\\\\.\\\\d{4,9}/\\\\S.*)$', 1))       AS doi_bare_eos\n",
    "#   FROM norm\n",
    "# )\n",
    "# SELECT\n",
    "#   raw,\n",
    "\n",
    "#   -- AUTHORS per your rule\n",
    "#   NULLIF(authors_from_year, '') AS authors,\n",
    "\n",
    "#   -- TITLE: prefer after-year; if too short/missing, use second sentence before year\n",
    "#   CASE\n",
    "#     WHEN title_after_year IS NOT NULL AND length(title_after_year) >= 8 THEN title_after_year\n",
    "#     WHEN title_second_sentence IS NOT NULL AND length(title_second_sentence) >= 8 THEN title_second_sentence\n",
    "#     ELSE NULL\n",
    "#   END AS title,\n",
    "\n",
    "#   -- DOI to end-of-string (normalize minor spacing)\n",
    "#   CASE\n",
    "#     WHEN doi_url_eos    <> '' THEN regexp_replace(doi_url_eos,    '(?i)(doi\\\\.org/)\\\\s+', '\\\\1')\n",
    "#     WHEN doi_colon_eos  <> '' THEN regexp_replace(doi_colon_eos,  '(?i)(doi\\\\s*:\\\\s*)\\\\s*', '\\\\1')\n",
    "#     WHEN doi_bare_eos   <> '' THEN doi_bare_eos\n",
    "#     ELSE NULL\n",
    "#   END AS doi_to_eos\n",
    "\n",
    "# FROM parts;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4588904806706811,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "parse_work_references",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
